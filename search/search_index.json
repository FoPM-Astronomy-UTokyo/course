{"config":{"lang":["ja"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"IoA FoPM Practical Course \u5909\u9769\u3092\u99c6\u52d5\u3059\u308b\u5148\u7aef\u7269\u7406\u30fb\u6570\u5b66\u30d7\u30ed\u30b0\u30e9\u30e0 \u5909\u9769\u3092\u99c6\u52d5\u3059\u308b\u5148\u7aef\u7269\u7406\u30fb\u6570\u5b66\u30d7\u30ed\u30b0\u30e9\u30e0 (FoPM) \u306f, \u4fee\u58eb\u535a\u58eb\u4e00\u8cab\u306e 5 \u5e74\u9593\u306e\u5b66\u4f4d\u30d7\u30ed\u30b0\u30e9\u30e0\u3067\u3059. \u57fa\u790e\u79d1\u5b66\u306e\u5c02\u9580\u4eba\u6750\u306b, \u79d1\u5b66\u6280\u8853\u3084\u793e\u4f1a\u30a4\u30ce\u30d9\u30fc\u30b7\u30e7\u30f3\u306b\u5e83\u304f\u5f71\u97ff\u3092\u4e0e\u3048\u308b\u305f\u3081\u306e\u30b9\u30ad\u30eb\u3092\u63d0\u4f9b\u3059\u308b\u3053\u3068\u3067, \u5f7c\u3089\u306e\u30dd\u30c6\u30f3\u30b7\u30e3\u30eb\u3092\u6700\u5927\u5316\u3059\u308b\u30d7\u30ed\u30b0\u30e9\u30e0\u3067\u3059. \u3053\u306e\u30da\u30fc\u30b8\u3067\u306f FoPM \u3067\u5b9f\u65bd\u3057\u305f\u5b9f\u7fd2 (\u5929\u6587\u5b66) \u306e\u8cc7\u6599\u3092\u516c\u958b\u3057\u3066\u3044\u307e\u3059. \u305d\u308c\u305e\u308c\u306e\u8cc7\u6599\u3078\u306f\u4ee5\u4e0b\u306e\u30ea\u30f3\u30af\u304b\u3089\u30a2\u30af\u30bb\u30b9\u3057\u3066\u304f\u3060\u3055\u3044. \u5b9f\u7fd2\u5e74\u5ea6 \u5b9f\u7fd2\u30bf\u30a4\u30c8\u30eb 2020 \u30de\u30eb\u30b3\u30d5\u9023\u9396\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5\u5165\u9580","title":"\u30c8\u30c3\u30d7\u30da\u30fc\u30b8"},{"location":"#ioa-fopm-practical-course","text":"","title":"IoA FoPM Practical Course"},{"location":"#_1","text":"\u5909\u9769\u3092\u99c6\u52d5\u3059\u308b\u5148\u7aef\u7269\u7406\u30fb\u6570\u5b66\u30d7\u30ed\u30b0\u30e9\u30e0 (FoPM) \u306f, \u4fee\u58eb\u535a\u58eb\u4e00\u8cab\u306e 5 \u5e74\u9593\u306e\u5b66\u4f4d\u30d7\u30ed\u30b0\u30e9\u30e0\u3067\u3059. \u57fa\u790e\u79d1\u5b66\u306e\u5c02\u9580\u4eba\u6750\u306b, \u79d1\u5b66\u6280\u8853\u3084\u793e\u4f1a\u30a4\u30ce\u30d9\u30fc\u30b7\u30e7\u30f3\u306b\u5e83\u304f\u5f71\u97ff\u3092\u4e0e\u3048\u308b\u305f\u3081\u306e\u30b9\u30ad\u30eb\u3092\u63d0\u4f9b\u3059\u308b\u3053\u3068\u3067, \u5f7c\u3089\u306e\u30dd\u30c6\u30f3\u30b7\u30e3\u30eb\u3092\u6700\u5927\u5316\u3059\u308b\u30d7\u30ed\u30b0\u30e9\u30e0\u3067\u3059. \u3053\u306e\u30da\u30fc\u30b8\u3067\u306f FoPM \u3067\u5b9f\u65bd\u3057\u305f\u5b9f\u7fd2 (\u5929\u6587\u5b66) \u306e\u8cc7\u6599\u3092\u516c\u958b\u3057\u3066\u3044\u307e\u3059. \u305d\u308c\u305e\u308c\u306e\u8cc7\u6599\u3078\u306f\u4ee5\u4e0b\u306e\u30ea\u30f3\u30af\u304b\u3089\u30a2\u30af\u30bb\u30b9\u3057\u3066\u304f\u3060\u3055\u3044. \u5b9f\u7fd2\u5e74\u5ea6 \u5b9f\u7fd2\u30bf\u30a4\u30c8\u30eb 2020 \u30de\u30eb\u30b3\u30d5\u9023\u9396\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5\u5165\u9580","title":"\u5909\u9769\u3092\u99c6\u52d5\u3059\u308b\u5148\u7aef\u7269\u7406\u30fb\u6570\u5b66\u30d7\u30ed\u30b0\u30e9\u30e0"},{"location":"mcmc/","text":"\u306f\u3058\u3081\u306b \u3053\u306e\u5b9f\u7fd2\u3067\u306f\u30de\u30eb\u30b3\u30d5\u9023\u9396\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5 (Markov-Chain Monte Carlo; MCMC ) \u3092\u3068\u308a\u3042\u3064\u304b\u3044\u307e\u3059. MCMC \u306f\u3042\u308b\u78ba\u7387\u5206\u5e03\u304b\u3089, \u78ba\u7387\u5909\u6570\u3092\u52b9\u7387\u3088\u304f\u30b5\u30f3\u30d7\u30eb\u3059\u308b\u305f\u3081\u306e\u624b\u6cd5\u306e\u3072\u3068\u3064\u3067\u3059. \u4efb\u610f\u306e\u78ba\u7387\u5206\u5e03\u306b\u5f93\u3046\u4e71\u6570\u3092\u751f\u6210\u3059\u308b\u305f\u3081\u306e\u624b\u6cd5\u3068\u8a00\u3044\u63db\u3048\u3066\u3082\u3044\u3044\u3067\u3057\u3087\u3046. \u78ba\u7387\u5909\u6570 \\(x\\) \u304c\u78ba\u7387\u5206\u5e03 \\(P(x)\\) \u306b\u5f93\u3046\u3068\u3057\u307e\u3059 1 . \u3053\u306e\u3053\u3068\u3092\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u8868\u8a18\u3057\u307e\u3059. \\[ x \\sim P(x). \\] \\(x\\) \u306f\u96e2\u6563\u5024\u3067\u3082\u9023\u7d9a\u3067\u3082\u3044\u3044\u306e\u3067\u3059\u304c, \u3053\u3053\u3067\u306f\u4fbf\u5b9c\u7684\u306b\u9023\u7d9a\u3057\u305f\u5024\u3092\u3068\u308b\u3068\u3057\u307e\u3057\u3087\u3046. \\(x\\) \u3092\u4f7f\u3063\u3066\u8a08\u7b97\u3067\u304d\u308b\u91cf \\(A(x)\\) \u306e\u671f\u5f85\u5024\u306f\u6b21\u306e\u3088\u3046\u306b\u66f8\u3051\u307e\u3059. \\[ \\left\\langle A(x) \\right\\rangle_{x \\sim P(x)} = \\int\\mathrm{d}x\\,A(x)P(x). \\] \u3082\u3057 \\(x\\) \u304c\u591a\u6b21\u5143\u306e\u91cf\u3067\u3042\u308c\u3070\u53f3\u8fba\u306e\u7a4d\u5206\u306f\u591a\u6b21\u5143\u7a7a\u9593\u3067\u306e\u7a4d\u5206\u306b\u306a\u308a\u307e\u3059. \u591a\u6b21\u5143\u3067\u306e\u7a4d\u5206\u306f\u4e00\u822c\u306b\u8a08\u7b97\u30b3\u30b9\u30c8\u304c\u9ad8\u304f\u306a\u3063\u3066\u3057\u307e\u3044\u307e\u3059. \u4e00\u65b9\u3067, \u78ba\u7387\u5206\u5e03 \\(P(x)\\) \u306b\u5f93\u3046\u78ba\u7387\u5909\u6570\u306e\u5217 \\(\\{x_i\\}_{i=1{\\ldots}n}\\) \u3092\u7528\u3044\u308b\u3068, \u53f3\u8fba\u306e\u7a4d\u5206\u3092\u4ee5\u4e0b\u306e\u548c\u306b\u3088\u3063\u3066\u8fd1\u4f3c\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \\[ \\int\\mathrm{d}x\\,A(x)P(x) \\simeq \\frac{1}{n}\\sum_{i=1}^{n} A(x_i). \\] \u3053\u308c\u306b\u3088\u3063\u3066\u3042\u3089\u3086\u308b\u91cf \\(A(x)\\) \u306e\u671f\u5f85\u5024\u3092\u307e\u3063\u305f\u304f\u540c\u3058\u624b\u7d9a\u304d\u3067\u6c42\u3081\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u307e\u305f, \\(x\\) \u304c\u96e2\u6563\u7684\u3067\u3042\u3063\u3066\u3082\u9023\u7d9a\u3067\u3042\u3063\u3066\u3082\u540c\u3058\u624b\u7d9a\u304d\u3067\u8a08\u7b97\u3092\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u3082\u3061\u308d\u3093, \u78ba\u7387\u5206\u5e03 \\(P(x)\\) \u306b\u5f93\u3046\u78ba\u7387\u5909\u6570\u306e\u5217 \\(\\{x_i\\}_{i=1{\\ldots}n}\\) \u3092\u52b9\u7387\u3088\u304f\u751f\u6210\u3059\u308b (\u78ba\u7387\u5206\u5e03 \\(P(x)\\) \u304b\u3089\u30b5\u30f3\u30d7\u30eb\u3059\u308b) \u624b\u6cd5\u304c\u3042\u308b\u3053\u3068\u304c\u524d\u63d0\u3067\u3059. \u30b5\u30f3\u30d7\u30eb\u3059\u308b\u305f\u3081\u306e\u8a08\u7b97\u30b3\u30b9\u30c8\u304c\u7a4d\u5206\u3092\u4e0a\u56de\u3063\u3066\u3057\u307e\u3063\u3066\u306f\u610f\u5473\u304c\u3042\u308a\u307e\u305b\u3093. \u305d\u3057\u3066 MCMC \u306f\u4f4e\u30b3\u30b9\u30c8\u3067\u78ba\u7387\u5206\u5e03 \\(P(x)\\) \u306b\u5f93\u3046\u78ba\u7387\u5909\u6570 \\(x\\) \u3092\u30b5\u30f3\u30d7\u30eb\u3059\u308b\u3053\u3068\u306e\u3067\u304d\u308b\u5f37\u529b\u306a\u624b\u6cd5\u3067\u3059. \u7279\u306b\u9ad8\u6b21\u5143\u7a7a\u9593\u3092\u5bfe\u8c61\u3068\u3057\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u5834\u5408\u3084, \u78ba\u7387\u5206\u5e03\u95a2\u6570\u3092\u76f4\u63a5\u8a08\u7b97\u3059\u308b\u3053\u3068\u304c\u96e3\u3057\u3044\u5834\u5408\u306b\u6d3b\u8e8d\u3057\u307e\u3059. \u4ee5\u4e0b\u3067\u306f, \u4f55\u6545 MCMC \u304c\u5fc5\u8981\u306b\u306a\u308b\u306e\u304b\u3068\u3044\u3063\u305f\u3068\u3053\u308d\u304b\u3089\u59cb\u3081\u3066, Python \u3067 MCMC \u3092\u52d5\u304b\u3059\u30b3\u30fc\u30c9\u3092\u66f8\u304d, \u3055\u307e\u3056\u307e\u306a\u554f\u984c\u306b\u9069\u7528\u3059\u308b\u3053\u3068\u3092\u76ee\u6307\u3057\u307e\u3059. \u30b3\u30f3\u30c6\u30f3\u30c4 \u4e71\u6570\u751f\u6210 \u2013 \u9006\u95a2\u6570\u6cd5\u3068\u68c4\u5374\u6cd5 \u9759\u7684\u306a\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5\u306b\u3088\u308b\u8a08\u7b97 \u52d5\u7684\u306a\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5 \u2013 \u30de\u30eb\u30b3\u30d5\u9023\u9396\u306b\u3088\u308b\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0 Metropolis-Hastings \u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306b\u3088\u308b MCMC \u5b9f\u8df5 \u30de\u30eb\u30b3\u30d5\u9023\u9396\u306e\u53ce\u675f\u306b\u95a2\u3059\u308b\u3042\u308c\u3053\u308c \u6f14\u7fd2\u554f\u984c: \u7dda\u5f62\u56de\u5e30 \u6f14\u7fd2\u554f\u984c: \u6253\u3061\u5207\u308a\u56de\u5e30\u30e2\u30c7\u30eb \u52d5\u4f5c\u74b0\u5883 \u3053\u306e\u30c6\u30ad\u30b9\u30c8\u306e\u5185\u5bb9\u306f Python 3.7.1 \u3092\u30d9\u30fc\u30b9\u306b\u4f5c\u6210\u3055\u308c\u3066\u3044\u307e\u3059. \u4f7f\u7528\u3057\u3066\u3044\u308b\u30d1\u30c3\u30b1\u30fc\u30b8\u306f\u4ee5\u4e0b\u306e\u3068\u304a\u308a\u3067\u3059. \u3082\u3057\u30c6\u30ad\u30b9\u30c8\u306b\u8a18\u8f09\u3057\u3066\u3042\u308b\u30b3\u30fc\u30c9\u304c\u52d5\u304b\u306a\u3044\u5834\u5408\u306f, \u30d1\u30c3\u30b1\u30fc\u30b8\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306b\u5dee\u304c\u306a\u3044\u304b\u3092\u30c1\u30a7\u30c3\u30af\u3057\u3066\u307f\u3066\u304f\u3060\u3055\u3044. astropy == 4.2 matplotlib == 3.3 . 4 numpy == 1.20 . 1 pandas == 1.1 . 4 scipy == 1.3 . 0 tqdm == 4.59 . 0 \u3082\u3057, \u3053\u306e\u30c6\u30ad\u30b9\u30c8\u306e\u30b3\u30fc\u30c9\u304c\u6700\u65b0\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u3067\u52d5\u304b\u306a\u304b\u3063\u305f\u5834\u5408\u306b\u306f\u66f4\u65b0\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u306e\u3067\u7ba1\u7406\u8005\u307e\u3067\u304a\u77e5\u3089\u305b\u304f\u3060\u3055\u3044. \u3053\u306e\u30c6\u30ad\u30b9\u30c8\u3067\u306f\u69d8\u3005\u306a\u78ba\u7387\u5206\u5e03\u304c\u51fa\u3066\u304f\u308b\u3053\u3068\u304c\u4e88\u60f3\u3055\u308c\u308b\u306e\u3067, \u305d\u306e\u90fd\u5ea6\u65b0\u3057\u3044\u8a18\u53f7\u3092\u3042\u3066\u3066\u3044\u308b\u3068\u6587\u5b57\u304c\u67af\u6e07\u3057\u3066\u3057\u307e\u3044\u307e\u3059. \u305d\u3053\u3067\u78ba\u7387\u5909\u6570 \\(x\\) \u306e\u78ba\u7387\u5206\u5e03\u3092 \\(P(x)\\) \u3068\u8868\u8a18\u3057\u307e\u3059. \u78ba\u7387\u5909\u6570 \\(Y\\) \u306e\u78ba\u7387\u5206\u5e03\u306f \\(P(Y)\\) \u3067\u3059. \u6587\u5b57\u306f\u540c\u3058\u3067\u3082\u5f15\u6570\u304c\u5909\u308f\u308c\u3070\u9055\u3046\u78ba\u7387\u5206\u5e03\u95a2\u6570\u3092\u8868\u3057\u3066\u3044\u308b\u3068\u89e3\u91c8\u3057\u3066\u304f\u3060\u3055\u3044. \u4f8b\u5916\u306f \\(P(x)\\) \u3068 \\(P(x')\\) \u3067\u3059. \u3053\u308c\u306f\u540c\u3058\u78ba\u7387\u5206\u5e03\u95a2\u6570\u3067\u3059\u304c \\(x\\) \u3068 \\(x'\\) \u3068\u3044\u3046\u7570\u306a\u308b\u5024\u306b\u5bfe\u3059\u308b\u78ba\u7387\u306e\u5024\u3092\u8868\u3057\u3066\u3044\u308b\u3068\u89e3\u91c8\u3057\u3066\u304f\u3060\u3055\u3044. \u21a9","title":"\u306f\u3058\u3081\u306b"},{"location":"mcmc/#_1","text":"\u3053\u306e\u5b9f\u7fd2\u3067\u306f\u30de\u30eb\u30b3\u30d5\u9023\u9396\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5 (Markov-Chain Monte Carlo; MCMC ) \u3092\u3068\u308a\u3042\u3064\u304b\u3044\u307e\u3059. MCMC \u306f\u3042\u308b\u78ba\u7387\u5206\u5e03\u304b\u3089, \u78ba\u7387\u5909\u6570\u3092\u52b9\u7387\u3088\u304f\u30b5\u30f3\u30d7\u30eb\u3059\u308b\u305f\u3081\u306e\u624b\u6cd5\u306e\u3072\u3068\u3064\u3067\u3059. \u4efb\u610f\u306e\u78ba\u7387\u5206\u5e03\u306b\u5f93\u3046\u4e71\u6570\u3092\u751f\u6210\u3059\u308b\u305f\u3081\u306e\u624b\u6cd5\u3068\u8a00\u3044\u63db\u3048\u3066\u3082\u3044\u3044\u3067\u3057\u3087\u3046. \u78ba\u7387\u5909\u6570 \\(x\\) \u304c\u78ba\u7387\u5206\u5e03 \\(P(x)\\) \u306b\u5f93\u3046\u3068\u3057\u307e\u3059 1 . \u3053\u306e\u3053\u3068\u3092\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u8868\u8a18\u3057\u307e\u3059. \\[ x \\sim P(x). \\] \\(x\\) \u306f\u96e2\u6563\u5024\u3067\u3082\u9023\u7d9a\u3067\u3082\u3044\u3044\u306e\u3067\u3059\u304c, \u3053\u3053\u3067\u306f\u4fbf\u5b9c\u7684\u306b\u9023\u7d9a\u3057\u305f\u5024\u3092\u3068\u308b\u3068\u3057\u307e\u3057\u3087\u3046. \\(x\\) \u3092\u4f7f\u3063\u3066\u8a08\u7b97\u3067\u304d\u308b\u91cf \\(A(x)\\) \u306e\u671f\u5f85\u5024\u306f\u6b21\u306e\u3088\u3046\u306b\u66f8\u3051\u307e\u3059. \\[ \\left\\langle A(x) \\right\\rangle_{x \\sim P(x)} = \\int\\mathrm{d}x\\,A(x)P(x). \\] \u3082\u3057 \\(x\\) \u304c\u591a\u6b21\u5143\u306e\u91cf\u3067\u3042\u308c\u3070\u53f3\u8fba\u306e\u7a4d\u5206\u306f\u591a\u6b21\u5143\u7a7a\u9593\u3067\u306e\u7a4d\u5206\u306b\u306a\u308a\u307e\u3059. \u591a\u6b21\u5143\u3067\u306e\u7a4d\u5206\u306f\u4e00\u822c\u306b\u8a08\u7b97\u30b3\u30b9\u30c8\u304c\u9ad8\u304f\u306a\u3063\u3066\u3057\u307e\u3044\u307e\u3059. \u4e00\u65b9\u3067, \u78ba\u7387\u5206\u5e03 \\(P(x)\\) \u306b\u5f93\u3046\u78ba\u7387\u5909\u6570\u306e\u5217 \\(\\{x_i\\}_{i=1{\\ldots}n}\\) \u3092\u7528\u3044\u308b\u3068, \u53f3\u8fba\u306e\u7a4d\u5206\u3092\u4ee5\u4e0b\u306e\u548c\u306b\u3088\u3063\u3066\u8fd1\u4f3c\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \\[ \\int\\mathrm{d}x\\,A(x)P(x) \\simeq \\frac{1}{n}\\sum_{i=1}^{n} A(x_i). \\] \u3053\u308c\u306b\u3088\u3063\u3066\u3042\u3089\u3086\u308b\u91cf \\(A(x)\\) \u306e\u671f\u5f85\u5024\u3092\u307e\u3063\u305f\u304f\u540c\u3058\u624b\u7d9a\u304d\u3067\u6c42\u3081\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u307e\u305f, \\(x\\) \u304c\u96e2\u6563\u7684\u3067\u3042\u3063\u3066\u3082\u9023\u7d9a\u3067\u3042\u3063\u3066\u3082\u540c\u3058\u624b\u7d9a\u304d\u3067\u8a08\u7b97\u3092\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u3082\u3061\u308d\u3093, \u78ba\u7387\u5206\u5e03 \\(P(x)\\) \u306b\u5f93\u3046\u78ba\u7387\u5909\u6570\u306e\u5217 \\(\\{x_i\\}_{i=1{\\ldots}n}\\) \u3092\u52b9\u7387\u3088\u304f\u751f\u6210\u3059\u308b (\u78ba\u7387\u5206\u5e03 \\(P(x)\\) \u304b\u3089\u30b5\u30f3\u30d7\u30eb\u3059\u308b) \u624b\u6cd5\u304c\u3042\u308b\u3053\u3068\u304c\u524d\u63d0\u3067\u3059. \u30b5\u30f3\u30d7\u30eb\u3059\u308b\u305f\u3081\u306e\u8a08\u7b97\u30b3\u30b9\u30c8\u304c\u7a4d\u5206\u3092\u4e0a\u56de\u3063\u3066\u3057\u307e\u3063\u3066\u306f\u610f\u5473\u304c\u3042\u308a\u307e\u305b\u3093. \u305d\u3057\u3066 MCMC \u306f\u4f4e\u30b3\u30b9\u30c8\u3067\u78ba\u7387\u5206\u5e03 \\(P(x)\\) \u306b\u5f93\u3046\u78ba\u7387\u5909\u6570 \\(x\\) \u3092\u30b5\u30f3\u30d7\u30eb\u3059\u308b\u3053\u3068\u306e\u3067\u304d\u308b\u5f37\u529b\u306a\u624b\u6cd5\u3067\u3059. \u7279\u306b\u9ad8\u6b21\u5143\u7a7a\u9593\u3092\u5bfe\u8c61\u3068\u3057\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u5834\u5408\u3084, \u78ba\u7387\u5206\u5e03\u95a2\u6570\u3092\u76f4\u63a5\u8a08\u7b97\u3059\u308b\u3053\u3068\u304c\u96e3\u3057\u3044\u5834\u5408\u306b\u6d3b\u8e8d\u3057\u307e\u3059. \u4ee5\u4e0b\u3067\u306f, \u4f55\u6545 MCMC \u304c\u5fc5\u8981\u306b\u306a\u308b\u306e\u304b\u3068\u3044\u3063\u305f\u3068\u3053\u308d\u304b\u3089\u59cb\u3081\u3066, Python \u3067 MCMC \u3092\u52d5\u304b\u3059\u30b3\u30fc\u30c9\u3092\u66f8\u304d, \u3055\u307e\u3056\u307e\u306a\u554f\u984c\u306b\u9069\u7528\u3059\u308b\u3053\u3068\u3092\u76ee\u6307\u3057\u307e\u3059.","title":"\u306f\u3058\u3081\u306b"},{"location":"mcmc/#_2","text":"\u4e71\u6570\u751f\u6210 \u2013 \u9006\u95a2\u6570\u6cd5\u3068\u68c4\u5374\u6cd5 \u9759\u7684\u306a\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5\u306b\u3088\u308b\u8a08\u7b97 \u52d5\u7684\u306a\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5 \u2013 \u30de\u30eb\u30b3\u30d5\u9023\u9396\u306b\u3088\u308b\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0 Metropolis-Hastings \u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306b\u3088\u308b MCMC \u5b9f\u8df5 \u30de\u30eb\u30b3\u30d5\u9023\u9396\u306e\u53ce\u675f\u306b\u95a2\u3059\u308b\u3042\u308c\u3053\u308c \u6f14\u7fd2\u554f\u984c: \u7dda\u5f62\u56de\u5e30 \u6f14\u7fd2\u554f\u984c: \u6253\u3061\u5207\u308a\u56de\u5e30\u30e2\u30c7\u30eb","title":"\u30b3\u30f3\u30c6\u30f3\u30c4"},{"location":"mcmc/#_3","text":"\u3053\u306e\u30c6\u30ad\u30b9\u30c8\u306e\u5185\u5bb9\u306f Python 3.7.1 \u3092\u30d9\u30fc\u30b9\u306b\u4f5c\u6210\u3055\u308c\u3066\u3044\u307e\u3059. \u4f7f\u7528\u3057\u3066\u3044\u308b\u30d1\u30c3\u30b1\u30fc\u30b8\u306f\u4ee5\u4e0b\u306e\u3068\u304a\u308a\u3067\u3059. \u3082\u3057\u30c6\u30ad\u30b9\u30c8\u306b\u8a18\u8f09\u3057\u3066\u3042\u308b\u30b3\u30fc\u30c9\u304c\u52d5\u304b\u306a\u3044\u5834\u5408\u306f, \u30d1\u30c3\u30b1\u30fc\u30b8\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306b\u5dee\u304c\u306a\u3044\u304b\u3092\u30c1\u30a7\u30c3\u30af\u3057\u3066\u307f\u3066\u304f\u3060\u3055\u3044. astropy == 4.2 matplotlib == 3.3 . 4 numpy == 1.20 . 1 pandas == 1.1 . 4 scipy == 1.3 . 0 tqdm == 4.59 . 0 \u3082\u3057, \u3053\u306e\u30c6\u30ad\u30b9\u30c8\u306e\u30b3\u30fc\u30c9\u304c\u6700\u65b0\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u3067\u52d5\u304b\u306a\u304b\u3063\u305f\u5834\u5408\u306b\u306f\u66f4\u65b0\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u306e\u3067\u7ba1\u7406\u8005\u307e\u3067\u304a\u77e5\u3089\u305b\u304f\u3060\u3055\u3044. \u3053\u306e\u30c6\u30ad\u30b9\u30c8\u3067\u306f\u69d8\u3005\u306a\u78ba\u7387\u5206\u5e03\u304c\u51fa\u3066\u304f\u308b\u3053\u3068\u304c\u4e88\u60f3\u3055\u308c\u308b\u306e\u3067, \u305d\u306e\u90fd\u5ea6\u65b0\u3057\u3044\u8a18\u53f7\u3092\u3042\u3066\u3066\u3044\u308b\u3068\u6587\u5b57\u304c\u67af\u6e07\u3057\u3066\u3057\u307e\u3044\u307e\u3059. \u305d\u3053\u3067\u78ba\u7387\u5909\u6570 \\(x\\) \u306e\u78ba\u7387\u5206\u5e03\u3092 \\(P(x)\\) \u3068\u8868\u8a18\u3057\u307e\u3059. \u78ba\u7387\u5909\u6570 \\(Y\\) \u306e\u78ba\u7387\u5206\u5e03\u306f \\(P(Y)\\) \u3067\u3059. \u6587\u5b57\u306f\u540c\u3058\u3067\u3082\u5f15\u6570\u304c\u5909\u308f\u308c\u3070\u9055\u3046\u78ba\u7387\u5206\u5e03\u95a2\u6570\u3092\u8868\u3057\u3066\u3044\u308b\u3068\u89e3\u91c8\u3057\u3066\u304f\u3060\u3055\u3044. \u4f8b\u5916\u306f \\(P(x)\\) \u3068 \\(P(x')\\) \u3067\u3059. \u3053\u308c\u306f\u540c\u3058\u78ba\u7387\u5206\u5e03\u95a2\u6570\u3067\u3059\u304c \\(x\\) \u3068 \\(x'\\) \u3068\u3044\u3046\u7570\u306a\u308b\u5024\u306b\u5bfe\u3059\u308b\u78ba\u7387\u306e\u5024\u3092\u8868\u3057\u3066\u3044\u308b\u3068\u89e3\u91c8\u3057\u3066\u304f\u3060\u3055\u3044. \u21a9","title":"\u52d5\u4f5c\u74b0\u5883"},{"location":"mcmc/censored_regression/","text":"\u6f14\u7fd2\u554f\u984c: \u6253\u3061\u5207\u308a\u56de\u5e30\u30e2\u30c7\u30eb \u3053\u3053\u3067\u306f\u8d85\u5927\u8cea\u91cf\u30d6\u30e9\u30c3\u30af\u30db\u30fc\u30eb (supermassive blackhole) \u3068, \u9280\u6cb3\u30d0\u30eb\u30b8 (bulge) \u306e\u901f\u5ea6\u5206\u6563\u306e\u95a2\u4fc2\u306b\u5c11\u3057\u624b\u3092\u52a0\u3048\u305f\u30c7\u30fc\u30bf\u3092\u4f7f\u7528\u3057\u307e\u3059. \u5929\u6587\u5b66\u306b\u9650\u3089\u305a, \u5b9f\u9a13\u306b\u3088\u3063\u3066\u5f97\u3089\u308c\u308b\u30c7\u30fc\u30bf\u306f\u88c5\u7f6e\u6027\u80fd\u306e\u9650\u754c\u3084\u5b9f\u9a13\u6642\u9593\u306e\u9650\u754c\u306a\u3069\u306b\u3088\u3063\u3066\u4e00\u90e8\u3057\u304b\u30c7\u30fc\u30bf\u304c\u53d6\u5f97\u3067\u304d\u306a\u3044\u3053\u3068\u304c\u3088\u304f\u3042\u308a\u307e\u3059. \u3053\u3053\u3067\u306f\u305d\u306e\u3088\u3046\u306a\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u9069\u7528\u3059\u308b\u3053\u3068\u306e\u3067\u304d\u308b\u6253\u3061\u5207\u308a\u56de\u5e30\u30e2\u30c7\u30eb (censored regression) \u3092 \u30c7\u30fc\u30bf \u540c\u3058\u304f Harris et al. (2013) \u306e \u30ab\u30bf\u30ed\u30b0 \u3092\u5229\u7528\u3057\u307e\u3059. \u305f\u3060\u3057\u4eca\u56de\u306f\u30d6\u30e9\u30c3\u30af\u30db\u30fc\u30eb\u8cea\u91cf\u304c \\(10^{8.5}M_\\odot\\) \u672a\u6e80\u306e\u5929\u4f53\u306f\u691c\u51fa\u9650\u754c\u4ee5\u4e0b\u3060\u3063\u305f\u3068\u4eee\u5b9a\u3057\u3066\u5024\u3092 0 \u306b\u6539\u5909\u3057\u3066\u3044\u307e\u3059. \u6f14\u7fd2\u7528\u306b\u6574\u5f62\u3057\u305f\u30c7\u30fc\u30bf\u3092\u4ee5\u4e0b\u304b\u3089\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u304f\u3060\u3055\u3044. \u30d5\u30a1\u30a4\u30eb\u540d \u5f62\u5f0f exercise_censored_regression.csv csv \u30c7\u30fc\u30bf\u30c6\u30fc\u30d6\u30eb\u306b\u306f\u4ee5\u4e0b\u306e\u30ab\u30e9\u30e0\u304c\u542b\u307e\u308c\u3066\u3044\u307e\u3059. \u30ab\u30e9\u30e0\u540d \u8aac\u660e galaxy \u9280\u6cb3\u540d/\u30ab\u30bf\u30ed\u30b0 ID 1 ra \u8d64\u7d4c\u5ea7\u6a19 (J2000) 1 dec \u8d64\u7def\u5ea7\u6a19 (J2000) 1 dist \u8ddd\u96e2 (Mpc) 1 dist_err \u8ddd\u96e2\u306e\u4e0d\u5b9a\u6027 (Mpc) 1 logsig \u9280\u6cb3\u30d0\u30eb\u30b8\u306e\u901f\u5ea6\u5206\u6563 (\u5bfe\u6570) \\(\\log_{10}\\sigma_e\\) (km/s) logsig_err \u9280\u6cb3\u30d0\u30eb\u30b8\u306e\u901f\u5ea6\u5206\u6563\u306e\u4e0d\u5b9a\u6027 \\(\\varepsilon_\\sigma\\) logM_B \u8d85\u5927\u8cea\u91cf\u30d6\u30e9\u30c3\u30af\u30db\u30fc\u30eb\u306e\u8cea\u91cf (\u5bfe\u6570) \\(\\log_{10}{M_B}\\) ( \\({M_\\odot}\\) ) logM_B_err \u8d85\u5927\u8cea\u91cf\u30d6\u30e9\u30c3\u30af\u30db\u30fc\u30eb\u306e\u8cea\u91cf\u306e\u4e0d\u5b9a\u6027 \\(\\varepsilon_M\\) \u307e\u305a\u306f\u30c7\u30fc\u30bf\u306e\u95a2\u4fc2\u3092\u56f3\u793a\u3057\u307e\u3059. import numpy as np import pandas as pd import matplotlib.pyplot as plt table = pd . read_csv ( './exercise_linear_regression.csv' ) print ( table ) fig = plt . figure () ax = fig . add_subplot () ax . errorbar ( x = table . logsig , y = table . logM_B , xerr = table . logsig_err , yerr = table . logM_B_err , fmt = '.' ) ax . set_xlabel ( '$\\log_ {10} \\sigma_e$ (km/s)' ) ax . set_ylabel ( '$\\log_ {10} M_B$ ($M_\\odot$)' ) fig . tight_layout () plt . show () \u8a08\u7b97\u7d50\u679c galaxy ra dec dist dist_err logsig logsig_err logM_B logM_B_err 0 MilkyWay 0.000000 0.000000 0.00 0.00 2.021 0.076 0.00 0.000 1 NGC221 0.711607 40.865165 0.76 0.07 1.875 0.017 0.00 0.000 2 NGC224 0.712316 41.268883 0.77 0.02 2.204 0.021 0.00 0.000 3 NGC253 0.792531 -25.288442 3.54 0.20 2.011 0.073 0.00 0.000 4 NGC821 2.139199 10.995008 23.38 1.24 2.320 0.020 0.00 0.000 5 NGC1023 2.673329 39.063253 11.43 1.00 2.320 0.020 0.00 0.000 6 NGC1316 3.378256 -37.208211 21.09 0.30 2.357 0.006 0.00 0.000 7 NGC1332 3.438111 -21.335276 22.91 0.20 2.506 0.018 9.17 0.060 8 NGC1399 3.641408 -35.450626 20.68 0.50 2.528 0.020 8.69 0.065 9 NGC2778 9.206775 35.027417 22.91 3.39 2.243 0.019 0.00 0.000 10 NGC3031 9.925869 69.065438 3.55 0.07 2.155 0.021 0.00 0.000 11 NGC3115 10.087214 -7.718556 10.00 0.50 2.362 0.020 8.96 0.170 12 NGC3377 10.795104 13.985641 11.04 0.25 2.161 0.020 0.00 0.000 13 NGC3379 10.797108 12.581611 10.20 0.50 2.314 0.021 0.00 0.000 14 NGC3384 10.804699 12.629401 10.80 0.77 2.155 0.021 0.00 0.000 15 NGC3414 10.854492 27.974833 25.23 4.14 2.374 0.014 0.00 0.000 16 NGC3585 11.221418 -26.754864 21.20 1.73 2.328 0.020 8.51 0.140 17 NGC3607 11.281816 18.051899 20.00 2.00 2.360 0.020 0.00 0.000 18 NGC3608 11.283036 18.148538 23.00 2.00 2.260 0.021 8.67 0.095 19 NGC3842 11.733936 19.949696 94.90 6.70 2.498 0.011 9.99 0.125 20 NGC4261 12.323060 5.825041 31.62 2.89 2.498 0.020 8.71 0.085 21 NGC4291 12.338247 75.370944 26.18 4.16 2.384 0.021 8.98 0.140 22 NGC4350 12.399394 16.693471 15.50 0.78 2.256 0.017 8.74 0.100 23 NGC4374 12.417685 12.887071 18.51 0.61 2.471 0.020 8.96 0.045 24 NGC4459 12.483339 13.978556 16.01 0.55 2.223 0.020 0.00 0.000 25 NGC4472 12.496331 8.000389 17.03 0.21 2.468 0.004 9.26 0.150 26 NGC4473 12.496907 13.429397 15.25 0.51 2.279 0.020 0.00 0.000 27 NGC4486 12.513724 12.391217 17.00 0.30 2.574 0.020 9.77 0.030 28 NGC4486A 12.516033 12.270333 18.36 0.64 2.045 0.019 0.00 0.000 29 NGC4552 12.594402 12.556115 15.89 0.55 2.402 0.006 8.68 0.045 30 NGC4564 12.607493 11.439400 15.87 0.53 2.210 0.021 0.00 0.000 31 NGC4594 12.666513 -11.623010 9.77 0.84 2.380 0.021 8.72 0.435 32 NGC4621 12.700637 11.647308 14.85 0.50 2.352 0.006 8.60 0.065 33 NGC4649 12.727789 11.552672 17.09 0.61 2.585 0.021 9.63 0.100 34 NGC4697 12.809995 -5.800602 12.01 0.78 2.248 0.019 0.00 0.000 35 NGC4889 13.002237 27.977031 96.60 6.80 2.603 0.006 10.32 0.435 36 NGC5128 13.424479 -43.018118 3.80 0.07 2.176 0.020 0.00 0.000 37 IC4296 13.610847 -33.965822 49.68 2.73 2.508 0.021 9.13 0.065 38 NGC5813 15.019805 1.702009 32.21 2.78 2.374 0.006 8.84 0.070 39 NGC5845 15.100215 1.633972 25.94 2.63 2.369 0.020 8.69 0.140 40 NGC5846 15.108124 1.606291 24.89 2.40 2.379 0.008 9.04 0.080 41 NGC6086 16.209883 29.484478 137.30 9.60 2.524 0.012 9.56 0.160 42 NGC7332 22.623476 23.798260 23.01 2.22 2.097 0.011 0.00 0.000 43 IC1459 22.952945 -36.462176 29.24 4.02 2.486 0.011 9.45 0.195 44 NGC7457 23.016647 30.144889 13.24 1.34 1.826 0.019 0.00 0.000 45 NGC7768 23.849610 27.147336 112.10 7.90 2.495 0.021 9.11 0.150 \u6253\u3061\u5207\u308a\u56de\u5e30\u30e2\u30c7\u30eb \u7dda\u5f62\u56de\u5e30\u306e\u5834\u5408 \u3068\u540c\u69d8\u306b Harris et al. (2013) \u3092\u53c2\u8003\u306b\u3057\u3066\u4ee5\u4e0b\u306e\u5f0f\u3092 fitting \u306e\u95a2\u6570\u3068\u3057\u3066\u63a1\u7528\u3057\u307e\u3059. \u305f\u3060\u3057 \\(\\sigma_0\\) \u306f 200 km/s \u3068\u3057\u307e\u3059. \\[ \\log_{10} \\frac{M_B}{M_\\odot} = \\alpha + \\beta \\log_{10}\\frac{\\sigma_e}{\\sigma_0}. \\] \u89b3\u6e2c\u5024\u304c\u6709\u52b9\u306a\u5834\u5408\u306b\u306f\u6b63\u898f\u5206\u5e03\u3092\u4eee\u5b9a\u3057\u305f\u5c24\u5ea6\u95a2\u6570\u3092\u4f7f\u7528\u3057\u307e\u3059. 1 2 \\[ \\begin{aligned} \\log{L}_i(\\alpha,\\beta,\\varepsilon; D) = -\\frac{\\Delta_i^2}{2S_i^2} -\\frac{1}{2}\\log{S_i^2} \\qquad\\qquad\\\\ \\left\\{\\begin{aligned} \\Delta_i &= \\log_{10}{M_{B,i}} - \\alpha - \\beta\\log_{10}\\sigma_{e,i}, \\\\ S_i^2 &= {\\varepsilon_{M,i}}^2 + \\beta^2{\\varepsilon_{\\sigma,i}}^2 + \\varepsilon^2, \\\\ \\tau~ &= \\varepsilon^{-2}. \\end{aligned}\\right. \\end{aligned} \\] \u89b3\u6e2c\u5024\u304c\u7121\u52b9\u306a\u5834\u5408\u306b\u3082\u6b63\u898f\u5206\u5e03\u3092\u4eee\u5b9a\u3057\u305f\u78ba\u7387\u3092\u4f7f\u7528\u3057\u307e\u3059. \u305f\u3060\u3057, \u691c\u51fa\u9650\u754c (\u4eca\u56de\u306f \\(10^{8.5}M_\\odot\\) ) \u4ee5\u4e0b\u3067\u3042\u308b\u78ba\u7387\u3092\u4f7f\u3044\u307e\u3059. \\[ \\log\\tilde{L}_i(\\alpha,\\beta,\\varepsilon; D) = -\\log{C}(M_\\mathrm{lim},\\alpha+\\beta\\log_{10}\\sigma_{e,i},S_i). \\] \u3053\u3053\u3067 \\(C(m,\\mu,\\sigma)\\) \u306f\u6b63\u898f\u5206\u5e03\u306e\u7d2f\u7a4d\u78ba\u7387\u5206\u5e03\u95a2\u6570, \\(M_\\mathrm{lim}\\) \u306f\u691c\u51fa\u9650\u754c\u8cea\u91cf\u3067\u3059. \u5168\u30c7\u30fc\u30bf\u306b\u3064\u3044\u3066\u5408\u8a08\u3057\u305f\u5c24\u5ea6\u95a2\u6570\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u306a\u308a\u307e\u3059. \\[ \\log{L}(\\alpha,\\beta,\\varepsilon; D) = \\sum_{i=1}^n \\left(v_i\\log{L_i} + (1-v_i)\\log\\tilde{L}_i\\right) + \\log{\\operatorname{Gamma}(\\tau, k, \\theta)}. \\] \\(\\tau\\) \u306b\u3064\u3044\u3066\u306e\u4e8b\u524d\u5206\u5e03\u3068\u3057\u3066 Gamma \u5206\u5e03\u3092\u4eee\u5b9a\u3057\u307e\u3057\u305f. \u6253\u3061\u5207\u308a\u30c7\u30fc\u30bf\u3092\u6392\u9664\u3059\u308b \u6253\u3061\u5207\u308a\u30c7\u30fc\u30bf\u3092\u542b\u3081\u306a\u3044\u3067\u89e3\u6790\u3057\u305f\u5834\u5408\u306b\u3069\u306e\u3088\u3046\u306a\u7d50\u679c\u306b\u306a\u308b\u304b\u3092\u8a08\u7b97\u3057\u3066\u304f\u3060\u3055\u3044. Example import numpy as np import pandas as pd import scipy.stats as stats import matplotlib.pyplot as plt from mhmcmc import MHMCMCSampler , GaussianStep table = pd . read_csv ( './exercise_censored_regression.csv' ) table = table . loc [ table . logM_B > 0 ,:] def log_gamma ( x , k = 1e-3 , t = 1e3 ): return ( k - 1 ) * np . log ( x ) - x / t if x > 0 else - 1e10 def log_likelihood ( x ): if x [ 2 ] < 0 : return - 1e10 delta = table . logM_B - ( x [ 0 ] + x [ 1 ] * ( table . logsig - np . log10 ( 200 ))) sqsig = table . logM_B_err ** 2 + x [ 1 ] ** 2 * table . logsig_err ** 2 + x [ 2 ] logpdf = - ( delta ** 2 / sqsig / 2 + np . log ( sqsig ) / 2 ) return np . sum ( logpdf ) + log_gamma ( 1 / x [ 2 ]) step = GaussianStep ( np . array ([ 0.02 , 0.15 , 0.05 ])) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . array ([ 8.0 , 5.0 , 0.5 ]) model . initialize ( x0 ) sample = model . generate ( 51000 ) sample = sample [ 1000 :] sample [:, 2 ] = np . sqrt ( sample [:, 2 ]) x = np . linspace ( - 0.5 , 0.5 , 50 ) a , b , e = sample . mean ( axis = 0 ) fig = plt . figure ( figsize = ( 8 , 6 )) ax = fig . add_subplot () ax . fill_between ( x , a + b * x - 3 * e , a + b * x + 3 * e , color = 'gray' , alpha = 0.05 ) ax . fill_between ( x , a + b * x - e , a + b * x + e , color = 'gray' , alpha = 0.10 ) for _a , _b , _e in sample [:: 1000 ,:]: ax . plot ( x , _a + _b * x , color = 'orange' , alpha = 0.05 ) ax . errorbar ( x = table . logsig - np . log10 ( 200 ), y = table . logM_B , xerr = table . logsig_err , yerr = table . logM_B_err , fmt = '.' ) ax . plot ( x , a + b * x ) ax . set_xlabel ( '$\\log_ {10} \\sigma_e$ (km/s)' ) ax . set_ylabel ( '$\\log_ {10} M_B$ ($M_\\odot$)' ) fig . tight_layout () plt . show () print ( f 'MCMC inference: alpha= { a : .3f } , beta= { b : .3f } , epsilon= { e : .3f } ' ) \u8a08\u7b97\u7d50\u679c MCMC inference: alpha=8.612, beta=3.274, epsilon=0.345 1-\u03c3, 3-\u03c3 \u306e\u4e0d\u5b9a\u6027\u3092\u30b0\u30ec\u30fc\u306e\u9818\u57df\u3067\u8868\u3057\u3066\u3044\u307e\u3059. \u53c2\u8003\u307e\u3067\u306b\u4e0a\u8a18\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u51fa\u529b\u3057\u305f\u30c8\u30ec\u30fc\u30b9\u3068\u81ea\u5df1\u76f8\u95a2\u95a2\u6570\u3092\u793a\u3057\u307e\u3059. \u6253\u3061\u5207\u308a\u30c7\u30fc\u30bf\u3092\u542b\u3081\u308b \u6253\u3061\u5207\u308a\u30c7\u30fc\u30bf\u3092\u542b\u3081\u3066\u89e3\u6790\u3057\u305f\u5834\u5408\u306b\u3069\u306e\u3088\u3046\u306a\u7d50\u679c\u306b\u306a\u308b\u304b\u8a08\u7b97\u3057\u3066\u304f\u3060\u3055\u3044. Example import numpy as np import pandas as pd import scipy.stats as stats import matplotlib.pyplot as plt from mhmcmc import MHMCMCSampler , GaussianStep table = pd . read_csv ( '../../data/mcmc/exercise_censored_regression.csv' ) def log_gamma ( x , k , t ): return ( k - 1 ) * np . log ( x ) - x / t if x > 0 else - 1e10 def log_likelihood ( x ): valid = ( table . logM_B > 0.0 ) beta = x [ 0 ] + x [ 1 ] * ( table . logsig - np . log10 ( 200 )) delta = table . logM_B - beta sqsig = table . logM_B_err ** 2 + x [ 1 ] ** 2 * table . logsig_err ** 2 + x [ 2 ] if ( sqsig < 0 ) . any (): return - 1e10 logpdf = - ( delta ** 2 / sqsig / 2 + np . log ( sqsig ) / 2 ) logcdf = stats . norm . logcdf ( 8.0 , beta , np . sqrt ( sqsig )) return np . sum ( valid * logpdf + ( 1 - valid ) * logcdf ) + log_gamma ( 1 / x [ 2 ], 1e-3 , 1e3 ) step = GaussianStep ( np . array ([ 0.02 , 0.15 , 0.05 ])) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . array ([ 8.0 , 5.0 , 0.5 ]) model . initialize ( x0 ) sample = model . generate ( 51000 ) sample = sample [ 1000 :] sample [:, 2 ] = np . sqrt ( sample [:, 2 ]) x = np . linspace ( - 0.5 , 0.5 , 50 ) a , b , e = sample . mean ( axis = 0 ) fig = plt . figure ( figsize = ( 8 , 6 )) ax = fig . add_subplot () ax . fill_between ( x , a + b * x - 3 * e , a + b * x + 3 * e , color = 'gray' , alpha = 0.05 ) ax . fill_between ( x , a + b * x - e , a + b * x + e , color = 'gray' , alpha = 0.10 ) for _a , _b , _e in sample [:: 1000 ,:]: ax . plot ( x , _a + _b * x , color = 'orange' , alpha = 0.05 ) ax . errorbar ( x = table . logsig - np . log10 ( 200 ), y = table . logM_B , xerr = table . logsig_err , yerr = table . logM_B_err , fmt = '.' ) ax . plot ( x , a + b * x ) ax . set_xlabel ( '$\\log_ {10} \\sigma_e$ (km/s)' ) ax . set_ylabel ( '$\\log_ {10} M_B$ ($M_\\odot$)' ) fig . tight_layout () plt . show () print ( f 'MCMC inference: alpha= { a : .3f } , beta= { b : .3f } , epsilon= { e : .3f } ' ) \u8a08\u7b97\u7d50\u679c MCMC inference: alpha=7.920, beta=6.743, epsilon=0.573 1-\u03c3, 3-\u03c3 \u306e\u4e0d\u5b9a\u6027\u3092\u30b0\u30ec\u30fc\u306e\u9818\u57df\u3067\u8868\u3057\u3066\u3044\u307e\u3059. \u53c2\u8003\u307e\u3067\u306b\u4e0a\u8a18\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u51fa\u529b\u3057\u305f\u30c8\u30ec\u30fc\u30b9\u3068\u81ea\u5df1\u76f8\u95a2\u95a2\u6570\u3092\u793a\u3057\u307e\u3059. \\(\\log{L}_i(\\alpha,\\beta; D)\\) \u306f \\(i\\) \u756a\u76ee\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u5bfe\u6570\u5c24\u5ea6\u3067\u3059. \u21a9 \u21a9 \u21a9 \u21a9 \u21a9 \u21a9 \u4ee5\u4e0b \\(\\sigma_{e,i}\\) \u306f \\(\\sigma_0\\) \u3067\u898f\u683c\u5316\u3055\u308c\u305f\u5024\u3068\u3057\u3066\u6271\u3044\u307e\u3059. \u21a9","title":"\u6f14\u7fd2\u554f\u984c: \u6253\u3061\u5207\u308a\u56de\u5e30\u30e2\u30c7\u30eb"},{"location":"mcmc/censored_regression/#_1","text":"\u3053\u3053\u3067\u306f\u8d85\u5927\u8cea\u91cf\u30d6\u30e9\u30c3\u30af\u30db\u30fc\u30eb (supermassive blackhole) \u3068, \u9280\u6cb3\u30d0\u30eb\u30b8 (bulge) \u306e\u901f\u5ea6\u5206\u6563\u306e\u95a2\u4fc2\u306b\u5c11\u3057\u624b\u3092\u52a0\u3048\u305f\u30c7\u30fc\u30bf\u3092\u4f7f\u7528\u3057\u307e\u3059. \u5929\u6587\u5b66\u306b\u9650\u3089\u305a, \u5b9f\u9a13\u306b\u3088\u3063\u3066\u5f97\u3089\u308c\u308b\u30c7\u30fc\u30bf\u306f\u88c5\u7f6e\u6027\u80fd\u306e\u9650\u754c\u3084\u5b9f\u9a13\u6642\u9593\u306e\u9650\u754c\u306a\u3069\u306b\u3088\u3063\u3066\u4e00\u90e8\u3057\u304b\u30c7\u30fc\u30bf\u304c\u53d6\u5f97\u3067\u304d\u306a\u3044\u3053\u3068\u304c\u3088\u304f\u3042\u308a\u307e\u3059. \u3053\u3053\u3067\u306f\u305d\u306e\u3088\u3046\u306a\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u9069\u7528\u3059\u308b\u3053\u3068\u306e\u3067\u304d\u308b\u6253\u3061\u5207\u308a\u56de\u5e30\u30e2\u30c7\u30eb (censored regression) \u3092","title":"\u6f14\u7fd2\u554f\u984c: \u6253\u3061\u5207\u308a\u56de\u5e30\u30e2\u30c7\u30eb"},{"location":"mcmc/censored_regression/#_2","text":"\u540c\u3058\u304f Harris et al. (2013) \u306e \u30ab\u30bf\u30ed\u30b0 \u3092\u5229\u7528\u3057\u307e\u3059. \u305f\u3060\u3057\u4eca\u56de\u306f\u30d6\u30e9\u30c3\u30af\u30db\u30fc\u30eb\u8cea\u91cf\u304c \\(10^{8.5}M_\\odot\\) \u672a\u6e80\u306e\u5929\u4f53\u306f\u691c\u51fa\u9650\u754c\u4ee5\u4e0b\u3060\u3063\u305f\u3068\u4eee\u5b9a\u3057\u3066\u5024\u3092 0 \u306b\u6539\u5909\u3057\u3066\u3044\u307e\u3059. \u6f14\u7fd2\u7528\u306b\u6574\u5f62\u3057\u305f\u30c7\u30fc\u30bf\u3092\u4ee5\u4e0b\u304b\u3089\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u304f\u3060\u3055\u3044. \u30d5\u30a1\u30a4\u30eb\u540d \u5f62\u5f0f exercise_censored_regression.csv csv \u30c7\u30fc\u30bf\u30c6\u30fc\u30d6\u30eb\u306b\u306f\u4ee5\u4e0b\u306e\u30ab\u30e9\u30e0\u304c\u542b\u307e\u308c\u3066\u3044\u307e\u3059. \u30ab\u30e9\u30e0\u540d \u8aac\u660e galaxy \u9280\u6cb3\u540d/\u30ab\u30bf\u30ed\u30b0 ID 1 ra \u8d64\u7d4c\u5ea7\u6a19 (J2000) 1 dec \u8d64\u7def\u5ea7\u6a19 (J2000) 1 dist \u8ddd\u96e2 (Mpc) 1 dist_err \u8ddd\u96e2\u306e\u4e0d\u5b9a\u6027 (Mpc) 1 logsig \u9280\u6cb3\u30d0\u30eb\u30b8\u306e\u901f\u5ea6\u5206\u6563 (\u5bfe\u6570) \\(\\log_{10}\\sigma_e\\) (km/s) logsig_err \u9280\u6cb3\u30d0\u30eb\u30b8\u306e\u901f\u5ea6\u5206\u6563\u306e\u4e0d\u5b9a\u6027 \\(\\varepsilon_\\sigma\\) logM_B \u8d85\u5927\u8cea\u91cf\u30d6\u30e9\u30c3\u30af\u30db\u30fc\u30eb\u306e\u8cea\u91cf (\u5bfe\u6570) \\(\\log_{10}{M_B}\\) ( \\({M_\\odot}\\) ) logM_B_err \u8d85\u5927\u8cea\u91cf\u30d6\u30e9\u30c3\u30af\u30db\u30fc\u30eb\u306e\u8cea\u91cf\u306e\u4e0d\u5b9a\u6027 \\(\\varepsilon_M\\) \u307e\u305a\u306f\u30c7\u30fc\u30bf\u306e\u95a2\u4fc2\u3092\u56f3\u793a\u3057\u307e\u3059. import numpy as np import pandas as pd import matplotlib.pyplot as plt table = pd . read_csv ( './exercise_linear_regression.csv' ) print ( table ) fig = plt . figure () ax = fig . add_subplot () ax . errorbar ( x = table . logsig , y = table . logM_B , xerr = table . logsig_err , yerr = table . logM_B_err , fmt = '.' ) ax . set_xlabel ( '$\\log_ {10} \\sigma_e$ (km/s)' ) ax . set_ylabel ( '$\\log_ {10} M_B$ ($M_\\odot$)' ) fig . tight_layout () plt . show () \u8a08\u7b97\u7d50\u679c galaxy ra dec dist dist_err logsig logsig_err logM_B logM_B_err 0 MilkyWay 0.000000 0.000000 0.00 0.00 2.021 0.076 0.00 0.000 1 NGC221 0.711607 40.865165 0.76 0.07 1.875 0.017 0.00 0.000 2 NGC224 0.712316 41.268883 0.77 0.02 2.204 0.021 0.00 0.000 3 NGC253 0.792531 -25.288442 3.54 0.20 2.011 0.073 0.00 0.000 4 NGC821 2.139199 10.995008 23.38 1.24 2.320 0.020 0.00 0.000 5 NGC1023 2.673329 39.063253 11.43 1.00 2.320 0.020 0.00 0.000 6 NGC1316 3.378256 -37.208211 21.09 0.30 2.357 0.006 0.00 0.000 7 NGC1332 3.438111 -21.335276 22.91 0.20 2.506 0.018 9.17 0.060 8 NGC1399 3.641408 -35.450626 20.68 0.50 2.528 0.020 8.69 0.065 9 NGC2778 9.206775 35.027417 22.91 3.39 2.243 0.019 0.00 0.000 10 NGC3031 9.925869 69.065438 3.55 0.07 2.155 0.021 0.00 0.000 11 NGC3115 10.087214 -7.718556 10.00 0.50 2.362 0.020 8.96 0.170 12 NGC3377 10.795104 13.985641 11.04 0.25 2.161 0.020 0.00 0.000 13 NGC3379 10.797108 12.581611 10.20 0.50 2.314 0.021 0.00 0.000 14 NGC3384 10.804699 12.629401 10.80 0.77 2.155 0.021 0.00 0.000 15 NGC3414 10.854492 27.974833 25.23 4.14 2.374 0.014 0.00 0.000 16 NGC3585 11.221418 -26.754864 21.20 1.73 2.328 0.020 8.51 0.140 17 NGC3607 11.281816 18.051899 20.00 2.00 2.360 0.020 0.00 0.000 18 NGC3608 11.283036 18.148538 23.00 2.00 2.260 0.021 8.67 0.095 19 NGC3842 11.733936 19.949696 94.90 6.70 2.498 0.011 9.99 0.125 20 NGC4261 12.323060 5.825041 31.62 2.89 2.498 0.020 8.71 0.085 21 NGC4291 12.338247 75.370944 26.18 4.16 2.384 0.021 8.98 0.140 22 NGC4350 12.399394 16.693471 15.50 0.78 2.256 0.017 8.74 0.100 23 NGC4374 12.417685 12.887071 18.51 0.61 2.471 0.020 8.96 0.045 24 NGC4459 12.483339 13.978556 16.01 0.55 2.223 0.020 0.00 0.000 25 NGC4472 12.496331 8.000389 17.03 0.21 2.468 0.004 9.26 0.150 26 NGC4473 12.496907 13.429397 15.25 0.51 2.279 0.020 0.00 0.000 27 NGC4486 12.513724 12.391217 17.00 0.30 2.574 0.020 9.77 0.030 28 NGC4486A 12.516033 12.270333 18.36 0.64 2.045 0.019 0.00 0.000 29 NGC4552 12.594402 12.556115 15.89 0.55 2.402 0.006 8.68 0.045 30 NGC4564 12.607493 11.439400 15.87 0.53 2.210 0.021 0.00 0.000 31 NGC4594 12.666513 -11.623010 9.77 0.84 2.380 0.021 8.72 0.435 32 NGC4621 12.700637 11.647308 14.85 0.50 2.352 0.006 8.60 0.065 33 NGC4649 12.727789 11.552672 17.09 0.61 2.585 0.021 9.63 0.100 34 NGC4697 12.809995 -5.800602 12.01 0.78 2.248 0.019 0.00 0.000 35 NGC4889 13.002237 27.977031 96.60 6.80 2.603 0.006 10.32 0.435 36 NGC5128 13.424479 -43.018118 3.80 0.07 2.176 0.020 0.00 0.000 37 IC4296 13.610847 -33.965822 49.68 2.73 2.508 0.021 9.13 0.065 38 NGC5813 15.019805 1.702009 32.21 2.78 2.374 0.006 8.84 0.070 39 NGC5845 15.100215 1.633972 25.94 2.63 2.369 0.020 8.69 0.140 40 NGC5846 15.108124 1.606291 24.89 2.40 2.379 0.008 9.04 0.080 41 NGC6086 16.209883 29.484478 137.30 9.60 2.524 0.012 9.56 0.160 42 NGC7332 22.623476 23.798260 23.01 2.22 2.097 0.011 0.00 0.000 43 IC1459 22.952945 -36.462176 29.24 4.02 2.486 0.011 9.45 0.195 44 NGC7457 23.016647 30.144889 13.24 1.34 1.826 0.019 0.00 0.000 45 NGC7768 23.849610 27.147336 112.10 7.90 2.495 0.021 9.11 0.150","title":"\u30c7\u30fc\u30bf"},{"location":"mcmc/censored_regression/#_3","text":"\u7dda\u5f62\u56de\u5e30\u306e\u5834\u5408 \u3068\u540c\u69d8\u306b Harris et al. (2013) \u3092\u53c2\u8003\u306b\u3057\u3066\u4ee5\u4e0b\u306e\u5f0f\u3092 fitting \u306e\u95a2\u6570\u3068\u3057\u3066\u63a1\u7528\u3057\u307e\u3059. \u305f\u3060\u3057 \\(\\sigma_0\\) \u306f 200 km/s \u3068\u3057\u307e\u3059. \\[ \\log_{10} \\frac{M_B}{M_\\odot} = \\alpha + \\beta \\log_{10}\\frac{\\sigma_e}{\\sigma_0}. \\] \u89b3\u6e2c\u5024\u304c\u6709\u52b9\u306a\u5834\u5408\u306b\u306f\u6b63\u898f\u5206\u5e03\u3092\u4eee\u5b9a\u3057\u305f\u5c24\u5ea6\u95a2\u6570\u3092\u4f7f\u7528\u3057\u307e\u3059. 1 2 \\[ \\begin{aligned} \\log{L}_i(\\alpha,\\beta,\\varepsilon; D) = -\\frac{\\Delta_i^2}{2S_i^2} -\\frac{1}{2}\\log{S_i^2} \\qquad\\qquad\\\\ \\left\\{\\begin{aligned} \\Delta_i &= \\log_{10}{M_{B,i}} - \\alpha - \\beta\\log_{10}\\sigma_{e,i}, \\\\ S_i^2 &= {\\varepsilon_{M,i}}^2 + \\beta^2{\\varepsilon_{\\sigma,i}}^2 + \\varepsilon^2, \\\\ \\tau~ &= \\varepsilon^{-2}. \\end{aligned}\\right. \\end{aligned} \\] \u89b3\u6e2c\u5024\u304c\u7121\u52b9\u306a\u5834\u5408\u306b\u3082\u6b63\u898f\u5206\u5e03\u3092\u4eee\u5b9a\u3057\u305f\u78ba\u7387\u3092\u4f7f\u7528\u3057\u307e\u3059. \u305f\u3060\u3057, \u691c\u51fa\u9650\u754c (\u4eca\u56de\u306f \\(10^{8.5}M_\\odot\\) ) \u4ee5\u4e0b\u3067\u3042\u308b\u78ba\u7387\u3092\u4f7f\u3044\u307e\u3059. \\[ \\log\\tilde{L}_i(\\alpha,\\beta,\\varepsilon; D) = -\\log{C}(M_\\mathrm{lim},\\alpha+\\beta\\log_{10}\\sigma_{e,i},S_i). \\] \u3053\u3053\u3067 \\(C(m,\\mu,\\sigma)\\) \u306f\u6b63\u898f\u5206\u5e03\u306e\u7d2f\u7a4d\u78ba\u7387\u5206\u5e03\u95a2\u6570, \\(M_\\mathrm{lim}\\) \u306f\u691c\u51fa\u9650\u754c\u8cea\u91cf\u3067\u3059. \u5168\u30c7\u30fc\u30bf\u306b\u3064\u3044\u3066\u5408\u8a08\u3057\u305f\u5c24\u5ea6\u95a2\u6570\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u306a\u308a\u307e\u3059. \\[ \\log{L}(\\alpha,\\beta,\\varepsilon; D) = \\sum_{i=1}^n \\left(v_i\\log{L_i} + (1-v_i)\\log\\tilde{L}_i\\right) + \\log{\\operatorname{Gamma}(\\tau, k, \\theta)}. \\] \\(\\tau\\) \u306b\u3064\u3044\u3066\u306e\u4e8b\u524d\u5206\u5e03\u3068\u3057\u3066 Gamma \u5206\u5e03\u3092\u4eee\u5b9a\u3057\u307e\u3057\u305f.","title":"\u6253\u3061\u5207\u308a\u56de\u5e30\u30e2\u30c7\u30eb"},{"location":"mcmc/censored_regression/#_4","text":"\u6253\u3061\u5207\u308a\u30c7\u30fc\u30bf\u3092\u542b\u3081\u306a\u3044\u3067\u89e3\u6790\u3057\u305f\u5834\u5408\u306b\u3069\u306e\u3088\u3046\u306a\u7d50\u679c\u306b\u306a\u308b\u304b\u3092\u8a08\u7b97\u3057\u3066\u304f\u3060\u3055\u3044. Example import numpy as np import pandas as pd import scipy.stats as stats import matplotlib.pyplot as plt from mhmcmc import MHMCMCSampler , GaussianStep table = pd . read_csv ( './exercise_censored_regression.csv' ) table = table . loc [ table . logM_B > 0 ,:] def log_gamma ( x , k = 1e-3 , t = 1e3 ): return ( k - 1 ) * np . log ( x ) - x / t if x > 0 else - 1e10 def log_likelihood ( x ): if x [ 2 ] < 0 : return - 1e10 delta = table . logM_B - ( x [ 0 ] + x [ 1 ] * ( table . logsig - np . log10 ( 200 ))) sqsig = table . logM_B_err ** 2 + x [ 1 ] ** 2 * table . logsig_err ** 2 + x [ 2 ] logpdf = - ( delta ** 2 / sqsig / 2 + np . log ( sqsig ) / 2 ) return np . sum ( logpdf ) + log_gamma ( 1 / x [ 2 ]) step = GaussianStep ( np . array ([ 0.02 , 0.15 , 0.05 ])) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . array ([ 8.0 , 5.0 , 0.5 ]) model . initialize ( x0 ) sample = model . generate ( 51000 ) sample = sample [ 1000 :] sample [:, 2 ] = np . sqrt ( sample [:, 2 ]) x = np . linspace ( - 0.5 , 0.5 , 50 ) a , b , e = sample . mean ( axis = 0 ) fig = plt . figure ( figsize = ( 8 , 6 )) ax = fig . add_subplot () ax . fill_between ( x , a + b * x - 3 * e , a + b * x + 3 * e , color = 'gray' , alpha = 0.05 ) ax . fill_between ( x , a + b * x - e , a + b * x + e , color = 'gray' , alpha = 0.10 ) for _a , _b , _e in sample [:: 1000 ,:]: ax . plot ( x , _a + _b * x , color = 'orange' , alpha = 0.05 ) ax . errorbar ( x = table . logsig - np . log10 ( 200 ), y = table . logM_B , xerr = table . logsig_err , yerr = table . logM_B_err , fmt = '.' ) ax . plot ( x , a + b * x ) ax . set_xlabel ( '$\\log_ {10} \\sigma_e$ (km/s)' ) ax . set_ylabel ( '$\\log_ {10} M_B$ ($M_\\odot$)' ) fig . tight_layout () plt . show () print ( f 'MCMC inference: alpha= { a : .3f } , beta= { b : .3f } , epsilon= { e : .3f } ' ) \u8a08\u7b97\u7d50\u679c MCMC inference: alpha=8.612, beta=3.274, epsilon=0.345 1-\u03c3, 3-\u03c3 \u306e\u4e0d\u5b9a\u6027\u3092\u30b0\u30ec\u30fc\u306e\u9818\u57df\u3067\u8868\u3057\u3066\u3044\u307e\u3059. \u53c2\u8003\u307e\u3067\u306b\u4e0a\u8a18\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u51fa\u529b\u3057\u305f\u30c8\u30ec\u30fc\u30b9\u3068\u81ea\u5df1\u76f8\u95a2\u95a2\u6570\u3092\u793a\u3057\u307e\u3059.","title":"\u6253\u3061\u5207\u308a\u30c7\u30fc\u30bf\u3092\u6392\u9664\u3059\u308b"},{"location":"mcmc/censored_regression/#_5","text":"\u6253\u3061\u5207\u308a\u30c7\u30fc\u30bf\u3092\u542b\u3081\u3066\u89e3\u6790\u3057\u305f\u5834\u5408\u306b\u3069\u306e\u3088\u3046\u306a\u7d50\u679c\u306b\u306a\u308b\u304b\u8a08\u7b97\u3057\u3066\u304f\u3060\u3055\u3044. Example import numpy as np import pandas as pd import scipy.stats as stats import matplotlib.pyplot as plt from mhmcmc import MHMCMCSampler , GaussianStep table = pd . read_csv ( '../../data/mcmc/exercise_censored_regression.csv' ) def log_gamma ( x , k , t ): return ( k - 1 ) * np . log ( x ) - x / t if x > 0 else - 1e10 def log_likelihood ( x ): valid = ( table . logM_B > 0.0 ) beta = x [ 0 ] + x [ 1 ] * ( table . logsig - np . log10 ( 200 )) delta = table . logM_B - beta sqsig = table . logM_B_err ** 2 + x [ 1 ] ** 2 * table . logsig_err ** 2 + x [ 2 ] if ( sqsig < 0 ) . any (): return - 1e10 logpdf = - ( delta ** 2 / sqsig / 2 + np . log ( sqsig ) / 2 ) logcdf = stats . norm . logcdf ( 8.0 , beta , np . sqrt ( sqsig )) return np . sum ( valid * logpdf + ( 1 - valid ) * logcdf ) + log_gamma ( 1 / x [ 2 ], 1e-3 , 1e3 ) step = GaussianStep ( np . array ([ 0.02 , 0.15 , 0.05 ])) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . array ([ 8.0 , 5.0 , 0.5 ]) model . initialize ( x0 ) sample = model . generate ( 51000 ) sample = sample [ 1000 :] sample [:, 2 ] = np . sqrt ( sample [:, 2 ]) x = np . linspace ( - 0.5 , 0.5 , 50 ) a , b , e = sample . mean ( axis = 0 ) fig = plt . figure ( figsize = ( 8 , 6 )) ax = fig . add_subplot () ax . fill_between ( x , a + b * x - 3 * e , a + b * x + 3 * e , color = 'gray' , alpha = 0.05 ) ax . fill_between ( x , a + b * x - e , a + b * x + e , color = 'gray' , alpha = 0.10 ) for _a , _b , _e in sample [:: 1000 ,:]: ax . plot ( x , _a + _b * x , color = 'orange' , alpha = 0.05 ) ax . errorbar ( x = table . logsig - np . log10 ( 200 ), y = table . logM_B , xerr = table . logsig_err , yerr = table . logM_B_err , fmt = '.' ) ax . plot ( x , a + b * x ) ax . set_xlabel ( '$\\log_ {10} \\sigma_e$ (km/s)' ) ax . set_ylabel ( '$\\log_ {10} M_B$ ($M_\\odot$)' ) fig . tight_layout () plt . show () print ( f 'MCMC inference: alpha= { a : .3f } , beta= { b : .3f } , epsilon= { e : .3f } ' ) \u8a08\u7b97\u7d50\u679c MCMC inference: alpha=7.920, beta=6.743, epsilon=0.573 1-\u03c3, 3-\u03c3 \u306e\u4e0d\u5b9a\u6027\u3092\u30b0\u30ec\u30fc\u306e\u9818\u57df\u3067\u8868\u3057\u3066\u3044\u307e\u3059. \u53c2\u8003\u307e\u3067\u306b\u4e0a\u8a18\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u51fa\u529b\u3057\u305f\u30c8\u30ec\u30fc\u30b9\u3068\u81ea\u5df1\u76f8\u95a2\u95a2\u6570\u3092\u793a\u3057\u307e\u3059. \\(\\log{L}_i(\\alpha,\\beta; D)\\) \u306f \\(i\\) \u756a\u76ee\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u5bfe\u6570\u5c24\u5ea6\u3067\u3059. \u21a9 \u21a9 \u21a9 \u21a9 \u21a9 \u21a9 \u4ee5\u4e0b \\(\\sigma_{e,i}\\) \u306f \\(\\sigma_0\\) \u3067\u898f\u683c\u5316\u3055\u308c\u305f\u5024\u3068\u3057\u3066\u6271\u3044\u307e\u3059. \u21a9","title":"\u6253\u3061\u5207\u308a\u30c7\u30fc\u30bf\u3092\u542b\u3081\u308b"},{"location":"mcmc/chain_convergence/","text":"\u30de\u30eb\u30b3\u30d5\u9023\u9396\u306e\u53ce\u675f \u30de\u30eb\u30b3\u30d5\u9023\u9396\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5 (MCMC) \u3067\u306f, \u751f\u6210\u3055\u308c\u305f\u72b6\u614b\u306e\u5217 \\(\\{x_i\\}_{i=0{\\ldots}}\\) \u304c\u5b9a\u5e38\u5206\u5e03\u306b\u53ce\u675f\u3059\u308b\u307e\u3067\u72b6\u614b\u9077\u79fb\u3092\u7e70\u308a\u8fd4\u3057\u3066\u9023\u9396\u3092\u4f38\u3070\u3059\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059. \u3053\u3053\u3067\u306f\u5206\u5e03\u304c\u53ce\u675f\u3057\u3066\u3044\u308b\u304b, \u307e\u305f\u72b6\u614b\u9077\u79fb\u304c\u52b9\u7387\u3088\u304f\u884c\u308f\u308c\u3066\u3044\u308b\u304b\u3092\u8abf\u3079\u308b\u305f\u3081\u306e\u65b9\u6cd5\u3092\u3044\u304f\u3064\u304b\u7d39\u4ecb\u3057\u307e\u3059. \u30c8\u30ec\u30fc\u30b9\u3092\u78ba\u8a8d\u3059\u308b \u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306e\u5024\u3092\u6642\u7cfb\u5217\u306b\u8868\u793a\u3057\u305f\u3082\u306e\u3092\u30c8\u30ec\u30fc\u30b9\u3068\u3044\u3044\u307e\u3059. \u30c8\u30ec\u30fc\u30b9\u3092\u78ba\u8a8d\u3059\u308b\u3053\u3068\u3067 MCMC \u304c\u6a5f\u80fd\u3057\u3066\u3044\u308b (\u52b9\u7387\u3088\u304f\u72b6\u614b\u9077\u79fb\u3057\u3066\u3044\u308b) \u304b\u3092\u5927\u307e\u304b\u306b\u78ba\u8a8d\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u5206\u5e03\u304c\u9069\u5207\u306b\u53ce\u675f\u3057\u305f\u5834\u5408 \u3053\u3053\u3067\u306f\u4f8b\u3068\u3057\u3066 Rosenbrock \u306e\u95a2\u6570 1 \u3092\u4f7f\u3063\u3066\u4ee5\u4e0b\u306e\u78ba\u7387\u5206\u5e03\u306b\u5f93\u3046\u4e71\u6570\u3092\u751f\u6210\u3057\u307e\u3059. 2 \\[ P(x) \\propto \\mathrm{e}^{-\\left( (x_{[0]} - a)^2 + b(x_{[1]} - {x_{[0]}}^2)^2 \\right)} \\] \\((a,\\,b)\\) \u306f\u305d\u308c\u305e\u308c \\((2.0,\\,0.2)\\) \u3068\u3057\u307e\u3057\u305f. \u4ee5\u4e0b\u306b\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u305f\u7d50\u679c\u3092\u6563\u5e03\u56f3\u3068\u3057\u3066\u8868\u793a\u3059\u308b\u30b3\u30fc\u30c9\u306e\u30b5\u30f3\u30d7\u30eb\u3068\u7d50\u679c\u3092\u793a\u3057\u307e\u3059. \u3053\u3053\u3067\u306f\u6700\u521d\u306e 1000 \u500b\u3092 burn-in \u3068\u3057\u3066\u6368\u3066\u3066 10\u2075 \u500b\u306e\u30c7\u30fc\u30bf\u3092\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u3066\u3044\u307e\u3059. from mhmcmc import MHMCMCSampler , GaussianStep import numpy as np a = 2.0 b = 0.2 def rosenbrock ( x ): return ( x [ 0 ] - a ) ** 2 + b * ( x [ 1 ] - x [ 0 ] ** 2 ) ** 2 def log_likelihood ( x ): return - ( rosenbrock ( x )) step = GaussianStep ( 5.0 ) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . zeros ( 2 ) model . initialize ( x0 ) sample = model . generate ( 101000 ) sample = sample [ 1000 :] x = np . linspace ( - 6 , 10 , 1000 ) y = np . linspace ( - 20 , 100 , 1000 ) xx , yy = np . meshgrid ( x , y ) xy = np . dstack (( xx . flatten (), yy . flatten ())) . T z = np . log ( rosenbrock ( xy ) . reshape ( 1000 , 1000 )) lv = np . linspace ( - 2 , 4 , 13 ) import matplotlib.pyplot as plt fig = plt . figure () ax = fig . add_subplot () ax . contour ( xx , yy , z , levels = lv , alpha = 0.3 ) ax . scatter ( sample [:: 20 , 0 ], sample [:: 20 , 1 ], marker = '.' , s = 1 ) ax . set_xlabel ( 'random variable: x0' ) ax . set_ylabel ( 'random variable: x1' ) fig . tight_layout () plt . show () \u8a08\u7b97\u7d50\u679c Rosenbrock \u306e\u95a2\u6570\u306f \\((a,\\,a^2)\\) \u306b\u6700\u5c0f\u5024\u3092\u6301\u3061\u307e\u3059. \u4eca\u56de\u306f \\(a=2\\) \u306a\u306e\u3067\u6563\u5e03\u56f3\u3067 \\((2,\\,4)\\) \u4ed8\u8fd1\u306b\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3055\u308c\u305f\u30c7\u30fc\u30bf\u304c\u96c6\u307e\u3063\u3066\u3044\u308b\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3059. mhmcmc \u3067\u63d0\u4f9b\u3055\u308c\u3066\u3044\u308b\u95a2\u6570 display_trace() \u3092\u4f7f\u3063\u3066\u30c8\u30ec\u30fc\u30b9\u3092\u8868\u793a\u3057\u307e\u3059. \u4ee5\u4e0b\u306e\u30b3\u30fc\u30c9\u3067\u9ec4\u8272\u3067\u30cf\u30a4\u30e9\u30a4\u30c8\u3055\u308c\u3066\u3044\u308b\u90e8\u5206\u3092\u52a0\u3048\u3066\u304f\u3060\u3055\u3044. 1 \u5217\u76ee\u304c \\(x_{[0]}\\) \u306e\u30c8\u30ec\u30fc\u30b9\u3068\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u3092\u8868\u3057\u3066\u3044\u307e\u3059. 2 \u5217\u76ee\u306f \\(x_{[0]}\\) \u306e\u30c8\u30ec\u30fc\u30b9\u3068\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u3092\u8868\u3057\u3066\u3044\u307e\u3059. from mhmcmc import MHMCMCSampler , GaussianStep import numpy as np a = 2.0 b = 0.2 def rosenbrock ( x ): return ( x [ 0 ] - a ) ** 2 + b * ( x [ 1 ] - x [ 0 ] ** 2 ) ** 2 def log_likelihood ( x ): return - ( rosenbrock ( x )) step = GaussianStep ( 5.0 ) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . zeros ( 2 ) model . initialize ( x0 ) sample = model . generate ( 101000 ) sample = sample [ 1000 :] from mhmcmc import display_trace display_trace ( sample ) \u8a08\u7b97\u7d50\u679c \u30c8\u30ec\u30fc\u30b9\u306f \\(x_{[0]}\\) , \\(x_{[1]}\\) \u3069\u3061\u3089\u3082\u76ee\u7acb\u3063\u305f\u69cb\u9020\u306f\u306a\u304f\u5e2f\u72b6\u306b\u5e83\u304c\u3063\u3066\u3044\u308b\u3053\u3068\u304c\u5206\u304b\u308a\u307e\u3059. 3 \u5206\u5e03\u304c\u53ce\u675f\u3057\u3066\u3044\u308c\u3070\u30c7\u30fc\u30bf\u70b9\u306e\u5206\u5e03\u306f\u6642\u9593\u306b\u4f9d\u3089\u306a\u3044\u3068\u671f\u5f85\u3055\u308c\u308b\u305f\u3081, \u5927\u5c40\u7684\u306b\u306f\u3053\u306e\u3088\u3046\u306b\u5e2f\u306e\u3088\u3046\u306a\u898b\u305f\u76ee\u306b\u306a\u3063\u3066\u3044\u308b\u3068\u5b89\u5fc3\u3067\u304d\u307e\u3059. \u307e\u305f, \u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u306e\u30d4\u30fc\u30af\u306f \\(x_{[0]} = 2\\) , \\(x_{[1]} = 4\\) \u4ed8\u8fd1\u306b\u3042\u308b\u3053\u3068\u3082\u78ba\u8a8d\u3067\u304d\u307e\u3059. \u76ee\u7684\u3068\u3059\u308b\u5206\u5e03\u306b\u53ce\u675f\u3057\u3066\u3044\u308b\u3060\u308d\u3046\u3068\u5224\u65ad\u3067\u304d\u307e\u3059. \u30b9\u30c6\u30c3\u30d7\u5e45\u304c\u72ed\u3059\u304e\u308b\u5834\u5408 \u540c\u3058\u8a08\u7b97\u3092 GaussianStep \u306e\u5e45\u3092\u6975\u7aef\u306b\u72ed\u304f\u3057\u3066\u52d5\u304b\u3057\u3066\u307f\u307e\u3059. \u9ec4\u8272\u3067\u30cf\u30a4\u30e9\u30a4\u30c8\u3057\u305f\u90e8\u5206\u304c\u66f4\u65b0\u3057\u305f\u7b87\u6240\u3067\u3059. \u4e00\u5ea6\u306b\u79fb\u52d5\u3067\u304d\u308b\u8ddd\u96e2\u304c\u77ed\u304f\u306a\u3063\u305f\u305f\u3081\u306b, \u5206\u5e03\u304c\u53ce\u675f\u3059\u308b\u307e\u3067\u306b\u5fc5\u8981\u306a\u6642\u9593\u304c\u4f38\u3073\u308b\u3060\u308d\u3046\u3068\u671f\u5f85\u3055\u308c\u307e\u3059. from mhmcmc import MHMCMCSampler , GaussianStep import numpy as np a = 2.0 b = 0.2 def rosenbrock ( x ): return ( x [ 0 ] - a ) ** 2 + b * ( x [ 1 ] - x [ 0 ] ** 2 ) ** 2 def log_likelihood ( x ): return - ( rosenbrock ( x )) step = GaussianStep ( 0.01 ) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . zeros ( 2 ) model . initialize ( x0 ) sample = model . generate ( 101000 ) sample = sample [ 1000 :] from mhmcmc import display_trace display_trace ( sample ) \u8a08\u7b97\u7d50\u679c \u30c8\u30ec\u30fc\u30b9\u3092\u78ba\u8a8d\u3059\u308b\u3068 \\(x_{[0]}\\) , \\(x_{[1]}\\) \u3069\u3061\u3089\u3082\u5e2f\u72b6\u306b\u306f\u306a\u3089\u305a, \u30e9\u30f3\u30c0\u30e0\u30a6\u30a9\u30fc\u30af\u7684\u306a\u6319\u52d5\u304c\u898b\u3048\u3066\u3044\u307e\u3059. \u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u3082\u5148\u307b\u3069\u78ba\u8a8d\u3057\u305f\u3088\u3046\u306a\u5f62\u304b\u3089\u306f\u5927\u304d\u304f\u5916\u308c\u3066\u3044\u307e\u3059. \u63d0\u6848\u5206\u5e03\u306e\u5e45\u304c\u72ed\u3059\u304e\u308b\u305f\u3081\u306b\u5206\u5e03\u304c\u53ce\u675f\u3057\u3066\u3044\u306a\u3044, \u3042\u308b\u3044\u306f\u30b9\u30c6\u30c3\u30d7\u5e45\u306b\u5bfe\u3057\u3066\u8a08\u7b97\u6642\u9593\u304c\u8db3\u308a\u3066\u3044\u306a\u3044\u3068\u5224\u65ad\u3067\u304d\u307e\u3059. \u30b9\u30c6\u30c3\u30d7\u5e45\u304c\u5e83\u904e\u304e\u308b\u5834\u5408 \u4eca\u5ea6\u306f GaussianStep \u306e\u5e45\u3092\u6975\u7aef\u306b\u5e83\u304f\u3057\u3066\u52d5\u304b\u3057\u3066\u307f\u307e\u3059. \u9ec4\u8272\u3067\u30cf\u30a4\u30e9\u30a4\u30c8\u3057\u305f\u90e8\u5206\u304c\u66f4\u65b0\u3057\u305f\u7b87\u6240\u3067\u3059. \u4e00\u5ea6\u306b\u9577\u3044\u8ddd\u96e2\u3092\u79fb\u52d5\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3057\u305f. \u4e00\u65b9\u3067, \u4f4e\u78ba\u7387\u306e\u72b6\u614b\u3078\u306e\u9077\u79fb\u3092\u983b\u7e41\u306b\u63d0\u6848\u3055\u308c\u308b\u305f\u3081, \u307b\u3068\u3093\u3069\u306e\u72b6\u614b\u9077\u79fb\u304c\u5374\u4e0b\u3055\u308c, \u7d50\u679c\u3068\u3057\u3066\u78ba\u7387\u5206\u5e03\u306e\u53ce\u675f\u306f\u9045\u304f\u306a\u308a\u307e\u3059. from mhmcmc import MHMCMCSampler , GaussianStep import numpy as np a = 2.0 b = 0.2 def rosenbrock ( x ): return ( x [ 0 ] - a ) ** 2 + b * ( x [ 1 ] - x [ 0 ] ** 2 ) ** 2 def log_likelihood ( x ): return - ( rosenbrock ( x )) step = GaussianStep ( 100. ) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . zeros ( 2 ) model . initialize ( x0 ) sample = model . generate ( 101000 ) sample = sample [ 1000 :] from mhmcmc import display_trace display_trace ( sample ) \u8a08\u7b97\u7d50\u679c \u30c8\u30ec\u30fc\u30b9\u3092\u78ba\u8a8d\u3059\u308b\u3068\u77e9\u5f62\u306e\u30e9\u30a4\u30f3\u304c\u78ba\u8a8d\u3067\u304d\u307e\u3059. \u72b6\u614b\u9077\u79fb\u304c\u5374\u4e0b\u3055\u308c\u7d9a\u3051\u308b\u305f\u3081, \u4f4d\u7f6e\u3092\u307b\u3068\u3093\u3069\u79fb\u52d5\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u3066\u3044\u306a\u3044\u3053\u3068\u304c\u5206\u304b\u308a\u307e\u3059. \u3053\u306e\u3088\u3046\u306a\u5834\u5408\u3067\u3082\u975e\u5e38\u306b\u9577\u3044\u6642\u9593\u3092\u304b\u3051\u308c\u3070\u5b9a\u5e38\u5206\u5e03\u306b\u53ce\u675f\u3057\u307e\u3059. \u3057\u304b\u3057\u306a\u304c\u3089, \u3053\u306e\u3088\u3046\u306a\u30c8\u30ec\u30fc\u30b9\u304c\u5f97\u3089\u308c\u305f\u5834\u5408\u306b\u306f, \u4e00\u822c\u306b\u306f\u8a08\u7b97\u306e\u30bb\u30c3\u30c6\u30a3\u30f3\u30b0\u3092\u898b\u76f4\u3059\u3053\u3068\u304c\u5fc5\u8981\u3060\u3068\u601d\u308f\u308c\u307e\u3059. \u5e73\u5747\u5024\u306e\u691c\u5b9a \u5e73\u5747\u5024\u306e\u691c\u5b9a: t-\u691c\u5b9a \u30c7\u30fc\u30bf\u5217\u306e\u524d\u534a\u3068\u5f8c\u534a\u306e\u5e73\u5747\u5024\u306e\u5dee\u3092\u5206\u5e03\u304c\u53ce\u675f\u3057\u305f\u304b\u3069\u3046\u304b\u3092\u5224\u5b9a\u3059\u308b\u57fa\u6e96\u3068\u3057\u3066\u4f7f\u3046\u3053\u3068\u304c\u3067\u304d\u307e\u3059.t-\u691c\u5b9a\u306f 2 \u3064\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u5e73\u5747\u5024\u304c\u7b49\u3057\u3044\u304b\u3069\u3046\u304b\u3092\u5224\u5b9a\u3059\u308b\u624b\u6cd5\u3067\u3059. \u5148\u307b\u3069\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066 t-\u691c\u5b9a\u3092\u9069\u7528\u3057\u3066\u307f\u307e\u3059. \u9ec4\u8272\u3067\u30cf\u30a4\u30e9\u30a4\u30c8\u3057\u305f\u90e8\u5206\u304c\u4e3b\u306a\u5909\u66f4\u7b87\u6240\u3067\u3059. \u524d\u534a\u90e8\u5206\u3068\u5f8c\u534a\u90e8\u5206\u304b\u3089\u305d\u308c\u305e\u308c 20% \u305a\u3064\u63a1\u7528\u3057\u3066\u6bd4\u8f03\u3057\u307e\u3059. stats.ttext_ind(a,b) \u306f t-\u691c\u5b9a\u306b\u57fa\u3065\u3044\u3066 2 \u3064\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u5e73\u5747\u5024\u304c\u7b49\u3057\u3044\u3068\u307f\u306a\u305b\u308b\u78ba\u7387\u3092\u8fd4\u3059\u95a2\u6570\u3067\u3059. \u4e0b\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u306f pv \u3068\u3044\u3046\u5909\u6570\u306b\u78ba\u7387\u304c\u683c\u7d0d\u3055\u308c\u3066\u3044\u307e\u3059. from mhmcmc import MHMCMCSampler , GaussianStep import numpy as np a = 2.0 b = 0.2 def rosenbrock ( x ): return ( x [ 0 ] - a ) ** 2 + b * ( x [ 1 ] - x [ 0 ] ** 2 ) ** 2 def log_likelihood ( x ): return - ( rosenbrock ( x )) step = GaussianStep ( 5.0 ) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . zeros ( 2 ) model . initialize ( x0 ) sample = model . generate ( 101000 ) sample = sample [ 1000 :] m , n = sample . shape m20 , m50 = int ( m / 5 ), int ( m / 2 ) from scipy import stats tv , pv = stats . ttest_ind ( sample [: m20 ,:], sample [ m50 :( m50 + m20 ),:], equal_var = False ) print ( f 'probability(x0[former] == x0[latter]): { pv [ 0 ] : g } ' ) print ( f 'probability(x1[former] == x1[latter]): { pv [ 1 ] : g } ' ) \u8a08\u7b97\u7d50\u679c probability(x0[former] == x0[latter]): 0.0141046 probability(x1[former] == x1[latter]): 2.97703e-05 \u4e0a\u8a18\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u306f\u8a08\u7b97\u7d50\u679c\u306f\u307b\u307c\u30bc\u30ed (\u5e73\u5747\u5024\u304c\u540c\u3058\u3060\u3068\u306f\u307f\u306a\u305b\u306a\u3044) \u3067\u3057\u305f. t-\u691c\u5b9a\u306e\u7d50\u679c\u306f\u53ce\u675f\u3057\u305f\u3068\u306f\u8a00\u3048\u306a\u3044\u3068\u3044\u3046\u3082\u306e\u306b\u306a\u308a\u307e\u3057\u305f. 4 t-\u691c\u5b9a\u3067\u306f\u305d\u308c\u305e\u308c\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u542b\u307e\u308c\u308b\u30c7\u30fc\u30bf\u306f\u72ec\u7acb\u306b\u9078\u3070\u308c\u305f\u3082\u306e\u3067\u3042\u308b\u3068\u3044\u3046\u524d\u63d0\u304c\u3042\u308a\u307e\u3059. \u3057\u304b\u3057\u306a\u304c\u3089, \u30de\u30eb\u30b3\u30d5\u9023\u9396\u306b\u3088\u3063\u3066\u751f\u6210\u3055\u308c\u305f\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306f\u76f4\u524d\u306e\u72b6\u614b\u3068\u5f37\u304f\u76f8\u95a2\u3057\u3066\u3044\u307e\u3059. \u305d\u306e\u305f\u3081, \u72ec\u7acb\u306a\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3060\u3068\u307f\u306a\u305b\u308b\u30c7\u30fc\u30bf\u6570\u306f\u5b9f\u969b\u306b\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u305f\u30c7\u30fc\u30bf\u7dcf\u6570\u3088\u308a\u3082\u5fc5\u7136\u7684\u306b\u6e1b\u3063\u3066\u3044\u307e\u3059. \u4e0a\u8a18\u306e\u4f8b\u3067\u306f\u5168\u30c7\u30fc\u30bf\u3092 2 \u3064\u306b\u5206\u3051\u3066\u305d\u306e\u307e\u307e\u5e73\u5747\u5024\u306e\u5dee\u3092\u691c\u5b9a\u3057\u307e\u3057\u305f. \u305d\u306e\u305f\u3081, \u72ec\u7acb\u306a\u30c7\u30fc\u30bf\u6570\u3092\u4e0d\u5f53\u306b\u6c34\u5897\u3057\u3057\u3066 t-\u691c\u5b9a\u3092\u5b9f\u65bd\u3057\u305f\u3053\u3068\u306b\u306a\u3063\u3066\u3044\u307e\u3059. \u81ea\u5df1\u76f8\u95a2\u95a2\u6570 \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u304c\u3069\u306e\u7a0b\u5ea6\u306e\u76f8\u95a2\u3092\u6301\u3063\u3066\u3044\u308b\u304b\u3092\u8a55\u4fa1\u3059\u308b\u65b9\u6cd5\u306b\u81ea\u5df1\u76f8\u95a2\u95a2\u6570\u304c\u3042\u308a\u307e\u3059. \u81ea\u5df1\u76f8\u95a2\u95a2\u6570\u306f\u30c7\u30fc\u30bf\u306e\u6642\u523b\u3092 \\(k\\) \u3060\u3051\u30b7\u30d5\u30c8\u3055\u305b\u3066, \u5143\u306e\u30c7\u30fc\u30bf\u3068\u306e\u76f8\u95a2\u3092\u3068\u308b\u3053\u3068\u3067\u8a08\u7b97\u3057\u307e\u3059. \\[ {\\operatorname{autocorr}}\\left(k; \\{x_i\\}_{i=0{\\ldots}n}\\right) = \\sum_i (x_i - \\bar{x}) \\, (x_{i+k} - \\bar{x}) \\quad (-n \\leq k \\leq n). \\] \u4ee5\u4e0b\u306b\u81ea\u5df1\u76f8\u95a2\u3092\u8a08\u7b97\u3059\u308b\u305f\u3081\u306e Python \u95a2\u6570\u306e\u30b5\u30f3\u30d7\u30eb\u3092\u793a\u3057\u307e\u3059. def autocorrelation ( x : np . ndarray ) -> np . ndarray : ''' Calculate auto-correlation of x Parameters: x (numpy.ndarray): Data in (M,N)-array, where M is the number of samples and N is the number of dimensions. Returns: numpy.ndarray: Calculated auto-correlation in a (M,N)-array ''' if x . ndim == 1 : x = np . expand_dims ( x , axis = 0 ) v = x - x . mean ( axis = 0 ) M , N = v . shape var = v . var ( axis = 0 ) corr = [] for n in range ( N ): corr . append ( np . correlate ( v [:, n ], v [:, n ], mode = 'full' ) / var [ n ]) return np . arange ( - ( M - 1 ), M ), np . stack ( corr ) . T / M \u305f\u3060\u3057, \u3053\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u306f \\(k=0\\) \u306e\u3068\u304d\u306e\u5024 ( \\(\\{x_i\\}_{i=0{\\ldots}}\\) \u306e\u5206\u6563) \u3067\u898f\u683c\u5316\u3057\u3066\u3044\u307e\u3059. \u307e\u305f, \u3053\u306e\u95a2\u6570\u3082 mhmcmc.py \u306b\u542b\u307e\u308c\u3066\u3044\u308b\u306e\u3067 import \u3057\u3066\u4f7f\u3046\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u6b63\u898f\u5206\u5e03\u306b\u5f93\u3046\u4e71\u6570\u3067\u3042\u308c\u3070\u76f8\u95a2\u304c\u306a\u3044\u3053\u3068\u304c\u671f\u5f85\u3055\u308c\u307e\u3059. \u3053\u3053\u3067\u306f numpy \u306b\u3088\u3063\u3066\u63d0\u4f9b\u3055\u308c\u3066\u3044\u308b\u6b63\u898f\u5206\u5e03\u95a2\u6570\u306b\u5f93\u3046\u4e71\u6570\u3092\u4f7f\u3063\u3066 autocorrelation \u306e\u6319\u52d5\u3092\u78ba\u304b\u3081\u3066\u307f\u307e\u3059. from mhmcmc import autocorrelation from numpy.random import default_rng gen = default_rng ( 2021 ) data = gen . normal ( 0 , 1 , size = ( 100 )) k , corr = autocorrelation ( data ) import matplotlib.pyplot as plt fig = plt . figure ( figsize = ( 8 , 3 )) ax = fig . add_subplot () ax . plot ( k , corr , marker = '.' ) ax . set_xlabel ( 'displacement: k' ) ax . set_ylabel ( 'autocorr for N(0,1)' ) fig . tight_layout () plt . show () \u8a08\u7b97\u7d50\u679c \u76f8\u95a2\u304c\u306a\u3051\u308c\u3070\u81ea\u5df1\u76f8\u95a2\u95a2\u6570\u306e\u5024\u306f 0 \u306b\u306a\u308a\u307e\u3059. \u6a19\u6e96\u6b63\u898f\u5206\u5e03\u306b\u5f93\u3046\u4e71\u6570\u306f\u76f8\u95a2\u3092\u6301\u305f\u306a\u3044\u305f\u3081 \\(k=0\\) \u3067\u306e\u307f 0 \u3067\u306a\u3044\u671f\u5f85\u5024\u3092\u6301\u3061\u307e\u3059. \u305d\u308c\u3067\u306f MCMC \u306b\u3088\u3063\u3066\u751f\u6210\u3055\u308c\u305f\u30c7\u30fc\u30bf\u5217\u306b\u3053\u306e\u95a2\u6570\u3092\u9069\u7528\u3057\u3066\u307f\u307e\u3057\u3087\u3046. from mhmcmc import MHMCMCSampler , GaussianStep from mhmcmc import autocorrelation import numpy as np a = 2.0 b = 0.2 def rosenbrock ( x ): return ( x [ 0 ] - a ) ** 2 + b * ( x [ 1 ] - x [ 0 ] ** 2 ) ** 2 def log_likelihood ( x ): return - ( rosenbrock ( x )) step = GaussianStep ( 5.0 ) x0 = np . zeros ( 2 ) model = MHMCMCSampler ( log_likelihood , step ) model . initialize ( x0 ) sample = model . generate ( 101000 ) sample = sample [ 1000 :,:] k , corr = autocorrelation ( sample ) import matplotlib.pyplot as plt fig = plt . figure ( figsize = ( 8 , 6 )) ax1 = fig . add_subplot ( 2 , 1 , 1 ) ax1 . plot ( k , corr [:, 0 ], marker = '' ) ax1 . set_xlim ([ - 800 , 800 ]) ax1 . set_ylabel ( 'autocorr for x0' ) ax2 = fig . add_subplot ( 2 , 1 , 2 ) ax2 . plot ( k , corr [ 0 , 1 ], marker = '' ) ax2 . set_xlim ([ - 800 , 800 ]) ax2 . set_ylabel ( 'autocorr for x1' ) ax2 . set_xlabel ( 'displacement: k' ) fig . tight_layout () plt . show () \u8a08\u7b97\u7d50\u679c \u51fa\u529b\u3055\u308c\u305f\u30b0\u30e9\u30d5\u3092\u898b\u308b\u3068 \\(k=0\\) \u4ee5\u5916\u306b\u3082\u6709\u610f\u306b 0 \u3067\u306a\u3044\u5024\u3092\u6301\u3064\u3053\u3068\u304c\u5206\u304b\u308a\u307e\u3059. \u3053\u306e\u30b1\u30fc\u30b9\u3067\u306f \\(x_{[0]}\\) \u3067\u3082, \\(x_{[1]}\\) \u3067\u3082, \u304a\u304a\u3088\u305d \\(k=200\\) \u7a0b\u5ea6\u3067\u307b\u307c 0 \u306b\u306a\u308a\u307e\u3059. \u3064\u307e\u308a, \u30c7\u30fc\u30bf\u3092\u3059\u3079\u3066\u4f7f\u3046\u306e\u3067\u306f\u306a\u304f 200 \u500b\u7a0b\u5ea6\u304a\u304d\u306b\u4f7f\u3046\u3053\u3068\u3067, \u76f8\u95a2\u304c\u307b\u307c 0 \u306e\u4e71\u6570\u3068\u307f\u306a\u305b\u308b\u3068\u671f\u5f85\u3067\u304d\u307e\u3059. \u5e73\u5747\u5024\u306e\u691c\u5b9a: t-\u691c\u5b9a (\u3082\u3046\u4e00\u5ea6) \u4ee5\u4e0a\u306e\u3053\u3068\u3092\u3075\u307e\u3048\u3066, \u3082\u3046\u4e00\u5ea6 t-\u691c\u5b9a\u3092\u5b9f\u65bd\u3057\u3066\u307f\u307e\u3059. \u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u7dcf\u6570\u306f 10\u2075 \u500b\u3067\u3059\u304c, 200 \u500b\u304a\u304d\u306b\u30c7\u30fc\u30bf\u3092\u63a1\u7528\u3059\u308b\u306e\u3067\u72ec\u7acb\u306a\u30b5\u30f3\u30d7\u30eb\u3068\u307f\u306a\u305b\u308b\u7dcf\u30c7\u30fc\u30bf\u6570\u306f 500 \u500b\u3067\u3059. \u3053\u308c\u3092 2 \u3064\u306b\u5206\u3051\u3066\u5e73\u5747\u5024\u304c\u7b49\u3057\u3044\u304b\u3069\u3046\u304b\u3092 t-\u691c\u5b9a\u3067\u691c\u8a3c\u3057\u307e\u3059. from mhmcmc import MHMCMCSampler , GaussianStep import numpy as np a = 2.0 b = 0.2 def rosenbrock ( x ): return ( x [ 0 ] - a ) ** 2 + b * ( x [ 1 ] - x [ 0 ] ** 2 ) ** 2 def log_likelihood ( x ): return - ( rosenbrock ( x )) step = GaussianStep ( 5.0 ) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . zeros ( 2 ) model . initialize ( x0 ) sample = model . generate ( 101000 ) sample = sample [ 1000 :: 200 ] m , n = sample . shape m20 , m50 = int ( m / 5 ), int ( m / 2 ) from scipy import stats tv , pv = stats . ttest_ind ( sample [: m20 ,:], sample [ m50 :( m50 + m20 ),:], equal_var = False ) print ( f 'probability(x0[former] == x0[latter]): { pv [ 0 ] : g } ' ) print ( f 'probability(x1[former] == x1[latter]): { pv [ 1 ] : g } ' ) \u8a08\u7b97\u7d50\u679c probability(x0[former] == x0[latter]): 0.190402 probability(x1[former] == x1[latter]): 0.966328 \u524d\u56de\u3068\u5927\u304d\u304f\u5909\u308f\u3063\u3066, \u5e73\u5747\u5024\u304c\u540c\u3058\u5206\u5e03\u304b\u3089\u306e\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3060\u3068\u307f\u306a\u305b\u308b\u78ba\u7387\u304c\u305d\u308c\u305e\u308c 19%, 96% \u3068\u3044\u3046\u7d50\u679c\u306b\u306a\u308a\u307e\u3057\u305f. \u524d\u534a\u3068\u5f8c\u534a\u3067\u6709\u610f\u306b\u9055\u3046\u3068\u306f\u307f\u306a\u305b\u306a\u3044\u7a0b\u5ea6\u306e\u5024\u306b\u306a\u3063\u3066\u3044\u307e\u3059. \u4eca\u56de\u306e\u4f8b\u306e\u3088\u3046\u306b, \u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u305f\u30c7\u30fc\u30bf\u9593\u306e\u76f8\u95a2\u304c\u5f71\u97ff\u3092\u4e0e\u3048\u308b\u5834\u5408\u306b\u306f, \u30c7\u30fc\u30bf\u3092\u9593\u5f15\u3044\u3066\u72ec\u7acb\u3057\u305f\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3060\u3068\u307f\u306a\u305b\u308b\u30c7\u30fc\u30bf\u3060\u3051\u3092\u4f7f\u7528\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059. 5 \u9023\u9396\u5185-\u9023\u9396\u9593\u5206\u6563\u306e\u8a08\u7b97 \u6642\u9593\u304c\u8a31\u305b\u3070 MCMC \u3092\u8907\u6570\u56de\u5b9f\u884c\u3057\u3066\u6bd4\u8f03\u3092\u3059\u308b\u3068\u3044\u3046\u65b9\u6cd5\u304c\u4f7f\u3048\u307e\u3059. \u305d\u308c\u305e\u308c\u306e\u30de\u30eb\u30b3\u30d5\u9023\u9396\u5185\u90e8\u306e\u5206\u6563 (within-chain) \u306b\u6bd4\u3079\u3066, \u8907\u6570\u306e\u30de\u30eb\u30b3\u30d5\u9023\u9396\u9593\u306e\u5206\u6563 (between-chain) \u304c\u5927\u304d\u3044\u5834\u5408\u306b\u306f\u5206\u5e03\u304c\u53ce\u675f\u3057\u3066\u3044\u306a\u3044\u3068\u307f\u306a\u3059\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u5408\u8a08 \\(M\\) \u56de\u306e MCMC \u3092\u5b9f\u884c\u3057, \u305d\u308c\u305e\u308c\u306e chain \u3067 \\(N\\) \u500b\u306e\u30c7\u30fc\u30bf\u3092\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u305f\u3068\u3057\u307e\u3059. \u3053\u306e\u3068\u304d, within-chain variance \\(\\sigma^2_w\\) \u3068 between-chain variance \\(\\sigma^2_b\\) \u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u66f8\u3051\u307e\u3059. \\[ \\left\\{~\\begin{aligned} \\sigma^2_w &= \\frac{1}{M(n-1)}\\sum_{m=1}^M\\sum_{i=1}^n (x_{m,i} - \\bar{x}_{m})^2 \\\\ \\sigma^2_b &= \\frac{n}{M-1}\\sum_{m=1}^M (\\bar{x}_m - \\bar{x})^2. \\end{aligned}\\right. \\] \u3053\u3053\u3067 \\(\\bar{x}_m\\) \u306f\u5404 chain \u5185\u3067\u306e\u5e73\u5747\u5024, \\(\\bar{x}\\) \u306f\u30c7\u30fc\u30bf\u5168\u3066\u306b\u5bfe\u3059\u308b\u5e73\u5747\u5024\u3067\u3059. \u3053\u3053\u3067\u5168\u4f53\u306e\u5206\u6563 6 7 \u3068 between-chain variance \\(\\sigma^2_b\\) \u306e\u6bd4\u306e\u5e73\u65b9\u6839\u3068\u3057\u3066 \\(\\hat{R}\\) \u3092\u5b9a\u7fa9\u3057\u307e\u3059. \\[ \\hat{R} = \\sqrt{1 + \\frac{\\sigma^2_b - \\sigma^2_w}{n\\sigma^2_w}}. \\] \u3053\u306e\u91cf\u306f \\(\\sigma^2_b = \\sigma^2_w\\) \u306e\u3068\u304d\u306b \\(\\hat{R} \\simeq 1\\) \u3068\u306a\u308a\u307e\u3059. \u6163\u7fd2\u3068\u3057\u3066 \\(\\hat{R} \\lesssim 1.1\\) \u2013 \\(1.2\\) \u307b\u3069\u3067\u3042\u308c\u3070\u53ce\u675f\u3057\u305f\u3068\u8003\u3048\u3066\u3088\u3044\u3068\u3044\u3046\u3053\u3068\u306b\u306a\u3063\u3066\u3044\u307e\u3059. \\(\\hat{R}\\) \u3092\u3064\u304b\u3063\u3066\u53ce\u675f\u3057\u305f\u3068\u8a00\u3048\u308b\u304b\u3069\u3046\u304b\u3092\u5224\u5b9a\u3057\u3066\u307f\u307e\u3059. \u4ee5\u4e0b\u306b 4 \u3064\u306e MCMC chains \u3092\u751f\u6210\u3057\u3066 \\(\\hat{R}\\) \u3092\u8a08\u7b97\u3059\u308b\u30b5\u30f3\u30d7\u30eb\u3092\u793a\u3057\u307e\u3059. from mhmcmc import MHMCMCSampler , GaussianStep import numpy as np a = 2.0 b = 0.2 def rosenbrock ( x ): return ( x [ 0 ] - a ) ** 2 + b * ( x [ 1 ] - x [ 0 ] ** 2 ) ** 2 def log_likelihood ( x ): return - ( rosenbrock ( x )) nchain = 4 step = GaussianStep ( 5.0 ) samples = [] for n in range ( nchain ): x0 = np . zeros ( 2 ) + n model = MHMCMCSampler ( log_likelihood , step ) model . initialize ( x0 ) sample = model . generate ( 101000 ) samples . append ( sample [ 1000 ::]) samples = np . stack ( samples ) nsample = samples . shape [ 1 ] intra_mean = samples . mean ( axis = 1 ) global_mean = samples . mean ( axis = ( 0 , 1 )) . reshape (( 1 , 2 )) within_var = samples . var ( axis = 1 ) . mean ( axis = 0 ) between_var = nsample * np . var ( intra_mean - global_mean , axis = 0 ) Rhat = np . sqrt ( 1 + ( between_var / within_var - 1 ) / nsample ) print ( f 'Rhat values: { Rhat } ' ) \u8a08\u7b97\u7d50\u679c Rhat values: [1.00044594 1.00048218] \u8a08\u7b97\u3057\u305f \\(\\hat{R}\\) \u306e\u5024\u306f\u307b\u307c 1 \u306b\u8fd1\u304f, \u5341\u5206\u306b\u53ce\u675f\u3057\u305f\u3068\u5224\u5b9a\u3057\u3066\u3082\u3088\u3055\u305d\u3046\u3067\u3059. 8 \u30d0\u30ca\u30ca\u578b\u306e\u30dd\u30c6\u30f3\u30b7\u30e3\u30eb\u3092\u6301\u3064\u95a2\u6570\u3067, \u6570\u5024\u6700\u9069\u5316\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306e\u6027\u80fd\u8a55\u4fa1\u3084\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u3067\u3088\u304f\u4f7f\u308f\u308c\u307e\u3059. \u500b\u306e\u5546\u306e\u30b5\u30f3\u30d7\u30eb\u3068\u3057\u3066\u3053\u306e\u95a2\u6570\u3092\u63a1\u7528\u3057\u305f\u6df1\u3044\u7406\u7531\u306f\u7279\u306b\u3042\u308a\u307e\u305b\u3093. \u21a9 \\(x\\) \u306e \\(i\\) \u756a\u76ee\u306e\u8981\u7d20\u3092 \\(x_{[i]}\\) \u3067\u8868\u3057\u307e\u3059. \u21a9 \u3053\u306e\u6642\u70b9\u3067\u306f\u30c7\u30fc\u30bf\u3092\u9593\u5f15\u3044\u3066\u3044\u306a\u3044\u306e\u3067, \u3088\u308a\u7d30\u304b\u304f\u8868\u793a\u3055\u305b\u308b\u3068\u30e9\u30f3\u30c0\u30e0\u30a6\u30a9\u30fc\u30af\u7684\u306b\u52d5\u3044\u3066\u3044\u308b\u69d8\u5b50\u304c\u898b\u3048\u3066\u304d\u307e\u3059. \u5927\u304d\u306a\u30b9\u30b1\u30fc\u30eb\u3067\u898b\u3066\u3044\u308b\u306e\u3067\u6f70\u3055\u308c\u3066\u3044\u308b\u3060\u3051\u3067\u3059. \u21a9 \u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u6570\u304c\u8db3\u308a\u305a\u672c\u5f53\u306b\u53ce\u675f\u3057\u3066\u3044\u306a\u3044\u306e\u3067\u306f\uff1f\u3068\u601d\u3046\u304b\u3082\u3057\u308c\u307e\u305b\u3093. \u8a66\u3057\u306b\u6570\u3092 5 \u500d\u306b\u5897\u3084\u3057\u3066\u307f\u305f\u3068\u3053\u308d\u78ba\u7387\u306f\u3055\u3089\u306b\u6e1b\u308a\u307e\u3057\u305f. \u30b5\u30f3\u30d7\u30eb\u6570\u304c\u5897\u3048\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u5dee\u304c\u3088\u308a\u6709\u610f\u306b\u306a\u3063\u305f\u3068\u5224\u5b9a\u3055\u308c\u305f\u3088\u3046\u3067\u3059. \u21a9 \u3061\u306a\u307f\u306b\u671f\u5f85\u5024 (\u5358\u7d14\u5e73\u5747) \u306e\u8a08\u7b97\u3067\u306f\u30c7\u30fc\u30bf\u306e\u76f8\u95a2\u306f\u5f71\u97ff\u3057\u307e\u305b\u3093 (\u53ce\u675f\u304c\u30c7\u30fc\u30bf\u6570\u306e\u308f\u308a\u306b\u306f\u9045\u304f\u306a\u308b\u3060\u3051). \u21a9 \u5168\u4f53\u306e\u5206\u6563\u306e \u201c\u63a8\u5b9a\u5024\u201d \u3068\u3057\u3066 \\(\\sigma^2_{bw} = \\left((n-1)\\sigma^2_w + \\sigma^2_b\\right)/n\\) \u3068\u3044\u3046\u5f0f\u3092\u4f7f\u3063\u3066\u3044\u308b\u3088\u3046\u3067\u3059. Gelman et al. (2013) \u306b\u3088\u308b\u3068 \u201cThis quantity overestimates the marginal posterior variance assuming the starting distributions in appropriately overdispersed, but is unbiased \u2026\u201d. \u3068\u306e\u3053\u3068\u3067\u3057\u305f. \u21a9 \u624b\u5143\u3067\u5168\u4f53\u306e\u5206\u6563\u3092\u8a08\u7b97\u3092\u3057\u3066\u307f\u305f\u3089 \\(\\sigma^2_{bw} = \\left((n-1)\\sigma^2_w + (1-M^{-1})\\sigma^2_b\\right)/(n-M^{-1})\\) \u306b\u306a\u308a\u307e\u3057\u305f. \u305f\u3060\u3057, \u30c7\u30fc\u30bf\u306e\u76f8\u95a2\u306b\u3064\u3044\u3066\u306f\u4f55\u3082\u8003\u616e\u3057\u3066\u3044\u307e\u305b\u3093. \\(\\sigma^2_w\\) \u3068 \\(\\sigma^2_b\\) \u306e\u91cd\u307f\u4ed8\u304d\u5e73\u5747\u306b\u306a\u308b\u3068\u3044\u3046\u7d50\u679c\u306f\u78ba\u8a8d\u3067\u304d\u307e\u3057\u305f. \u21a9 \u305f\u3060\u3057\u30d1\u30e9\u30e1\u30bf\u3092\u5909\u3048\u3066\u8a08\u7b97\u3057\u3066\u307f\u308b\u3068 \\(\\hat{R} \\simeq 1\\) \u306e\u5834\u5408\u3067\u3082\u30c8\u30ec\u30fc\u30b9\u3092\u898b\u308b\u3068\u307e\u3063\u305f\u304f\u53ce\u675f\u3057\u3066\u3044\u306a\u3044\u3068\u3044\u3046\u30b1\u30fc\u30b9\u3082\u3042\u308a\u307e\u3057\u305f. \u91cd\u8981\u306a\u8a08\u7b97\u3067\u306f\u904e\u4fe1\u305b\u305a\u306b\u30c8\u30ec\u30fc\u30b9\u3084\u76f8\u95a2\u3082\u78ba\u8a8d\u3057\u3066\u304a\u3044\u305f\u307b\u3046\u304c\u3088\u3044\u3068\u601d\u3044\u307e\u3059. \u21a9","title":"\u30de\u30eb\u30b3\u30d5\u9023\u9396\u306e\u53ce\u675f"},{"location":"mcmc/chain_convergence/#_1","text":"\u30de\u30eb\u30b3\u30d5\u9023\u9396\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5 (MCMC) \u3067\u306f, \u751f\u6210\u3055\u308c\u305f\u72b6\u614b\u306e\u5217 \\(\\{x_i\\}_{i=0{\\ldots}}\\) \u304c\u5b9a\u5e38\u5206\u5e03\u306b\u53ce\u675f\u3059\u308b\u307e\u3067\u72b6\u614b\u9077\u79fb\u3092\u7e70\u308a\u8fd4\u3057\u3066\u9023\u9396\u3092\u4f38\u3070\u3059\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059. \u3053\u3053\u3067\u306f\u5206\u5e03\u304c\u53ce\u675f\u3057\u3066\u3044\u308b\u304b, \u307e\u305f\u72b6\u614b\u9077\u79fb\u304c\u52b9\u7387\u3088\u304f\u884c\u308f\u308c\u3066\u3044\u308b\u304b\u3092\u8abf\u3079\u308b\u305f\u3081\u306e\u65b9\u6cd5\u3092\u3044\u304f\u3064\u304b\u7d39\u4ecb\u3057\u307e\u3059.","title":"\u30de\u30eb\u30b3\u30d5\u9023\u9396\u306e\u53ce\u675f"},{"location":"mcmc/chain_convergence/#_2","text":"\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306e\u5024\u3092\u6642\u7cfb\u5217\u306b\u8868\u793a\u3057\u305f\u3082\u306e\u3092\u30c8\u30ec\u30fc\u30b9\u3068\u3044\u3044\u307e\u3059. \u30c8\u30ec\u30fc\u30b9\u3092\u78ba\u8a8d\u3059\u308b\u3053\u3068\u3067 MCMC \u304c\u6a5f\u80fd\u3057\u3066\u3044\u308b (\u52b9\u7387\u3088\u304f\u72b6\u614b\u9077\u79fb\u3057\u3066\u3044\u308b) \u304b\u3092\u5927\u307e\u304b\u306b\u78ba\u8a8d\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059.","title":"\u30c8\u30ec\u30fc\u30b9\u3092\u78ba\u8a8d\u3059\u308b"},{"location":"mcmc/chain_convergence/#_3","text":"\u3053\u3053\u3067\u306f\u4f8b\u3068\u3057\u3066 Rosenbrock \u306e\u95a2\u6570 1 \u3092\u4f7f\u3063\u3066\u4ee5\u4e0b\u306e\u78ba\u7387\u5206\u5e03\u306b\u5f93\u3046\u4e71\u6570\u3092\u751f\u6210\u3057\u307e\u3059. 2 \\[ P(x) \\propto \\mathrm{e}^{-\\left( (x_{[0]} - a)^2 + b(x_{[1]} - {x_{[0]}}^2)^2 \\right)} \\] \\((a,\\,b)\\) \u306f\u305d\u308c\u305e\u308c \\((2.0,\\,0.2)\\) \u3068\u3057\u307e\u3057\u305f. \u4ee5\u4e0b\u306b\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u305f\u7d50\u679c\u3092\u6563\u5e03\u56f3\u3068\u3057\u3066\u8868\u793a\u3059\u308b\u30b3\u30fc\u30c9\u306e\u30b5\u30f3\u30d7\u30eb\u3068\u7d50\u679c\u3092\u793a\u3057\u307e\u3059. \u3053\u3053\u3067\u306f\u6700\u521d\u306e 1000 \u500b\u3092 burn-in \u3068\u3057\u3066\u6368\u3066\u3066 10\u2075 \u500b\u306e\u30c7\u30fc\u30bf\u3092\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u3066\u3044\u307e\u3059. from mhmcmc import MHMCMCSampler , GaussianStep import numpy as np a = 2.0 b = 0.2 def rosenbrock ( x ): return ( x [ 0 ] - a ) ** 2 + b * ( x [ 1 ] - x [ 0 ] ** 2 ) ** 2 def log_likelihood ( x ): return - ( rosenbrock ( x )) step = GaussianStep ( 5.0 ) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . zeros ( 2 ) model . initialize ( x0 ) sample = model . generate ( 101000 ) sample = sample [ 1000 :] x = np . linspace ( - 6 , 10 , 1000 ) y = np . linspace ( - 20 , 100 , 1000 ) xx , yy = np . meshgrid ( x , y ) xy = np . dstack (( xx . flatten (), yy . flatten ())) . T z = np . log ( rosenbrock ( xy ) . reshape ( 1000 , 1000 )) lv = np . linspace ( - 2 , 4 , 13 ) import matplotlib.pyplot as plt fig = plt . figure () ax = fig . add_subplot () ax . contour ( xx , yy , z , levels = lv , alpha = 0.3 ) ax . scatter ( sample [:: 20 , 0 ], sample [:: 20 , 1 ], marker = '.' , s = 1 ) ax . set_xlabel ( 'random variable: x0' ) ax . set_ylabel ( 'random variable: x1' ) fig . tight_layout () plt . show () \u8a08\u7b97\u7d50\u679c Rosenbrock \u306e\u95a2\u6570\u306f \\((a,\\,a^2)\\) \u306b\u6700\u5c0f\u5024\u3092\u6301\u3061\u307e\u3059. \u4eca\u56de\u306f \\(a=2\\) \u306a\u306e\u3067\u6563\u5e03\u56f3\u3067 \\((2,\\,4)\\) \u4ed8\u8fd1\u306b\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3055\u308c\u305f\u30c7\u30fc\u30bf\u304c\u96c6\u307e\u3063\u3066\u3044\u308b\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3059. mhmcmc \u3067\u63d0\u4f9b\u3055\u308c\u3066\u3044\u308b\u95a2\u6570 display_trace() \u3092\u4f7f\u3063\u3066\u30c8\u30ec\u30fc\u30b9\u3092\u8868\u793a\u3057\u307e\u3059. \u4ee5\u4e0b\u306e\u30b3\u30fc\u30c9\u3067\u9ec4\u8272\u3067\u30cf\u30a4\u30e9\u30a4\u30c8\u3055\u308c\u3066\u3044\u308b\u90e8\u5206\u3092\u52a0\u3048\u3066\u304f\u3060\u3055\u3044. 1 \u5217\u76ee\u304c \\(x_{[0]}\\) \u306e\u30c8\u30ec\u30fc\u30b9\u3068\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u3092\u8868\u3057\u3066\u3044\u307e\u3059. 2 \u5217\u76ee\u306f \\(x_{[0]}\\) \u306e\u30c8\u30ec\u30fc\u30b9\u3068\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u3092\u8868\u3057\u3066\u3044\u307e\u3059. from mhmcmc import MHMCMCSampler , GaussianStep import numpy as np a = 2.0 b = 0.2 def rosenbrock ( x ): return ( x [ 0 ] - a ) ** 2 + b * ( x [ 1 ] - x [ 0 ] ** 2 ) ** 2 def log_likelihood ( x ): return - ( rosenbrock ( x )) step = GaussianStep ( 5.0 ) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . zeros ( 2 ) model . initialize ( x0 ) sample = model . generate ( 101000 ) sample = sample [ 1000 :] from mhmcmc import display_trace display_trace ( sample ) \u8a08\u7b97\u7d50\u679c \u30c8\u30ec\u30fc\u30b9\u306f \\(x_{[0]}\\) , \\(x_{[1]}\\) \u3069\u3061\u3089\u3082\u76ee\u7acb\u3063\u305f\u69cb\u9020\u306f\u306a\u304f\u5e2f\u72b6\u306b\u5e83\u304c\u3063\u3066\u3044\u308b\u3053\u3068\u304c\u5206\u304b\u308a\u307e\u3059. 3 \u5206\u5e03\u304c\u53ce\u675f\u3057\u3066\u3044\u308c\u3070\u30c7\u30fc\u30bf\u70b9\u306e\u5206\u5e03\u306f\u6642\u9593\u306b\u4f9d\u3089\u306a\u3044\u3068\u671f\u5f85\u3055\u308c\u308b\u305f\u3081, \u5927\u5c40\u7684\u306b\u306f\u3053\u306e\u3088\u3046\u306b\u5e2f\u306e\u3088\u3046\u306a\u898b\u305f\u76ee\u306b\u306a\u3063\u3066\u3044\u308b\u3068\u5b89\u5fc3\u3067\u304d\u307e\u3059. \u307e\u305f, \u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u306e\u30d4\u30fc\u30af\u306f \\(x_{[0]} = 2\\) , \\(x_{[1]} = 4\\) \u4ed8\u8fd1\u306b\u3042\u308b\u3053\u3068\u3082\u78ba\u8a8d\u3067\u304d\u307e\u3059. \u76ee\u7684\u3068\u3059\u308b\u5206\u5e03\u306b\u53ce\u675f\u3057\u3066\u3044\u308b\u3060\u308d\u3046\u3068\u5224\u65ad\u3067\u304d\u307e\u3059.","title":"\u5206\u5e03\u304c\u9069\u5207\u306b\u53ce\u675f\u3057\u305f\u5834\u5408"},{"location":"mcmc/chain_convergence/#_4","text":"\u540c\u3058\u8a08\u7b97\u3092 GaussianStep \u306e\u5e45\u3092\u6975\u7aef\u306b\u72ed\u304f\u3057\u3066\u52d5\u304b\u3057\u3066\u307f\u307e\u3059. \u9ec4\u8272\u3067\u30cf\u30a4\u30e9\u30a4\u30c8\u3057\u305f\u90e8\u5206\u304c\u66f4\u65b0\u3057\u305f\u7b87\u6240\u3067\u3059. \u4e00\u5ea6\u306b\u79fb\u52d5\u3067\u304d\u308b\u8ddd\u96e2\u304c\u77ed\u304f\u306a\u3063\u305f\u305f\u3081\u306b, \u5206\u5e03\u304c\u53ce\u675f\u3059\u308b\u307e\u3067\u306b\u5fc5\u8981\u306a\u6642\u9593\u304c\u4f38\u3073\u308b\u3060\u308d\u3046\u3068\u671f\u5f85\u3055\u308c\u307e\u3059. from mhmcmc import MHMCMCSampler , GaussianStep import numpy as np a = 2.0 b = 0.2 def rosenbrock ( x ): return ( x [ 0 ] - a ) ** 2 + b * ( x [ 1 ] - x [ 0 ] ** 2 ) ** 2 def log_likelihood ( x ): return - ( rosenbrock ( x )) step = GaussianStep ( 0.01 ) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . zeros ( 2 ) model . initialize ( x0 ) sample = model . generate ( 101000 ) sample = sample [ 1000 :] from mhmcmc import display_trace display_trace ( sample ) \u8a08\u7b97\u7d50\u679c \u30c8\u30ec\u30fc\u30b9\u3092\u78ba\u8a8d\u3059\u308b\u3068 \\(x_{[0]}\\) , \\(x_{[1]}\\) \u3069\u3061\u3089\u3082\u5e2f\u72b6\u306b\u306f\u306a\u3089\u305a, \u30e9\u30f3\u30c0\u30e0\u30a6\u30a9\u30fc\u30af\u7684\u306a\u6319\u52d5\u304c\u898b\u3048\u3066\u3044\u307e\u3059. \u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u3082\u5148\u307b\u3069\u78ba\u8a8d\u3057\u305f\u3088\u3046\u306a\u5f62\u304b\u3089\u306f\u5927\u304d\u304f\u5916\u308c\u3066\u3044\u307e\u3059. \u63d0\u6848\u5206\u5e03\u306e\u5e45\u304c\u72ed\u3059\u304e\u308b\u305f\u3081\u306b\u5206\u5e03\u304c\u53ce\u675f\u3057\u3066\u3044\u306a\u3044, \u3042\u308b\u3044\u306f\u30b9\u30c6\u30c3\u30d7\u5e45\u306b\u5bfe\u3057\u3066\u8a08\u7b97\u6642\u9593\u304c\u8db3\u308a\u3066\u3044\u306a\u3044\u3068\u5224\u65ad\u3067\u304d\u307e\u3059.","title":"\u30b9\u30c6\u30c3\u30d7\u5e45\u304c\u72ed\u3059\u304e\u308b\u5834\u5408"},{"location":"mcmc/chain_convergence/#_5","text":"\u4eca\u5ea6\u306f GaussianStep \u306e\u5e45\u3092\u6975\u7aef\u306b\u5e83\u304f\u3057\u3066\u52d5\u304b\u3057\u3066\u307f\u307e\u3059. \u9ec4\u8272\u3067\u30cf\u30a4\u30e9\u30a4\u30c8\u3057\u305f\u90e8\u5206\u304c\u66f4\u65b0\u3057\u305f\u7b87\u6240\u3067\u3059. \u4e00\u5ea6\u306b\u9577\u3044\u8ddd\u96e2\u3092\u79fb\u52d5\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3057\u305f. \u4e00\u65b9\u3067, \u4f4e\u78ba\u7387\u306e\u72b6\u614b\u3078\u306e\u9077\u79fb\u3092\u983b\u7e41\u306b\u63d0\u6848\u3055\u308c\u308b\u305f\u3081, \u307b\u3068\u3093\u3069\u306e\u72b6\u614b\u9077\u79fb\u304c\u5374\u4e0b\u3055\u308c, \u7d50\u679c\u3068\u3057\u3066\u78ba\u7387\u5206\u5e03\u306e\u53ce\u675f\u306f\u9045\u304f\u306a\u308a\u307e\u3059. from mhmcmc import MHMCMCSampler , GaussianStep import numpy as np a = 2.0 b = 0.2 def rosenbrock ( x ): return ( x [ 0 ] - a ) ** 2 + b * ( x [ 1 ] - x [ 0 ] ** 2 ) ** 2 def log_likelihood ( x ): return - ( rosenbrock ( x )) step = GaussianStep ( 100. ) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . zeros ( 2 ) model . initialize ( x0 ) sample = model . generate ( 101000 ) sample = sample [ 1000 :] from mhmcmc import display_trace display_trace ( sample ) \u8a08\u7b97\u7d50\u679c \u30c8\u30ec\u30fc\u30b9\u3092\u78ba\u8a8d\u3059\u308b\u3068\u77e9\u5f62\u306e\u30e9\u30a4\u30f3\u304c\u78ba\u8a8d\u3067\u304d\u307e\u3059. \u72b6\u614b\u9077\u79fb\u304c\u5374\u4e0b\u3055\u308c\u7d9a\u3051\u308b\u305f\u3081, \u4f4d\u7f6e\u3092\u307b\u3068\u3093\u3069\u79fb\u52d5\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u3066\u3044\u306a\u3044\u3053\u3068\u304c\u5206\u304b\u308a\u307e\u3059. \u3053\u306e\u3088\u3046\u306a\u5834\u5408\u3067\u3082\u975e\u5e38\u306b\u9577\u3044\u6642\u9593\u3092\u304b\u3051\u308c\u3070\u5b9a\u5e38\u5206\u5e03\u306b\u53ce\u675f\u3057\u307e\u3059. \u3057\u304b\u3057\u306a\u304c\u3089, \u3053\u306e\u3088\u3046\u306a\u30c8\u30ec\u30fc\u30b9\u304c\u5f97\u3089\u308c\u305f\u5834\u5408\u306b\u306f, \u4e00\u822c\u306b\u306f\u8a08\u7b97\u306e\u30bb\u30c3\u30c6\u30a3\u30f3\u30b0\u3092\u898b\u76f4\u3059\u3053\u3068\u304c\u5fc5\u8981\u3060\u3068\u601d\u308f\u308c\u307e\u3059.","title":"\u30b9\u30c6\u30c3\u30d7\u5e45\u304c\u5e83\u904e\u304e\u308b\u5834\u5408"},{"location":"mcmc/chain_convergence/#_6","text":"","title":"\u5e73\u5747\u5024\u306e\u691c\u5b9a"},{"location":"mcmc/chain_convergence/#t-","text":"\u30c7\u30fc\u30bf\u5217\u306e\u524d\u534a\u3068\u5f8c\u534a\u306e\u5e73\u5747\u5024\u306e\u5dee\u3092\u5206\u5e03\u304c\u53ce\u675f\u3057\u305f\u304b\u3069\u3046\u304b\u3092\u5224\u5b9a\u3059\u308b\u57fa\u6e96\u3068\u3057\u3066\u4f7f\u3046\u3053\u3068\u304c\u3067\u304d\u307e\u3059.t-\u691c\u5b9a\u306f 2 \u3064\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u5e73\u5747\u5024\u304c\u7b49\u3057\u3044\u304b\u3069\u3046\u304b\u3092\u5224\u5b9a\u3059\u308b\u624b\u6cd5\u3067\u3059. \u5148\u307b\u3069\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066 t-\u691c\u5b9a\u3092\u9069\u7528\u3057\u3066\u307f\u307e\u3059. \u9ec4\u8272\u3067\u30cf\u30a4\u30e9\u30a4\u30c8\u3057\u305f\u90e8\u5206\u304c\u4e3b\u306a\u5909\u66f4\u7b87\u6240\u3067\u3059. \u524d\u534a\u90e8\u5206\u3068\u5f8c\u534a\u90e8\u5206\u304b\u3089\u305d\u308c\u305e\u308c 20% \u305a\u3064\u63a1\u7528\u3057\u3066\u6bd4\u8f03\u3057\u307e\u3059. stats.ttext_ind(a,b) \u306f t-\u691c\u5b9a\u306b\u57fa\u3065\u3044\u3066 2 \u3064\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u5e73\u5747\u5024\u304c\u7b49\u3057\u3044\u3068\u307f\u306a\u305b\u308b\u78ba\u7387\u3092\u8fd4\u3059\u95a2\u6570\u3067\u3059. \u4e0b\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u306f pv \u3068\u3044\u3046\u5909\u6570\u306b\u78ba\u7387\u304c\u683c\u7d0d\u3055\u308c\u3066\u3044\u307e\u3059. from mhmcmc import MHMCMCSampler , GaussianStep import numpy as np a = 2.0 b = 0.2 def rosenbrock ( x ): return ( x [ 0 ] - a ) ** 2 + b * ( x [ 1 ] - x [ 0 ] ** 2 ) ** 2 def log_likelihood ( x ): return - ( rosenbrock ( x )) step = GaussianStep ( 5.0 ) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . zeros ( 2 ) model . initialize ( x0 ) sample = model . generate ( 101000 ) sample = sample [ 1000 :] m , n = sample . shape m20 , m50 = int ( m / 5 ), int ( m / 2 ) from scipy import stats tv , pv = stats . ttest_ind ( sample [: m20 ,:], sample [ m50 :( m50 + m20 ),:], equal_var = False ) print ( f 'probability(x0[former] == x0[latter]): { pv [ 0 ] : g } ' ) print ( f 'probability(x1[former] == x1[latter]): { pv [ 1 ] : g } ' ) \u8a08\u7b97\u7d50\u679c probability(x0[former] == x0[latter]): 0.0141046 probability(x1[former] == x1[latter]): 2.97703e-05 \u4e0a\u8a18\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u306f\u8a08\u7b97\u7d50\u679c\u306f\u307b\u307c\u30bc\u30ed (\u5e73\u5747\u5024\u304c\u540c\u3058\u3060\u3068\u306f\u307f\u306a\u305b\u306a\u3044) \u3067\u3057\u305f. t-\u691c\u5b9a\u306e\u7d50\u679c\u306f\u53ce\u675f\u3057\u305f\u3068\u306f\u8a00\u3048\u306a\u3044\u3068\u3044\u3046\u3082\u306e\u306b\u306a\u308a\u307e\u3057\u305f. 4 t-\u691c\u5b9a\u3067\u306f\u305d\u308c\u305e\u308c\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u542b\u307e\u308c\u308b\u30c7\u30fc\u30bf\u306f\u72ec\u7acb\u306b\u9078\u3070\u308c\u305f\u3082\u306e\u3067\u3042\u308b\u3068\u3044\u3046\u524d\u63d0\u304c\u3042\u308a\u307e\u3059. \u3057\u304b\u3057\u306a\u304c\u3089, \u30de\u30eb\u30b3\u30d5\u9023\u9396\u306b\u3088\u3063\u3066\u751f\u6210\u3055\u308c\u305f\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306f\u76f4\u524d\u306e\u72b6\u614b\u3068\u5f37\u304f\u76f8\u95a2\u3057\u3066\u3044\u307e\u3059. \u305d\u306e\u305f\u3081, \u72ec\u7acb\u306a\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3060\u3068\u307f\u306a\u305b\u308b\u30c7\u30fc\u30bf\u6570\u306f\u5b9f\u969b\u306b\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u305f\u30c7\u30fc\u30bf\u7dcf\u6570\u3088\u308a\u3082\u5fc5\u7136\u7684\u306b\u6e1b\u3063\u3066\u3044\u307e\u3059. \u4e0a\u8a18\u306e\u4f8b\u3067\u306f\u5168\u30c7\u30fc\u30bf\u3092 2 \u3064\u306b\u5206\u3051\u3066\u305d\u306e\u307e\u307e\u5e73\u5747\u5024\u306e\u5dee\u3092\u691c\u5b9a\u3057\u307e\u3057\u305f. \u305d\u306e\u305f\u3081, \u72ec\u7acb\u306a\u30c7\u30fc\u30bf\u6570\u3092\u4e0d\u5f53\u306b\u6c34\u5897\u3057\u3057\u3066 t-\u691c\u5b9a\u3092\u5b9f\u65bd\u3057\u305f\u3053\u3068\u306b\u306a\u3063\u3066\u3044\u307e\u3059.","title":"\u5e73\u5747\u5024\u306e\u691c\u5b9a: t-\u691c\u5b9a"},{"location":"mcmc/chain_convergence/#_7","text":"\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u304c\u3069\u306e\u7a0b\u5ea6\u306e\u76f8\u95a2\u3092\u6301\u3063\u3066\u3044\u308b\u304b\u3092\u8a55\u4fa1\u3059\u308b\u65b9\u6cd5\u306b\u81ea\u5df1\u76f8\u95a2\u95a2\u6570\u304c\u3042\u308a\u307e\u3059. \u81ea\u5df1\u76f8\u95a2\u95a2\u6570\u306f\u30c7\u30fc\u30bf\u306e\u6642\u523b\u3092 \\(k\\) \u3060\u3051\u30b7\u30d5\u30c8\u3055\u305b\u3066, \u5143\u306e\u30c7\u30fc\u30bf\u3068\u306e\u76f8\u95a2\u3092\u3068\u308b\u3053\u3068\u3067\u8a08\u7b97\u3057\u307e\u3059. \\[ {\\operatorname{autocorr}}\\left(k; \\{x_i\\}_{i=0{\\ldots}n}\\right) = \\sum_i (x_i - \\bar{x}) \\, (x_{i+k} - \\bar{x}) \\quad (-n \\leq k \\leq n). \\] \u4ee5\u4e0b\u306b\u81ea\u5df1\u76f8\u95a2\u3092\u8a08\u7b97\u3059\u308b\u305f\u3081\u306e Python \u95a2\u6570\u306e\u30b5\u30f3\u30d7\u30eb\u3092\u793a\u3057\u307e\u3059. def autocorrelation ( x : np . ndarray ) -> np . ndarray : ''' Calculate auto-correlation of x Parameters: x (numpy.ndarray): Data in (M,N)-array, where M is the number of samples and N is the number of dimensions. Returns: numpy.ndarray: Calculated auto-correlation in a (M,N)-array ''' if x . ndim == 1 : x = np . expand_dims ( x , axis = 0 ) v = x - x . mean ( axis = 0 ) M , N = v . shape var = v . var ( axis = 0 ) corr = [] for n in range ( N ): corr . append ( np . correlate ( v [:, n ], v [:, n ], mode = 'full' ) / var [ n ]) return np . arange ( - ( M - 1 ), M ), np . stack ( corr ) . T / M \u305f\u3060\u3057, \u3053\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u306f \\(k=0\\) \u306e\u3068\u304d\u306e\u5024 ( \\(\\{x_i\\}_{i=0{\\ldots}}\\) \u306e\u5206\u6563) \u3067\u898f\u683c\u5316\u3057\u3066\u3044\u307e\u3059. \u307e\u305f, \u3053\u306e\u95a2\u6570\u3082 mhmcmc.py \u306b\u542b\u307e\u308c\u3066\u3044\u308b\u306e\u3067 import \u3057\u3066\u4f7f\u3046\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u6b63\u898f\u5206\u5e03\u306b\u5f93\u3046\u4e71\u6570\u3067\u3042\u308c\u3070\u76f8\u95a2\u304c\u306a\u3044\u3053\u3068\u304c\u671f\u5f85\u3055\u308c\u307e\u3059. \u3053\u3053\u3067\u306f numpy \u306b\u3088\u3063\u3066\u63d0\u4f9b\u3055\u308c\u3066\u3044\u308b\u6b63\u898f\u5206\u5e03\u95a2\u6570\u306b\u5f93\u3046\u4e71\u6570\u3092\u4f7f\u3063\u3066 autocorrelation \u306e\u6319\u52d5\u3092\u78ba\u304b\u3081\u3066\u307f\u307e\u3059. from mhmcmc import autocorrelation from numpy.random import default_rng gen = default_rng ( 2021 ) data = gen . normal ( 0 , 1 , size = ( 100 )) k , corr = autocorrelation ( data ) import matplotlib.pyplot as plt fig = plt . figure ( figsize = ( 8 , 3 )) ax = fig . add_subplot () ax . plot ( k , corr , marker = '.' ) ax . set_xlabel ( 'displacement: k' ) ax . set_ylabel ( 'autocorr for N(0,1)' ) fig . tight_layout () plt . show () \u8a08\u7b97\u7d50\u679c \u76f8\u95a2\u304c\u306a\u3051\u308c\u3070\u81ea\u5df1\u76f8\u95a2\u95a2\u6570\u306e\u5024\u306f 0 \u306b\u306a\u308a\u307e\u3059. \u6a19\u6e96\u6b63\u898f\u5206\u5e03\u306b\u5f93\u3046\u4e71\u6570\u306f\u76f8\u95a2\u3092\u6301\u305f\u306a\u3044\u305f\u3081 \\(k=0\\) \u3067\u306e\u307f 0 \u3067\u306a\u3044\u671f\u5f85\u5024\u3092\u6301\u3061\u307e\u3059. \u305d\u308c\u3067\u306f MCMC \u306b\u3088\u3063\u3066\u751f\u6210\u3055\u308c\u305f\u30c7\u30fc\u30bf\u5217\u306b\u3053\u306e\u95a2\u6570\u3092\u9069\u7528\u3057\u3066\u307f\u307e\u3057\u3087\u3046. from mhmcmc import MHMCMCSampler , GaussianStep from mhmcmc import autocorrelation import numpy as np a = 2.0 b = 0.2 def rosenbrock ( x ): return ( x [ 0 ] - a ) ** 2 + b * ( x [ 1 ] - x [ 0 ] ** 2 ) ** 2 def log_likelihood ( x ): return - ( rosenbrock ( x )) step = GaussianStep ( 5.0 ) x0 = np . zeros ( 2 ) model = MHMCMCSampler ( log_likelihood , step ) model . initialize ( x0 ) sample = model . generate ( 101000 ) sample = sample [ 1000 :,:] k , corr = autocorrelation ( sample ) import matplotlib.pyplot as plt fig = plt . figure ( figsize = ( 8 , 6 )) ax1 = fig . add_subplot ( 2 , 1 , 1 ) ax1 . plot ( k , corr [:, 0 ], marker = '' ) ax1 . set_xlim ([ - 800 , 800 ]) ax1 . set_ylabel ( 'autocorr for x0' ) ax2 = fig . add_subplot ( 2 , 1 , 2 ) ax2 . plot ( k , corr [ 0 , 1 ], marker = '' ) ax2 . set_xlim ([ - 800 , 800 ]) ax2 . set_ylabel ( 'autocorr for x1' ) ax2 . set_xlabel ( 'displacement: k' ) fig . tight_layout () plt . show () \u8a08\u7b97\u7d50\u679c \u51fa\u529b\u3055\u308c\u305f\u30b0\u30e9\u30d5\u3092\u898b\u308b\u3068 \\(k=0\\) \u4ee5\u5916\u306b\u3082\u6709\u610f\u306b 0 \u3067\u306a\u3044\u5024\u3092\u6301\u3064\u3053\u3068\u304c\u5206\u304b\u308a\u307e\u3059. \u3053\u306e\u30b1\u30fc\u30b9\u3067\u306f \\(x_{[0]}\\) \u3067\u3082, \\(x_{[1]}\\) \u3067\u3082, \u304a\u304a\u3088\u305d \\(k=200\\) \u7a0b\u5ea6\u3067\u307b\u307c 0 \u306b\u306a\u308a\u307e\u3059. \u3064\u307e\u308a, \u30c7\u30fc\u30bf\u3092\u3059\u3079\u3066\u4f7f\u3046\u306e\u3067\u306f\u306a\u304f 200 \u500b\u7a0b\u5ea6\u304a\u304d\u306b\u4f7f\u3046\u3053\u3068\u3067, \u76f8\u95a2\u304c\u307b\u307c 0 \u306e\u4e71\u6570\u3068\u307f\u306a\u305b\u308b\u3068\u671f\u5f85\u3067\u304d\u307e\u3059.","title":"\u81ea\u5df1\u76f8\u95a2\u95a2\u6570"},{"location":"mcmc/chain_convergence/#t-_1","text":"\u4ee5\u4e0a\u306e\u3053\u3068\u3092\u3075\u307e\u3048\u3066, \u3082\u3046\u4e00\u5ea6 t-\u691c\u5b9a\u3092\u5b9f\u65bd\u3057\u3066\u307f\u307e\u3059. \u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u7dcf\u6570\u306f 10\u2075 \u500b\u3067\u3059\u304c, 200 \u500b\u304a\u304d\u306b\u30c7\u30fc\u30bf\u3092\u63a1\u7528\u3059\u308b\u306e\u3067\u72ec\u7acb\u306a\u30b5\u30f3\u30d7\u30eb\u3068\u307f\u306a\u305b\u308b\u7dcf\u30c7\u30fc\u30bf\u6570\u306f 500 \u500b\u3067\u3059. \u3053\u308c\u3092 2 \u3064\u306b\u5206\u3051\u3066\u5e73\u5747\u5024\u304c\u7b49\u3057\u3044\u304b\u3069\u3046\u304b\u3092 t-\u691c\u5b9a\u3067\u691c\u8a3c\u3057\u307e\u3059. from mhmcmc import MHMCMCSampler , GaussianStep import numpy as np a = 2.0 b = 0.2 def rosenbrock ( x ): return ( x [ 0 ] - a ) ** 2 + b * ( x [ 1 ] - x [ 0 ] ** 2 ) ** 2 def log_likelihood ( x ): return - ( rosenbrock ( x )) step = GaussianStep ( 5.0 ) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . zeros ( 2 ) model . initialize ( x0 ) sample = model . generate ( 101000 ) sample = sample [ 1000 :: 200 ] m , n = sample . shape m20 , m50 = int ( m / 5 ), int ( m / 2 ) from scipy import stats tv , pv = stats . ttest_ind ( sample [: m20 ,:], sample [ m50 :( m50 + m20 ),:], equal_var = False ) print ( f 'probability(x0[former] == x0[latter]): { pv [ 0 ] : g } ' ) print ( f 'probability(x1[former] == x1[latter]): { pv [ 1 ] : g } ' ) \u8a08\u7b97\u7d50\u679c probability(x0[former] == x0[latter]): 0.190402 probability(x1[former] == x1[latter]): 0.966328 \u524d\u56de\u3068\u5927\u304d\u304f\u5909\u308f\u3063\u3066, \u5e73\u5747\u5024\u304c\u540c\u3058\u5206\u5e03\u304b\u3089\u306e\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3060\u3068\u307f\u306a\u305b\u308b\u78ba\u7387\u304c\u305d\u308c\u305e\u308c 19%, 96% \u3068\u3044\u3046\u7d50\u679c\u306b\u306a\u308a\u307e\u3057\u305f. \u524d\u534a\u3068\u5f8c\u534a\u3067\u6709\u610f\u306b\u9055\u3046\u3068\u306f\u307f\u306a\u305b\u306a\u3044\u7a0b\u5ea6\u306e\u5024\u306b\u306a\u3063\u3066\u3044\u307e\u3059. \u4eca\u56de\u306e\u4f8b\u306e\u3088\u3046\u306b, \u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u305f\u30c7\u30fc\u30bf\u9593\u306e\u76f8\u95a2\u304c\u5f71\u97ff\u3092\u4e0e\u3048\u308b\u5834\u5408\u306b\u306f, \u30c7\u30fc\u30bf\u3092\u9593\u5f15\u3044\u3066\u72ec\u7acb\u3057\u305f\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3060\u3068\u307f\u306a\u305b\u308b\u30c7\u30fc\u30bf\u3060\u3051\u3092\u4f7f\u7528\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059. 5","title":"\u5e73\u5747\u5024\u306e\u691c\u5b9a: t-\u691c\u5b9a (\u3082\u3046\u4e00\u5ea6)"},{"location":"mcmc/chain_convergence/#-","text":"\u6642\u9593\u304c\u8a31\u305b\u3070 MCMC \u3092\u8907\u6570\u56de\u5b9f\u884c\u3057\u3066\u6bd4\u8f03\u3092\u3059\u308b\u3068\u3044\u3046\u65b9\u6cd5\u304c\u4f7f\u3048\u307e\u3059. \u305d\u308c\u305e\u308c\u306e\u30de\u30eb\u30b3\u30d5\u9023\u9396\u5185\u90e8\u306e\u5206\u6563 (within-chain) \u306b\u6bd4\u3079\u3066, \u8907\u6570\u306e\u30de\u30eb\u30b3\u30d5\u9023\u9396\u9593\u306e\u5206\u6563 (between-chain) \u304c\u5927\u304d\u3044\u5834\u5408\u306b\u306f\u5206\u5e03\u304c\u53ce\u675f\u3057\u3066\u3044\u306a\u3044\u3068\u307f\u306a\u3059\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u5408\u8a08 \\(M\\) \u56de\u306e MCMC \u3092\u5b9f\u884c\u3057, \u305d\u308c\u305e\u308c\u306e chain \u3067 \\(N\\) \u500b\u306e\u30c7\u30fc\u30bf\u3092\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u305f\u3068\u3057\u307e\u3059. \u3053\u306e\u3068\u304d, within-chain variance \\(\\sigma^2_w\\) \u3068 between-chain variance \\(\\sigma^2_b\\) \u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u66f8\u3051\u307e\u3059. \\[ \\left\\{~\\begin{aligned} \\sigma^2_w &= \\frac{1}{M(n-1)}\\sum_{m=1}^M\\sum_{i=1}^n (x_{m,i} - \\bar{x}_{m})^2 \\\\ \\sigma^2_b &= \\frac{n}{M-1}\\sum_{m=1}^M (\\bar{x}_m - \\bar{x})^2. \\end{aligned}\\right. \\] \u3053\u3053\u3067 \\(\\bar{x}_m\\) \u306f\u5404 chain \u5185\u3067\u306e\u5e73\u5747\u5024, \\(\\bar{x}\\) \u306f\u30c7\u30fc\u30bf\u5168\u3066\u306b\u5bfe\u3059\u308b\u5e73\u5747\u5024\u3067\u3059. \u3053\u3053\u3067\u5168\u4f53\u306e\u5206\u6563 6 7 \u3068 between-chain variance \\(\\sigma^2_b\\) \u306e\u6bd4\u306e\u5e73\u65b9\u6839\u3068\u3057\u3066 \\(\\hat{R}\\) \u3092\u5b9a\u7fa9\u3057\u307e\u3059. \\[ \\hat{R} = \\sqrt{1 + \\frac{\\sigma^2_b - \\sigma^2_w}{n\\sigma^2_w}}. \\] \u3053\u306e\u91cf\u306f \\(\\sigma^2_b = \\sigma^2_w\\) \u306e\u3068\u304d\u306b \\(\\hat{R} \\simeq 1\\) \u3068\u306a\u308a\u307e\u3059. \u6163\u7fd2\u3068\u3057\u3066 \\(\\hat{R} \\lesssim 1.1\\) \u2013 \\(1.2\\) \u307b\u3069\u3067\u3042\u308c\u3070\u53ce\u675f\u3057\u305f\u3068\u8003\u3048\u3066\u3088\u3044\u3068\u3044\u3046\u3053\u3068\u306b\u306a\u3063\u3066\u3044\u307e\u3059. \\(\\hat{R}\\) \u3092\u3064\u304b\u3063\u3066\u53ce\u675f\u3057\u305f\u3068\u8a00\u3048\u308b\u304b\u3069\u3046\u304b\u3092\u5224\u5b9a\u3057\u3066\u307f\u307e\u3059. \u4ee5\u4e0b\u306b 4 \u3064\u306e MCMC chains \u3092\u751f\u6210\u3057\u3066 \\(\\hat{R}\\) \u3092\u8a08\u7b97\u3059\u308b\u30b5\u30f3\u30d7\u30eb\u3092\u793a\u3057\u307e\u3059. from mhmcmc import MHMCMCSampler , GaussianStep import numpy as np a = 2.0 b = 0.2 def rosenbrock ( x ): return ( x [ 0 ] - a ) ** 2 + b * ( x [ 1 ] - x [ 0 ] ** 2 ) ** 2 def log_likelihood ( x ): return - ( rosenbrock ( x )) nchain = 4 step = GaussianStep ( 5.0 ) samples = [] for n in range ( nchain ): x0 = np . zeros ( 2 ) + n model = MHMCMCSampler ( log_likelihood , step ) model . initialize ( x0 ) sample = model . generate ( 101000 ) samples . append ( sample [ 1000 ::]) samples = np . stack ( samples ) nsample = samples . shape [ 1 ] intra_mean = samples . mean ( axis = 1 ) global_mean = samples . mean ( axis = ( 0 , 1 )) . reshape (( 1 , 2 )) within_var = samples . var ( axis = 1 ) . mean ( axis = 0 ) between_var = nsample * np . var ( intra_mean - global_mean , axis = 0 ) Rhat = np . sqrt ( 1 + ( between_var / within_var - 1 ) / nsample ) print ( f 'Rhat values: { Rhat } ' ) \u8a08\u7b97\u7d50\u679c Rhat values: [1.00044594 1.00048218] \u8a08\u7b97\u3057\u305f \\(\\hat{R}\\) \u306e\u5024\u306f\u307b\u307c 1 \u306b\u8fd1\u304f, \u5341\u5206\u306b\u53ce\u675f\u3057\u305f\u3068\u5224\u5b9a\u3057\u3066\u3082\u3088\u3055\u305d\u3046\u3067\u3059. 8 \u30d0\u30ca\u30ca\u578b\u306e\u30dd\u30c6\u30f3\u30b7\u30e3\u30eb\u3092\u6301\u3064\u95a2\u6570\u3067, \u6570\u5024\u6700\u9069\u5316\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306e\u6027\u80fd\u8a55\u4fa1\u3084\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u3067\u3088\u304f\u4f7f\u308f\u308c\u307e\u3059. \u500b\u306e\u5546\u306e\u30b5\u30f3\u30d7\u30eb\u3068\u3057\u3066\u3053\u306e\u95a2\u6570\u3092\u63a1\u7528\u3057\u305f\u6df1\u3044\u7406\u7531\u306f\u7279\u306b\u3042\u308a\u307e\u305b\u3093. \u21a9 \\(x\\) \u306e \\(i\\) \u756a\u76ee\u306e\u8981\u7d20\u3092 \\(x_{[i]}\\) \u3067\u8868\u3057\u307e\u3059. \u21a9 \u3053\u306e\u6642\u70b9\u3067\u306f\u30c7\u30fc\u30bf\u3092\u9593\u5f15\u3044\u3066\u3044\u306a\u3044\u306e\u3067, \u3088\u308a\u7d30\u304b\u304f\u8868\u793a\u3055\u305b\u308b\u3068\u30e9\u30f3\u30c0\u30e0\u30a6\u30a9\u30fc\u30af\u7684\u306b\u52d5\u3044\u3066\u3044\u308b\u69d8\u5b50\u304c\u898b\u3048\u3066\u304d\u307e\u3059. \u5927\u304d\u306a\u30b9\u30b1\u30fc\u30eb\u3067\u898b\u3066\u3044\u308b\u306e\u3067\u6f70\u3055\u308c\u3066\u3044\u308b\u3060\u3051\u3067\u3059. \u21a9 \u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u6570\u304c\u8db3\u308a\u305a\u672c\u5f53\u306b\u53ce\u675f\u3057\u3066\u3044\u306a\u3044\u306e\u3067\u306f\uff1f\u3068\u601d\u3046\u304b\u3082\u3057\u308c\u307e\u305b\u3093. \u8a66\u3057\u306b\u6570\u3092 5 \u500d\u306b\u5897\u3084\u3057\u3066\u307f\u305f\u3068\u3053\u308d\u78ba\u7387\u306f\u3055\u3089\u306b\u6e1b\u308a\u307e\u3057\u305f. \u30b5\u30f3\u30d7\u30eb\u6570\u304c\u5897\u3048\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u5dee\u304c\u3088\u308a\u6709\u610f\u306b\u306a\u3063\u305f\u3068\u5224\u5b9a\u3055\u308c\u305f\u3088\u3046\u3067\u3059. \u21a9 \u3061\u306a\u307f\u306b\u671f\u5f85\u5024 (\u5358\u7d14\u5e73\u5747) \u306e\u8a08\u7b97\u3067\u306f\u30c7\u30fc\u30bf\u306e\u76f8\u95a2\u306f\u5f71\u97ff\u3057\u307e\u305b\u3093 (\u53ce\u675f\u304c\u30c7\u30fc\u30bf\u6570\u306e\u308f\u308a\u306b\u306f\u9045\u304f\u306a\u308b\u3060\u3051). \u21a9 \u5168\u4f53\u306e\u5206\u6563\u306e \u201c\u63a8\u5b9a\u5024\u201d \u3068\u3057\u3066 \\(\\sigma^2_{bw} = \\left((n-1)\\sigma^2_w + \\sigma^2_b\\right)/n\\) \u3068\u3044\u3046\u5f0f\u3092\u4f7f\u3063\u3066\u3044\u308b\u3088\u3046\u3067\u3059. Gelman et al. (2013) \u306b\u3088\u308b\u3068 \u201cThis quantity overestimates the marginal posterior variance assuming the starting distributions in appropriately overdispersed, but is unbiased \u2026\u201d. \u3068\u306e\u3053\u3068\u3067\u3057\u305f. \u21a9 \u624b\u5143\u3067\u5168\u4f53\u306e\u5206\u6563\u3092\u8a08\u7b97\u3092\u3057\u3066\u307f\u305f\u3089 \\(\\sigma^2_{bw} = \\left((n-1)\\sigma^2_w + (1-M^{-1})\\sigma^2_b\\right)/(n-M^{-1})\\) \u306b\u306a\u308a\u307e\u3057\u305f. \u305f\u3060\u3057, \u30c7\u30fc\u30bf\u306e\u76f8\u95a2\u306b\u3064\u3044\u3066\u306f\u4f55\u3082\u8003\u616e\u3057\u3066\u3044\u307e\u305b\u3093. \\(\\sigma^2_w\\) \u3068 \\(\\sigma^2_b\\) \u306e\u91cd\u307f\u4ed8\u304d\u5e73\u5747\u306b\u306a\u308b\u3068\u3044\u3046\u7d50\u679c\u306f\u78ba\u8a8d\u3067\u304d\u307e\u3057\u305f. \u21a9 \u305f\u3060\u3057\u30d1\u30e9\u30e1\u30bf\u3092\u5909\u3048\u3066\u8a08\u7b97\u3057\u3066\u307f\u308b\u3068 \\(\\hat{R} \\simeq 1\\) \u306e\u5834\u5408\u3067\u3082\u30c8\u30ec\u30fc\u30b9\u3092\u898b\u308b\u3068\u307e\u3063\u305f\u304f\u53ce\u675f\u3057\u3066\u3044\u306a\u3044\u3068\u3044\u3046\u30b1\u30fc\u30b9\u3082\u3042\u308a\u307e\u3057\u305f. \u91cd\u8981\u306a\u8a08\u7b97\u3067\u306f\u904e\u4fe1\u305b\u305a\u306b\u30c8\u30ec\u30fc\u30b9\u3084\u76f8\u95a2\u3082\u78ba\u8a8d\u3057\u3066\u304a\u3044\u305f\u307b\u3046\u304c\u3088\u3044\u3068\u601d\u3044\u307e\u3059. \u21a9","title":"\u9023\u9396\u5185-\u9023\u9396\u9593\u5206\u6563\u306e\u8a08\u7b97"},{"location":"mcmc/generate_random_variables/","text":"\u4e71\u6570\u3092\u751f\u6210\u3059\u308b \u3053\u3053\u3067\u306f\u4efb\u610f\u306e\u78ba\u7387\u5206\u5e03\u95a2\u6570\u306b\u5f93\u3046\u4e71\u6570\u3092\u767a\u751f\u3055\u305b\u308b\u65b9\u6cd5\u3068\u3057\u3066, \u9006\u95a2\u6570\u6cd5\u3068\u68c4\u5374\u6cd5\u3068\u3044\u3046 2 \u3064\u306e\u65b9\u6cd5\u3092\u7d39\u4ecb\u3057\u307e\u3059. MCMC \u306e\u7406\u89e3\u306b\u306f\u3055\u307b\u3069\u91cd\u8981\u3067\u306f\u306a\u3044\u306e\u3067\u3059\u304c, MCMC \u3068\u5bfe\u6bd4\u3055\u305b\u308b\u624b\u6cd5\u3068\u3057\u3066\u3053\u3053\u3067\u7c21\u5358\u306b\u89e6\u308c\u3066\u304a\u304d\u307e\u3059. \u524d\u63d0/\u4e00\u69d8\u4e71\u6570\u3092\u751f\u6210\u3059\u308b\u95a2\u6570 \u524d\u63d0\u3068\u3057\u3066\u79c1\u305f\u3061\u306f \\([0,1)\\) \u306e\u7bc4\u56f2\u306b\u4e00\u69d8\u306b\u5206\u5e03\u3059\u308b\u4e71\u6570\u3092\u751f\u6210\u3067\u304d\u308b\u3068\u3057\u307e\u3059. \u307e\u305a, \u4f55\u3089\u304b\u306e\u4e71\u6570\u3092\u767a\u751f\u3055\u305b\u308b\u80fd\u529b\u304c\u306a\u3044\u3068\u4ee5\u4e0b\u306e\u8b70\u8ad6\u306f\u6210\u7acb\u3057\u307e\u305b\u3093. 1 Python \u3067\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u3057\u3066\u4e71\u6570\u751f\u6210\u5668\u3092\u751f\u6210\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. from numpy.random import default_rng # \u4e71\u6570\u751f\u6210\u5668 gen = default_rng ( 2021 ) # seed \u5024\u3092\u4e0e\u3048\u3066\u521d\u671f\u5316\u3059\u308b u = gen . uniform ( 0 , 1 , size = ( 5 )) print ( u ) \u8a08\u7b97\u7d50\u679c [ 0.75694783 0.94138187 0.59246304 0.31884171 0.62607384 ] \u6563\u5e03\u56f3\u3092\u4f5c\u6210\u3057\u3066\u751f\u6210\u3055\u308c\u305f\u4e71\u6570\u304c\u3069\u3093\u306a\u5206\u5e03\u306b\u306a\u3063\u3066\u3044\u308b\u306e\u304b\u78ba\u8a8d\u3057\u3066\u307f\u307e\u3057\u3087\u3046. \\([0,1)\\) \u306e\u7bc4\u56f2\u306b\u4e00\u69d8\u306b\u5206\u5e03\u3057\u3066\u3044\u308b\u3053\u3068\u304c\u78ba\u8a8d\u3067\u304d\u308b\u3068\u601d\u3044\u307e\u3059. import matplotlib.pyplot as plt from numpy.random import default_rng gen = default_rng ( 2021 ) fig = plt . figure () ax = fig . add_subplot () ax . plot ( gen . uniform ( 0 , 1 , size = ( 1000 )), ls = '' , marker = '.' ) ax . set_ylabel ( 'uniform random value' ) ax . set_xlabel ( 'sample number' ) plt . tight_layout () plt . show () \u8a08\u7b97\u7d50\u679c numpy \u306b\u306f\u3055\u307e\u3056\u307e\u306a\u78ba\u7387\u5206\u5e03\u306b\u5f93\u3046\u4e71\u6570\u3092\u751f\u6210\u3059\u308b\u305f\u3081\u306e\u95a2\u6570\u304c\u5099\u308f\u3063\u3066\u3044\u307e\u3059\u304c, \u3053\u3053\u3067\u306f\u4e00\u69d8\u4e71\u6570 uniform() \u3092\u4f7f\u3063\u3066\u4efb\u610f\u306e\u78ba\u7387\u5206\u5e03\u306b\u5f93\u3046\u4e71\u6570\u3092\u751f\u6210\u3059\u308b\u65b9\u6cd5\u306b\u3064\u3044\u3066\u7d39\u4ecb\u3057\u307e\u3059. \u4e71\u6570\u751f\u6210\u5668\u3092\u30ab\u30b9\u30bf\u30de\u30a4\u30ba\u3057\u305f\u3044\u5834\u5408 \u4e0a\u8a18\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u306f\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u4e71\u6570\u751f\u6210\u5668\u3092\u4f7f\u7528\u3057\u307e\u3057\u305f. \u4e71\u6570\u751f\u6210\u5668\u3092\u81ea\u5206\u3067\u30ab\u30b9\u30bf\u30de\u30a4\u30ba\u3057\u305f\u3044\u5834\u5408\u306b\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b Generator() \u3092\u547c\u3073\u51fa\u3057\u3066\u304f\u3060\u3055\u3044. from numpy.random import Generator , PCG64 gen = Generator ( PCG64 ( 2021 )) # PCG64 \u306b seed \u5024\u3092\u4e0e\u3048\u3066\u521d\u671f\u5316\u3059\u308b \u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f PCG64 \u304c\u4f7f\u7528\u3055\u308c\u307e\u3059\u304c, \u3082\u3057\u30e1\u30eb\u30bb\u30f3\u30cc\u30c4\u30a4\u30b9\u30bf\u3092\u4f7f\u7528\u3057\u305f\u3044\u5834\u5408\u306b\u306f MT19937 \u3092\u4f7f\u7528\u3057\u3066\u304f\u3060\u3055\u3044. from numpy.random import Generator , MT19937 gen = Generator ( MT19937 ( 2021 )) # MT19937 \u306b seed \u5024\u3092\u4e0e\u3048\u3066\u521d\u671f\u5316\u3059\u308b \u9006\u95a2\u6570\u6cd5 \u9006\u95a2\u6570\u6cd5\u306b\u3088\u308b\u4e71\u6570\u751f\u6210 \u9006\u95a2\u6570\u6cd5\u3068\u306f\u4ee5\u4e0b\u306e\u624b\u7d9a\u304d\u306b\u3088\u3063\u3066\u4e71\u6570\u3092\u751f\u6210\u3059\u308b\u65b9\u6cd5\u3067\u3059. \u7d2f\u7a4d\u78ba\u7387\u5206\u5e03 \\(C(x) = \\int P(x') \\mathrm{d}x'\\) \u306e\u9006\u95a2\u6570 \\(C^{-1}(y)\\) \u3092\u7528\u610f\u3059\u308b. 2 \\([0,1)\\) \u306e\u4e00\u69d8\u5206\u5e03 \\({\\operatorname{Unif}}(0,1)\\) \u304b\u3089 \\(u\\) \u3092\u30b5\u30f3\u30d7\u30eb\u3059\u308b. \\({x'} \\gets C^{-1}(u)\\) \u306b\u3088\u3063\u3066 \\({x'}\\) \u3092\u5b9a\u7fa9\u3059\u308b. \u7d2f\u7a4d\u78ba\u7387\u5206\u5e03 \\(C(x)\\) \u306f\u5358\u8abf\u5897\u52a0\u95a2\u6570\u306a\u306e\u3067\u5e38\u306b\u9006\u95a2\u6570\u3092\u6301\u3061\u307e\u3059. \\(C(x)\\) \u306e range \u306f \\([0,1)\\) \u306a\u306e\u3067, \u9006\u95a2\u6570 \\(C^{-1}(y)\\) \u306e domain \u306f \\([0,1)\\) \u306a\u306e\u3067 \\(u\\) \u3092\u5165\u529b\u3068\u3057\u3066\u4e0e\u3048\u308b\u3068, \\(C^{-1}(y)\\) \u306e domain \u5168\u4f53\u306b\u5bfe\u3057\u3066\u4e00\u69d8\u306e\u5bc6\u5ea6\u3067\u5165\u529b\u3092\u4e0e\u3048\u308b\u3053\u3068\u306b\u306a\u308a\u307e\u3059. \u3053\u3053\u3067 \\(u\\) \u3092 \\(\\mathrm{d}u\\) \u3060\u3051\u52d5\u304b\u3057\u305f\u3068\u304d\u306b \\({x'}\\) \u304c\u3069\u308c\u3060\u3051\u52d5\u304f\u304b\u3092\u8003\u3048\u308b\u3068, \\[ \\mathrm{d}{x'} = \\frac{\\mathrm{d}C^{-1}(u)}{\\mathrm{d}u} \\mathrm{d}u = \\frac{1}{P({x'})} \\mathrm{d}u. \\] \u3068\u306a\u308a\u307e\u3059. \\(u\\) \u21c9 \\({x'}\\) \u306e\u5909\u63db\u3067 \\(\\mathrm{d}u\\) \u306e\u5e45\u306b\u4e00\u69d8\u306b\u5206\u5e03\u3057\u3066\u3044\u305f\u30c7\u30fc\u30bf\u306f \\(\\mathrm{d}{x'} = P({x'})^{-1}\\mathrm{d}u\\) \u306e\u7bc4\u56f2\u306b\u5206\u5e03\u3059\u308b\u3053\u3068\u306b\u306a\u308b\u306e\u3067, \\({x'}\\) \u306e\u7a7a\u9593\u3067\u306f\u5bc6\u5ea6\u306f \\(P({x'})\\) \u500d\u306b\u306a\u308a\u307e\u3059. \u3053\u308c\u306b\u3088\u3063\u3066, \u4e0a\u8a18\u306e\u5909\u63db\u306b\u3088\u3063\u3066\u5f97\u3089\u308c\u305f\u4e71\u6570 \\(x'\\) \u306e\u5206\u5e03\u306f\u306f\u78ba\u7387\u5206\u5e03\u95a2\u6570 \\(P(x)\\) \u306b\u5f93\u3044\u307e\u3059. \u9006\u95a2\u6570\u6cd5\u306e\u6982\u5ff5\u56f3\u3092\u4ee5\u4e0b\u306b\u793a\u3057\u307e\u3059. \u7d2f\u7a4d\u78ba\u7387\u5206\u5e03 \\(C(x)\\) \u3092\u9ed2\u5b9f\u7dda\u3067\u793a\u3057\u307e\u3057\u305f. \u3053\u3053\u3067 \\([0,1)\\) \u306e\u7bc4\u56f2\u3067\u4e00\u69d8\u306b\u5024\u3092\u30b5\u30f3\u30d7\u30eb\u3057\u3066, \u305d\u306e\u5024\u3092\u9ad8\u3055\u306b\u3082\u3061 \\(x\\) \u8ef8\u3068\u4e26\u884c\u306b\u306a\u7dda (\u9ec4\u8272) \u3092\u5f15\u304d\u307e\u3059. \u3053\u3053\u3067\u306f\u7dda\u3092 30 \u672c\u5f15\u3044\u3066\u3044\u307e\u3059. \u7dda\u304c \\(C(x)\\) \u3068\u3076\u3064\u304b\u3063\u305f\u3068\u3053\u308d\u3067 \\(x\\) \u8ef8\u306b\u843d\u3068\u3057\u307e\u3059. \u3053\u306e\u64cd\u4f5c\u306f \\(u\\) \u21c9 \\({x'}\\) \u306e\u5909\u63db\u306b\u76f8\u5f53\u3057\u3066\u3044\u307e\u3059. \u78ba\u7387\u5206\u5e03 \\(P(x)\\) \u306e\u5024\u304c\u5927\u304d\u3044\u3068\u3053\u308d\u3067\u306f \\(C(x)\\) \u306e\u50be\u304d\u304c\u5927\u304d\u304f\u306a\u308b\u305f\u3081, \\(x\\) \u8ef8\u4e0a\u3067\u306f\u9ec4\u8272\u3044\u7dda\u306e\u5bc6\u5ea6\u304c\u9ad8\u304f\u306a\u3063\u3066\u3044\u308b\u3053\u3068\u304c\u5206\u304b\u308a\u307e\u3059. \u6307\u6570\u5206\u5e03\u306b\u5f93\u3046\u4e71\u6570 \u9006\u95a2\u6570\u6cd5\u3092\u4f7f\u3063\u3066\u6307\u6570\u5206\u5e03\u306b\u5f93\u3046\u4e71\u6570\u3092\u751f\u6210\u3057\u3066\u307f\u307e\u3057\u3087\u3046. \u6307\u6570\u5206\u5e03\u3068\u306f \\(x \\geq 0\\) \u3067\u5b9a\u7fa9\u3055\u308c\u308b\u78ba\u7387\u5206\u5e03\u3067, \u6e1b\u8870\u306e\u901f\u3055\u3092\u793a\u3059\u30d1\u30e9\u30e1\u30bf\u3092 1 \u3064\u6301\u3061\u307e\u3059. \\[ {\\operatorname{Exponential}}(\\lambda): P(x;\\lambda) = \\lambda\\exp(-{\\lambda}x). \\] \u7d2f\u7a4d\u78ba\u7387\u5206\u5e03\u306f \\(C(x;\\lambda) = 1-\\exp(-{\\lambda}x)\\) \u3068\u306a\u308b\u306e\u3067, \u4e00\u69d8\u5206\u5e03\u304b\u3089\u751f\u6210\u3057\u305f\u4e71\u6570 \\(u\\) \u3092\u3064\u304b\u3063\u3066\u4ee5\u4e0b\u306e\u5909\u63db\u3092\u3059\u308b\u3053\u3068\u3067\u6307\u6570\u5206\u5e03\u306b\u5f93\u3046\u4e71\u6570\u3092\u751f\u6210\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \\[ x' \\gets -\\frac{1}{\\lambda}\\log(1-u). \\] \u4ee5\u4e0b\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u306f\u4e00\u69d8\u4e71\u6570 \\(u\\) \u3092 1000 \u500b\u751f\u6210\u3057\u3066, \\(\\lambda = 3\\) \u306e\u6307\u6570\u5206\u5e03\u306b\u5f93\u3046\u4e71\u6570\u306b\u5909\u63db\u3057\u3066\u3044\u307e\u3059. \u751f\u6210\u3057\u305f\u4e71\u6570\u306e\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u3068\u78ba\u7387\u5206\u5e03 \\(P(x;\\lambda)\\) \u3092\u540c\u3058\u56f3\u306b\u30d7\u30ed\u30c3\u30c8\u3057\u3066\u76f8\u9055\u304c\u306a\u3044\u3053\u3068\u3092\u78ba\u8a8d\u3057\u3066\u3044\u307e\u3059. import matplotlib.pyplot as plt from numpy.random import default_rng import numpy as np gen = default_rng ( 2021 ) lam = 3.0 X = np . linspace ( 0 , 5 , 100 ) Y = lam * np . exp ( - lam * X ) u = gen . uniform ( 0 , 1 , size = ( 10000 )) x = - 1.0 / lam * np . log ( 1.0 - u ) fig = plt . figure () ax = fig . add_subplot () ax . hist ( x , bins = 50 , density = True ) ax . plot ( X , Y ) ax . set_ylabel ( 'frequency' ) ax . set_xlabel ( 'variable: x' ) plt . tight_layout () plt . show () \u8a08\u7b97\u7d50\u679c \u6b63\u898f\u5206\u5e03\u306b\u5f93\u3046\u4e71\u6570 \u2014 Box-Muller \u5909\u63db \u3082\u3046\u3072\u3068\u3064, \u9006\u95a2\u6570\u6cd5\u306e\u30b5\u30f3\u30d7\u30eb\u3068\u3057\u3066\u5e73\u5747\u304c 0 \u3067\u5206\u6563\u304c 1 \u306e\u6a19\u6e96\u6b63\u898f\u5206\u5e03 \\(\\mathcal{N}(0,1)\\) \u3092\u5c0e\u51fa\u3057\u307e\u3059. \u6a19\u6e96\u6b63\u898f\u5206\u5e03\u306f\u7d2f\u7a4d\u78ba\u7387\u5206\u5e03\u3092\u967d\u306b\u8a08\u7b97\u3059\u308b\u3053\u3068\u306f\u3067\u304d\u306a\u3044\u305f\u3081, \u9006\u95a2\u6570\u6cd5\u3092\u5358\u7d14\u306b\u5f53\u3066\u306f\u3081\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u305b\u3093. \u3057\u304b\u3057, Box-Muller \u5909\u63db\u3068\u3044\u3046\u624b\u6cd5\u3092\u4f7f\u3046\u3053\u3068\u3067\u4e00\u69d8\u5206\u5e03\u306b\u5f93\u3046 2 \u3064\u306e\u4e71\u6570\u304b\u3089 2 \u3064\u306e\u72ec\u7acb\u3057\u305f\u6a19\u6e96\u6b63\u898f\u5206\u5e03\u304b\u3089\u306a\u308b\u78ba\u7387\u5909\u6570 \\(x\\) , \\(y\\) \u3092\u5f97\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u307e\u305a\u306f, \\(x\\) , \\(y\\) \u306e\u540c\u6642\u78ba\u7387\u5206\u5e03 \\(P(x,y)\\) \u3092\u8003\u3048\u307e\u3059. \\[ P(x,y) = \\frac{1}{2\\pi}\\exp\\left(-\\frac{x^2+y^2}{2}\\right). \\] \u3053\u3053\u3067, \\(x = r\\cos\\theta\\) , \\(y = r\\sin\\theta\\) \u3068\u304a\u3044\u3066\u6975\u5ea7\u6a19\u7cfb\u306b\u5909\u63db\u3057\u3066\u304b\u3089\u7d2f\u7a4d\u78ba\u7387\u5206\u5e03\u3092\u8003\u3048\u307e\u3059. \u305f\u3060\u3057, \u78ba\u7387\u306f \\(\\theta\\) \u306b\u306f\u4f9d\u5b58\u3057\u306a\u3044\u305f\u3081 \\([0,2\\pi)\\) \u306b\u4e00\u69d8\u306b\u5206\u5e03\u3057\u3066\u3044\u308b\u3068\u8003\u3048\u3066\u3088\u3055\u305d\u3046\u3067\u3059. \u554f\u984c\u3092\u7c21\u5358\u306b\u3059\u308b\u305f\u3081\u306b \\(\\theta\\) \u306f\u7a4d\u5206\u3057\u3066\u6d88\u3057\u3066\u3057\u307e\u3063\u3066, \\(r\\) \u306b\u5bfe\u3059\u308b\u7d2f\u7a4d\u78ba\u7387\u5206\u5e03\u3092\u8003\u3048\u307e\u3059. \\[ C(r) = \\frac{1}{2\\pi}\\int_0^{2\\pi}\\mathrm{d}\\theta' \\int_0^r\\mathrm{d}r' r\\exp\\left(-\\frac{r^2}{2}\\right) = 1 - \\exp\\left(-\\frac{r^2}{2}\\right). \\] \u3053\u308c\u3067\u5148\u307b\u3069\u3068\u540c\u69d8\u306b\u9006\u95a2\u6570\u6cd5\u3092\u4f7f\u3046\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \\([0,1)\\) \u306e\u4e00\u69d8\u5206\u5e03\u306b\u5f93\u3046\u4e71\u6570 \\(u\\) , \\(v\\) \u3092\u4f7f\u3063\u3066 \\(r\\) , \\(\\theta\\) \u306b\u5909\u63db\u3057\u307e\u3059. \u3055\u3089\u306b \\(r\\) , \\(\\theta\\) \u3092\u76f4\u884c\u5ea7\u6a19\u3067\u306e\u5024\u306b\u5909\u63db\u3059\u308b\u3053\u3068\u3067, \u6b63\u898f\u5206\u5e03\u306b\u5f93\u3046\u78ba\u7387\u5909\u6570 \\(x\\) , \\(y\\) \u3092\u5f97\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \\[ \\left\\{~\\begin{aligned} r &= \\sqrt{-2\\log(1-u)} \\\\ \\theta &= 2\\pi v \\end{aligned}\\right. \\quad\\Rightarrow\\quad \\left\\{~\\begin{aligned} x &= r\\cos\\theta \\\\ y &= r\\sin\\theta \\end{aligned}\\right.. \\] \u4ee5\u4e0b\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u306f\u4e00\u69d8\u5206\u5e03\u304b\u3089 Box-Muller \u5909\u63db\u306b\u3088\u3063\u3066\u30b5\u30f3\u30d7\u30eb\u3057\u305f \\(x\\) \u306e\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u3068\u6a19\u6e96\u6b63\u898f\u5206\u5e03\u306e\u78ba\u7387\u5206\u5e03\u95a2\u6570\u3092\u540c\u3058\u56f3\u306b\u30d7\u30ed\u30c3\u30c8\u3057\u3066\u76f8\u9055\u304c\u306a\u3044\u3053\u3068\u3092\u78ba\u8a8d\u3057\u3066\u3044\u307e\u3059. import matplotlib.pyplot as plt from numpy.random import default_rng import numpy as np gen = default_rng ( 2021 ) X = np . linspace ( - 5 , 5 , 500 ) Y = np . exp ( - X * X / 2.0 ) / np . sqrt ( 2 * np . pi ) u = gen . uniform ( 0 , 1 , size = ( 30000 )) v = gen . uniform ( 0 , 1 , size = ( 30000 )) r = np . sqrt ( - 2 * np . log ( 1 - u )) t = 2 * np . pi * v x = r * np . cos ( t ) y = r * np . sin ( t ) fig = plt . figure () ax = fig . add_subplot () ax . hist ( x , bins = 50 , density = True ) ax . plot ( X , Y ) ax . set_ylabel ( 'frequency' ) ax . set_xlabel ( 'variable: x' ) plt . tight_layout () plt . show () \u8a08\u7b97\u7d50\u679c \u9006\u95a2\u6570\u6cd5\u306f\u7279\u5b9a\u306e\u78ba\u7387\u5206\u5e03\u306b\u5f93\u3046\u4e71\u6570\u3092\u751f\u6210\u3059\u308b\u65b9\u6cd5\u3068\u3057\u3066\u6975\u3081\u3066\u5f37\u529b\u3067\u3059. \u3057\u304b\u3057\u306a\u304c\u3089, \u9006\u95a2\u6570\u6cd5\u3092\u9069\u7528\u3059\u308b\u305f\u3081\u306b\u306f\u7d2f\u7a4d\u78ba\u7387\u5206\u5e03\u306e\u9006\u95a2\u6570\u3092\u52b9\u7387\u3088\u304f\u8a08\u7b97\u3067\u304d\u308b\u3068\u3044\u3046\u6761\u4ef6\u3092\u6e80\u305f\u3059\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059. \u9650\u3089\u308c\u305f\u30af\u30e9\u30b9\u306e\u78ba\u7387\u5206\u5e03\u306b\u3057\u304b\u9069\u7528\u3059\u308b\u3053\u3068\u306f\u3067\u304d\u307e\u305b\u3093. \u68c4\u5374\u6cd5 \u68c4\u5374\u6cd5\u306b\u3088\u308b\u4e71\u6570\u751f\u6210 \u68c4\u5374\u6cd5\u306f\u6975\u3081\u3066\u30b7\u30f3\u30d7\u30eb\u306a\u624b\u7d9a\u304d\u306b\u3088\u3063\u3066\u4e71\u6570\u3092\u751f\u6210\u3059\u308b\u65b9\u6cd5\u3067\u3059. \u4f8b\u3048\u3070\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u624b\u7d9a\u304d\u306b\u3088\u3063\u3066\u751f\u6210\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u4e00\u69d8\u5206\u5e03\u304b\u3089\u5019\u88dc \\(x\\) \u3092\u30b5\u30f3\u30d7\u30eb\u3059\u308b. \\([0,\\alpha)\\) \u306e\u4e00\u69d8\u5206\u5e03 \\({\\operatorname{Unif}}(0,\\alpha)\\) \u304b\u3089 \\(u\\) \u3092\u30b5\u30f3\u30d7\u30eb\u3059\u308b. 3 \\(u \\leq P(x)\\) \u3067\u3042\u308c\u3070 \\(x\\) \u3092\u63a1\u7528\u3059\u308b. \u305d\u3046\u3067\u306a\u3051\u308c\u3070 \\(x\\) \u3092\u68c4\u5374\u3059\u308b. \u5fc5\u8981\u306a\u30b5\u30f3\u30d7\u30eb\u6570\u304c\u63c3\u3046\u307e\u3067\u4e0a\u8a18\u306e\u624b\u7d9a\u304d\u3092\u7e70\u308a\u8fd4\u3059. \\(P(x)\\) \u306e\u5024\u306b\u5fdc\u3058\u3066\u63a1\u7528\u3055\u308c\u308b\u78ba\u7387\u304c\u9ad8\u304f\u306a\u308b\u305f\u3081, \u5fc5\u7136\u7684\u306b \\(P(x)\\) \u306b\u5f93\u3046\u4e71\u6570\u3092\u5f97\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \\(P(x)\\) \u306e\u5024\u3092\u8a55\u4fa1\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308c\u3070\u9069\u7528\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u305f\u3081, \u307b\u307c\u4efb\u610f\u306e\u5f62\u72b6\u306e\u78ba\u7387\u5206\u5e03\u306b\u5bfe\u3057\u3066\u4f7f\u3046\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u307e\u305f, \u3053\u306e\u624b\u7d9a\u304d\u3067\u306f\u78ba\u7387\u5909\u6570 \\(x\\) , \\(x'\\) \u304c\u63a1\u7528\u3055\u308c\u308b\u78ba\u7387\u306e\u6bd4 \\(P(x)/P(x')\\) \u306b\u3088\u3063\u3066 \\(x\\) \u304c\u5f93\u3046\u78ba\u7387\u5206\u5e03\u306e\u5f62\u72b6\u304c\u6c7a\u307e\u308a\u307e\u3059. \u305d\u306e\u305f\u3081, \u78ba\u7387\u5206\u5e03\u95a2\u6570\u306e\u5f62\u72b6\u306f\u308f\u304b\u3063\u3066\u3044\u308b\u304c\u898f\u683c\u5316\u5b9a\u6570\u304c\u308f\u304b\u3089\u306a\u3044 4 \u3068\u3044\u3046\u30b1\u30fc\u30b9\u3067\u3082\u9069\u7528\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u4ee5\u4e0b\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u306f\u78ba\u7387\u5206\u5e03 \\(P(x) \\propto \\sqrt{1-x^2}\\) \u306b\u5f93\u3046\u4e71\u6570\u3092\u68c4\u5374\u6cd5\u306b\u3088\u3063\u3066\u751f\u6210\u3057\u3066\u3044\u307e\u3059. \u751f\u6210\u3057\u305f\u4e71\u6570\u306e\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u304c\u78ba\u7387\u5206\u5e03\u3068\u76f8\u9055\u304c\u306a\u3044\u3053\u3068\u3092\u78ba\u8a8d\u3057\u3066\u3044\u307e\u3059. \u307e\u305f\u5408\u8a08\u3067 30000 \u4ef6\u306e\u30c7\u30fc\u30bf\u3092\u751f\u6210\u3059\u308b\u305f\u3081\u306b\u5408\u8a08\u3067\u4f55\u56de\u4e0a\u8a18\u306e\u624b\u7d9a\u304d\u3092\u7e70\u308a\u8fd4\u3057\u305f\u306e\u304b\u3092\u8868\u793a\u3057\u307e\u3059. import matplotlib.pyplot as plt from numpy.random import default_rng import numpy as np gen = default_rng ( 2021 ) func = lambda x : np . sqrt ( np . clip ( 1 - x * x , 0 , 1 )) / np . pi * 2.0 X = np . linspace ( - 1.2 , 1.2 , 500 ) Y = func ( X ) trial = 0 x = [] while len ( x ) < 30000 : u = gen . uniform ( - 2 , 2 ) v = gen . uniform ( 0 , 2.0 / np . pi ) if v < func ( u ): x . append ( u ) trial += 1 x = np . array ( x ) print ( f 'total trial: { trial } ' ) fig = plt . figure () ax = fig . add_subplot () ax . hist ( x , bins = 50 , density = True ) ax . plot ( X , Y ) ax . set_ylabel ( 'frequency' ) ax . set_xlabel ( 'variable: x' ) plt . tight_layout () plt . show () \u8a08\u7b97\u7d50\u679c total trial : 76247 \u63d0\u6848\u5206\u5e03\u306b\u3088\u308b\u52b9\u7387\u5316 \u4e0a\u8a18\u306e\u624b\u7d9a\u304d\u3067\u306f \\(x\\) \u3092\u4e00\u69d8\u306a\u5206\u5e03\u304b\u3089\u30b5\u30f3\u30d7\u30eb\u3057\u3066\u3044\u307e\u3057\u305f. \u3053\u3053\u3067, \u6700\u521d\u306b \\(x\\) \u3092\u62bd\u51fa\u3059\u308b\u5206\u5e03\u306e\u3053\u3068\u3092\u63d0\u6848\u5206\u5e03\u3068\u547c\u3073\u307e\u3059. \u63d0\u6848\u5206\u5e03\u306f\u4e00\u69d8\u5206\u5e03\u3067\u3042\u308b\u5fc5\u8981\u306f\u3042\u308a\u307e\u305b\u3093. \u63d0\u6848\u5206\u5e03\u3068\u3057\u3066 \\(P(x)\\) \u306b\u8fd1\u3044\u5206\u5e03\u3092\u7528\u3044\u308b\u3053\u3068\u3067, \u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3092\u52b9\u7387\u5316\u3059\u308b (\u68c4\u5374\u7387\u3092\u4e0b\u3052\u308b) \u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u63d0\u6848\u5206\u5e03\u3068\u3057\u3066 \\(Q(x)\\) \u3092\u3082\u3061\u3044\u305f\u5834\u5408\u306e\u624b\u7d9a\u304d\u3092\u4ee5\u4e0b\u306b\u793a\u3057\u307e\u3059. 5 \u63d0\u6848\u5206\u5e03 \\(Q(x)\\) \u304b\u3089\u5019\u88dc \\(x\\) \u3092\u30b5\u30f3\u30d7\u30eb\u3059\u308b. 6 \\([0,\\alpha)\\) \u306e\u4e00\u69d8\u5206\u5e03 \\({\\operatorname{Unif}}(0,\\alpha)\\) \u304b\u3089 \\(u\\) \u3092\u30b5\u30f3\u30d7\u30eb\u3059\u308b. 7 \\(u \\leq P(x)/Q(x)\\) \u3067\u3042\u308c\u3070 \\(x\\) \u3092\u63a1\u7528\u3059\u308b. \u305d\u3046\u3067\u306a\u3051\u308c\u3070 \\(x\\) \u3092\u68c4\u5374\u3059\u308b. \u5fc5\u8981\u306a\u30b5\u30f3\u30d7\u30eb\u6570\u304c\u63c3\u3046\u307e\u3067\u4e0a\u8a18\u306e\u624b\u7d9a\u304d\u3092\u7e70\u308a\u8fd4\u3059. \u4ee5\u4e0b\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u306f\u6a19\u6e96\u6b63\u898f\u5206\u5e03\u3092\u63d0\u6848\u5206\u5e03\u3068\u3057\u3066\u63a1\u7528\u3057\u305f\u78ba\u7387\u5206\u5e03 \\(P(x) \\propto \\sqrt{1-x^2}\\) \u306b\u5f93\u3046\u4e71\u6570\u3092\u68c4\u5374\u6cd5\u306b\u3088\u3063\u3066\u751f\u6210\u3057\u3066\u3044\u307e\u3059. \u751f\u6210\u3057\u305f\u4e71\u6570\u306e\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u304c\u6c42\u3081\u308b\u78ba\u7387\u5206\u5e03\u3068\u76f8\u9055\u306a\u3044\u3053\u3068\u3092\u78ba\u8a8d\u3057\u3066\u3044\u307e\u3059. \u307e\u305f\u5408\u8a08\u3067 30000 \u4ef6\u306e\u30c7\u30fc\u30bf\u3092\u751f\u6210\u3059\u308b\u305f\u3081\u306b\u5408\u8a08\u3067\u4f55\u56de\u4e0a\u8a18\u306e\u624b\u7d9a\u304d\u3092\u7e70\u308a\u8fd4\u3057\u305f\u306e\u304b\u3092\u8868\u793a\u3057\u307e\u3059. import matplotlib.pyplot as plt from numpy.random import default_rng import numpy as np gen = default_rng ( 2021 ) func = lambda x : np . sqrt ( np . clip ( 1 - x * x , 0 , 1 )) / np . pi * 2.0 prop = lambda x : np . exp ( - x * x / 2.0 ) / np . sqrt ( 2.0 * np . pi ) X = np . linspace ( - 1.2 , 1.2 , 500 ) Y = func ( X ) trial = 0 x = [] while len ( x ) < 30000 : u = gen . normal ( 0 , 1 ) v = gen . uniform ( 0 , np . sqrt ( 8 / np . pi )) if v < func ( u ) / prop ( u ): x . append ( u ) trial += 1 x = np . array ( x ) print ( f 'total trial: { trial } ' ) fig = plt . figure () ax = fig . add_subplot () ax . hist ( x , bins = 50 , density = True ) ax . plot ( X , Y ) ax . set_ylabel ( 'frequency' ) ax . set_xlabel ( 'variable: x' ) plt . tight_layout () plt . show () \u8a08\u7b97\u7d50\u679c total trial : 47650 \u76ee\u7684\u3068\u3059\u308b\u5206\u5e03\u306b\u8fd1\u3044\u5206\u5e03\u3092\u63d0\u6848\u5206\u5e03\u3068\u3057\u3066\u7528\u3044\u308b\u3053\u3068\u306b\u3088\u3063\u3066, \u52b9\u7387\u7684\u306b\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3067\u304d\u3066\u3044\u308b\u3053\u3068\u304c\u5206\u304b\u308a\u307e\u3059. \u68c4\u5374\u6cd5\u306e\u5f31\u70b9 \u68c4\u5374\u6cd5\u306f\u30b7\u30f3\u30d7\u30eb\u3067\u3042\u308a\u5e45\u5e83\u3044\u30af\u30e9\u30b9\u306e\u554f\u984c\u306b\u5bfe\u3057\u3066\u9069\u7528\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u4e00\u65b9\u3067, \u78ba\u7387\u5206\u5e03\u304c\u5c40\u6240\u7684\u306b\u9ad8\u3044\u5024\u3092\u6301\u3064\u5834\u5408\u306b\u306f, \u68c4\u5374\u7387\u304c\u9ad8\u304f\u306a\u3063\u3066\u3057\u307e\u3044, \u52b9\u7387\u7684\u306b\u30b5\u30f3\u30d7\u30eb\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u304f\u306a\u308b\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059. \u4ee5\u4e0b\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u306f \\(x \\in [0,10)\\) \u3067\u5b9a\u7fa9\u3055\u308c\u305f \\(\\lambda = 3\\) \u306e\u6307\u6570\u5206\u5e03\u306b\u5bfe\u3057\u3066 \\(\\alpha = \\lambda\\) \u3068\u3057\u3066\u68c4\u5374\u6cd5\u3092\u8a66\u3057\u3066\u307f\u307e\u3059. 10000 \u56de\u7e70\u308a\u8fd4\u3057\u305f\u3068\u304d\u306b\u68c4\u5374\u3055\u308c\u305f\u5272\u5408\u3092\u8a08\u7b97\u3057\u3066\u307f\u307e\u3059. from numpy.random import default_rng import numpy as np gen = default_rng ( 2021 ) lam = 3.0 ub = 10.0 func = lambda x : lam * np . exp ( - lam * x ) / ( 1.0 - np . exp ( - lam * ub )) x = gen . uniform ( 0 , ub , size = ( 10000 )) a = gen . uniform ( 0 , lam , size = ( 10000 )) rejected = a > func ( x ) print ( 'rejected fraction: {} ' . format ( rejected . sum () / rejected . size )) \u8a08\u7b97\u7d50\u679c rejected fraction : 0.9693 \u4eca\u56de\u306e\u30b1\u30fc\u30b9\u3067\u306f\u304a\u3088\u305d 96% \u306e\u8a66\u884c\u304c reject \u3055\u308c\u307e\u3057\u305f. \u671b\u3093\u3060\u6570\u3060\u3051\u4e71\u6570\u3092\u5f97\u308b\u305f\u3081\u306b\u304a\u3088\u305d 30 \u500d\u4ee5\u4e0a\u306e\u8a66\u884c\u3092\u8cbb\u3084\u3055\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u3053\u3068\u306b\u306a\u308a\u307e\u3059. \u68c4\u5374\u6cd5\u306f\u5b9f\u88c5\u3057\u3084\u3059\u304f, \u9069\u7528\u7bc4\u56f2\u306e\u5e83\u3044\u65b9\u6cd5\u3067\u306f\u3042\u308b\u306e\u3067\u3059\u304c, \u554f\u984c\u306b\u3088\u3063\u3066\u306f\u5fc5\u305a\u3057\u3082\u52b9\u7387\u306e\u826f\u3044\u65b9\u6cd5\u3068\u306f\u8a00\u3048\u307e\u305b\u3093. \u3082\u3061\u308d\u3093\u8a08\u7b97\u6a5f\u306b\u3088\u3063\u3066\u751f\u6210\u3055\u308c\u308b\u4e71\u6570\u306f\u64ec\u4f3c\u4e71\u6570\u3067\u3057\u304b\u306a\u3044\u306e\u3067\u3059\u304c, \u3053\u3053\u3067\u306f\u8003\u3048\u306a\u3044\u3053\u3068\u306b\u3057\u307e\u3057\u3087\u3046. \u21a9 \u4e00\u822c\u306b\u7d2f\u7a4d\u78ba\u7387\u5206\u5e03\u3092 \\(C(x)\\) , \u78ba\u7387\u5206\u5e03\u3092 \\(P(x)\\) \u3067\u8868\u3059\u3053\u3068\u306b\u3057\u307e\u3059. \u21a9 \u305f\u3060\u3057 \\(\\alpha \\geq \\max\\limits_x P(x)\\) \u3068\u3057\u307e\u3059. \u21a9 \u78ba\u7387\u3092 Bayes \u7684\u306b\u8a55\u4fa1\u3057\u3088\u3046\u3068\u3059\u308b\u3068\u3053\u306e\u30b1\u30fc\u30b9\u306b\u306f\u983b\u7e41\u306b\u906d\u9047\u3057\u307e\u3059. \u7279\u306b\u591a\u6b21\u5143\u306e\u91cf\u3092\u6271\u3063\u3066\u3044\u308b\u5834\u5408\u306b\u306f, \u898f\u683c\u5316\u3059\u308b\u305f\u3081\u306b\u591a\u6b21\u5143\u7a7a\u9593\u3067\u306e\u7a4d\u5206\u304c\u5fc5\u8981\u306b\u306a\u308b\u305f\u3081\u300c2 \u70b9\u306e\u78ba\u7387\u306e\u6bd4\u300d\u3055\u3048\u5206\u304b\u308c\u3070\u9069\u7528\u3067\u304d\u308b\u624b\u6cd5\u306f\u3068\u3066\u3082\u6709\u7528\u3067\u3059 (\u305d\u3057\u3066\u4eca\u56de MCMC \u3067\u7528\u3044\u308b Metropolis-Hasting \u6cd5\u3082\u3053\u306e\u30b1\u30fc\u30b9\u306b\u8a72\u5f53\u3057\u307e\u3059). \u21a9 \u3053\u3053\u3067\u306f\u4f8b\u5916\u7684\u306b\u78ba\u7387\u5206\u5e03\u95a2\u6570\u306b \\(Q(x)\\) \u3068\u3044\u3046\u8868\u73fe\u3092\u4f7f\u3063\u3066\u3044\u307e\u3059. \u5b9f\u614b\u3092\u53cd\u6620\u3057\u3066\u3044\u308b\u308f\u3051\u3067\u306f\u306a\u3044\u304c \\(P(x)\\) \u3092\u8fd1\u4f3c\u3059\u308b\u305f\u3081\u306b\u4f7f\u3044\u3084\u3059\u3044\u95a2\u6570\u3068\u3057\u3066\u63a1\u7528\u3057\u3066\u3044\u307e\u3059. \u21a9 \u3053\u3053\u3067 \\(P(x) > 0\\) \u3067\u3042\u308b\u3088\u3046\u306a \\(x\\) \u306b\u3064\u3044\u3066\u306f\u5fc5\u305a \\(Q(x) > 0\\) \u3067\u3042\u308b\u3088\u3046\u306a \\(Q(x)\\) \u3092\u9078\u3076\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059. \u63d0\u6848\u3055\u308c\u308b\u3053\u3068\u306e\u306a\u3044\u9818\u57df\u306f\u6c7a\u3057\u3066\u30b5\u30f3\u30d7\u30eb\u306b\u73fe\u308c\u307e\u305b\u3093. \u21a9 \u305f\u3060\u3057 \\(\\alpha \\geq \\max\\limits_x {P(x)}/{Q(x)}\\) \u3068\u3057\u307e\u3059. \u21a9","title":"\u4e71\u6570\u3092\u751f\u6210\u3059\u308b"},{"location":"mcmc/generate_random_variables/#_1","text":"\u3053\u3053\u3067\u306f\u4efb\u610f\u306e\u78ba\u7387\u5206\u5e03\u95a2\u6570\u306b\u5f93\u3046\u4e71\u6570\u3092\u767a\u751f\u3055\u305b\u308b\u65b9\u6cd5\u3068\u3057\u3066, \u9006\u95a2\u6570\u6cd5\u3068\u68c4\u5374\u6cd5\u3068\u3044\u3046 2 \u3064\u306e\u65b9\u6cd5\u3092\u7d39\u4ecb\u3057\u307e\u3059. MCMC \u306e\u7406\u89e3\u306b\u306f\u3055\u307b\u3069\u91cd\u8981\u3067\u306f\u306a\u3044\u306e\u3067\u3059\u304c, MCMC \u3068\u5bfe\u6bd4\u3055\u305b\u308b\u624b\u6cd5\u3068\u3057\u3066\u3053\u3053\u3067\u7c21\u5358\u306b\u89e6\u308c\u3066\u304a\u304d\u307e\u3059.","title":"\u4e71\u6570\u3092\u751f\u6210\u3059\u308b"},{"location":"mcmc/generate_random_variables/#_2","text":"\u524d\u63d0\u3068\u3057\u3066\u79c1\u305f\u3061\u306f \\([0,1)\\) \u306e\u7bc4\u56f2\u306b\u4e00\u69d8\u306b\u5206\u5e03\u3059\u308b\u4e71\u6570\u3092\u751f\u6210\u3067\u304d\u308b\u3068\u3057\u307e\u3059. \u307e\u305a, \u4f55\u3089\u304b\u306e\u4e71\u6570\u3092\u767a\u751f\u3055\u305b\u308b\u80fd\u529b\u304c\u306a\u3044\u3068\u4ee5\u4e0b\u306e\u8b70\u8ad6\u306f\u6210\u7acb\u3057\u307e\u305b\u3093. 1 Python \u3067\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u3057\u3066\u4e71\u6570\u751f\u6210\u5668\u3092\u751f\u6210\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. from numpy.random import default_rng # \u4e71\u6570\u751f\u6210\u5668 gen = default_rng ( 2021 ) # seed \u5024\u3092\u4e0e\u3048\u3066\u521d\u671f\u5316\u3059\u308b u = gen . uniform ( 0 , 1 , size = ( 5 )) print ( u ) \u8a08\u7b97\u7d50\u679c [ 0.75694783 0.94138187 0.59246304 0.31884171 0.62607384 ] \u6563\u5e03\u56f3\u3092\u4f5c\u6210\u3057\u3066\u751f\u6210\u3055\u308c\u305f\u4e71\u6570\u304c\u3069\u3093\u306a\u5206\u5e03\u306b\u306a\u3063\u3066\u3044\u308b\u306e\u304b\u78ba\u8a8d\u3057\u3066\u307f\u307e\u3057\u3087\u3046. \\([0,1)\\) \u306e\u7bc4\u56f2\u306b\u4e00\u69d8\u306b\u5206\u5e03\u3057\u3066\u3044\u308b\u3053\u3068\u304c\u78ba\u8a8d\u3067\u304d\u308b\u3068\u601d\u3044\u307e\u3059. import matplotlib.pyplot as plt from numpy.random import default_rng gen = default_rng ( 2021 ) fig = plt . figure () ax = fig . add_subplot () ax . plot ( gen . uniform ( 0 , 1 , size = ( 1000 )), ls = '' , marker = '.' ) ax . set_ylabel ( 'uniform random value' ) ax . set_xlabel ( 'sample number' ) plt . tight_layout () plt . show () \u8a08\u7b97\u7d50\u679c numpy \u306b\u306f\u3055\u307e\u3056\u307e\u306a\u78ba\u7387\u5206\u5e03\u306b\u5f93\u3046\u4e71\u6570\u3092\u751f\u6210\u3059\u308b\u305f\u3081\u306e\u95a2\u6570\u304c\u5099\u308f\u3063\u3066\u3044\u307e\u3059\u304c, \u3053\u3053\u3067\u306f\u4e00\u69d8\u4e71\u6570 uniform() \u3092\u4f7f\u3063\u3066\u4efb\u610f\u306e\u78ba\u7387\u5206\u5e03\u306b\u5f93\u3046\u4e71\u6570\u3092\u751f\u6210\u3059\u308b\u65b9\u6cd5\u306b\u3064\u3044\u3066\u7d39\u4ecb\u3057\u307e\u3059. \u4e71\u6570\u751f\u6210\u5668\u3092\u30ab\u30b9\u30bf\u30de\u30a4\u30ba\u3057\u305f\u3044\u5834\u5408 \u4e0a\u8a18\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u306f\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u4e71\u6570\u751f\u6210\u5668\u3092\u4f7f\u7528\u3057\u307e\u3057\u305f. \u4e71\u6570\u751f\u6210\u5668\u3092\u81ea\u5206\u3067\u30ab\u30b9\u30bf\u30de\u30a4\u30ba\u3057\u305f\u3044\u5834\u5408\u306b\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b Generator() \u3092\u547c\u3073\u51fa\u3057\u3066\u304f\u3060\u3055\u3044. from numpy.random import Generator , PCG64 gen = Generator ( PCG64 ( 2021 )) # PCG64 \u306b seed \u5024\u3092\u4e0e\u3048\u3066\u521d\u671f\u5316\u3059\u308b \u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f PCG64 \u304c\u4f7f\u7528\u3055\u308c\u307e\u3059\u304c, \u3082\u3057\u30e1\u30eb\u30bb\u30f3\u30cc\u30c4\u30a4\u30b9\u30bf\u3092\u4f7f\u7528\u3057\u305f\u3044\u5834\u5408\u306b\u306f MT19937 \u3092\u4f7f\u7528\u3057\u3066\u304f\u3060\u3055\u3044. from numpy.random import Generator , MT19937 gen = Generator ( MT19937 ( 2021 )) # MT19937 \u306b seed \u5024\u3092\u4e0e\u3048\u3066\u521d\u671f\u5316\u3059\u308b","title":"\u524d\u63d0/\u4e00\u69d8\u4e71\u6570\u3092\u751f\u6210\u3059\u308b\u95a2\u6570"},{"location":"mcmc/generate_random_variables/#_3","text":"","title":"\u9006\u95a2\u6570\u6cd5"},{"location":"mcmc/generate_random_variables/#_4","text":"\u9006\u95a2\u6570\u6cd5\u3068\u306f\u4ee5\u4e0b\u306e\u624b\u7d9a\u304d\u306b\u3088\u3063\u3066\u4e71\u6570\u3092\u751f\u6210\u3059\u308b\u65b9\u6cd5\u3067\u3059. \u7d2f\u7a4d\u78ba\u7387\u5206\u5e03 \\(C(x) = \\int P(x') \\mathrm{d}x'\\) \u306e\u9006\u95a2\u6570 \\(C^{-1}(y)\\) \u3092\u7528\u610f\u3059\u308b. 2 \\([0,1)\\) \u306e\u4e00\u69d8\u5206\u5e03 \\({\\operatorname{Unif}}(0,1)\\) \u304b\u3089 \\(u\\) \u3092\u30b5\u30f3\u30d7\u30eb\u3059\u308b. \\({x'} \\gets C^{-1}(u)\\) \u306b\u3088\u3063\u3066 \\({x'}\\) \u3092\u5b9a\u7fa9\u3059\u308b. \u7d2f\u7a4d\u78ba\u7387\u5206\u5e03 \\(C(x)\\) \u306f\u5358\u8abf\u5897\u52a0\u95a2\u6570\u306a\u306e\u3067\u5e38\u306b\u9006\u95a2\u6570\u3092\u6301\u3061\u307e\u3059. \\(C(x)\\) \u306e range \u306f \\([0,1)\\) \u306a\u306e\u3067, \u9006\u95a2\u6570 \\(C^{-1}(y)\\) \u306e domain \u306f \\([0,1)\\) \u306a\u306e\u3067 \\(u\\) \u3092\u5165\u529b\u3068\u3057\u3066\u4e0e\u3048\u308b\u3068, \\(C^{-1}(y)\\) \u306e domain \u5168\u4f53\u306b\u5bfe\u3057\u3066\u4e00\u69d8\u306e\u5bc6\u5ea6\u3067\u5165\u529b\u3092\u4e0e\u3048\u308b\u3053\u3068\u306b\u306a\u308a\u307e\u3059. \u3053\u3053\u3067 \\(u\\) \u3092 \\(\\mathrm{d}u\\) \u3060\u3051\u52d5\u304b\u3057\u305f\u3068\u304d\u306b \\({x'}\\) \u304c\u3069\u308c\u3060\u3051\u52d5\u304f\u304b\u3092\u8003\u3048\u308b\u3068, \\[ \\mathrm{d}{x'} = \\frac{\\mathrm{d}C^{-1}(u)}{\\mathrm{d}u} \\mathrm{d}u = \\frac{1}{P({x'})} \\mathrm{d}u. \\] \u3068\u306a\u308a\u307e\u3059. \\(u\\) \u21c9 \\({x'}\\) \u306e\u5909\u63db\u3067 \\(\\mathrm{d}u\\) \u306e\u5e45\u306b\u4e00\u69d8\u306b\u5206\u5e03\u3057\u3066\u3044\u305f\u30c7\u30fc\u30bf\u306f \\(\\mathrm{d}{x'} = P({x'})^{-1}\\mathrm{d}u\\) \u306e\u7bc4\u56f2\u306b\u5206\u5e03\u3059\u308b\u3053\u3068\u306b\u306a\u308b\u306e\u3067, \\({x'}\\) \u306e\u7a7a\u9593\u3067\u306f\u5bc6\u5ea6\u306f \\(P({x'})\\) \u500d\u306b\u306a\u308a\u307e\u3059. \u3053\u308c\u306b\u3088\u3063\u3066, \u4e0a\u8a18\u306e\u5909\u63db\u306b\u3088\u3063\u3066\u5f97\u3089\u308c\u305f\u4e71\u6570 \\(x'\\) \u306e\u5206\u5e03\u306f\u306f\u78ba\u7387\u5206\u5e03\u95a2\u6570 \\(P(x)\\) \u306b\u5f93\u3044\u307e\u3059. \u9006\u95a2\u6570\u6cd5\u306e\u6982\u5ff5\u56f3\u3092\u4ee5\u4e0b\u306b\u793a\u3057\u307e\u3059. \u7d2f\u7a4d\u78ba\u7387\u5206\u5e03 \\(C(x)\\) \u3092\u9ed2\u5b9f\u7dda\u3067\u793a\u3057\u307e\u3057\u305f. \u3053\u3053\u3067 \\([0,1)\\) \u306e\u7bc4\u56f2\u3067\u4e00\u69d8\u306b\u5024\u3092\u30b5\u30f3\u30d7\u30eb\u3057\u3066, \u305d\u306e\u5024\u3092\u9ad8\u3055\u306b\u3082\u3061 \\(x\\) \u8ef8\u3068\u4e26\u884c\u306b\u306a\u7dda (\u9ec4\u8272) \u3092\u5f15\u304d\u307e\u3059. \u3053\u3053\u3067\u306f\u7dda\u3092 30 \u672c\u5f15\u3044\u3066\u3044\u307e\u3059. \u7dda\u304c \\(C(x)\\) \u3068\u3076\u3064\u304b\u3063\u305f\u3068\u3053\u308d\u3067 \\(x\\) \u8ef8\u306b\u843d\u3068\u3057\u307e\u3059. \u3053\u306e\u64cd\u4f5c\u306f \\(u\\) \u21c9 \\({x'}\\) \u306e\u5909\u63db\u306b\u76f8\u5f53\u3057\u3066\u3044\u307e\u3059. \u78ba\u7387\u5206\u5e03 \\(P(x)\\) \u306e\u5024\u304c\u5927\u304d\u3044\u3068\u3053\u308d\u3067\u306f \\(C(x)\\) \u306e\u50be\u304d\u304c\u5927\u304d\u304f\u306a\u308b\u305f\u3081, \\(x\\) \u8ef8\u4e0a\u3067\u306f\u9ec4\u8272\u3044\u7dda\u306e\u5bc6\u5ea6\u304c\u9ad8\u304f\u306a\u3063\u3066\u3044\u308b\u3053\u3068\u304c\u5206\u304b\u308a\u307e\u3059.","title":"\u9006\u95a2\u6570\u6cd5\u306b\u3088\u308b\u4e71\u6570\u751f\u6210"},{"location":"mcmc/generate_random_variables/#_5","text":"\u9006\u95a2\u6570\u6cd5\u3092\u4f7f\u3063\u3066\u6307\u6570\u5206\u5e03\u306b\u5f93\u3046\u4e71\u6570\u3092\u751f\u6210\u3057\u3066\u307f\u307e\u3057\u3087\u3046. \u6307\u6570\u5206\u5e03\u3068\u306f \\(x \\geq 0\\) \u3067\u5b9a\u7fa9\u3055\u308c\u308b\u78ba\u7387\u5206\u5e03\u3067, \u6e1b\u8870\u306e\u901f\u3055\u3092\u793a\u3059\u30d1\u30e9\u30e1\u30bf\u3092 1 \u3064\u6301\u3061\u307e\u3059. \\[ {\\operatorname{Exponential}}(\\lambda): P(x;\\lambda) = \\lambda\\exp(-{\\lambda}x). \\] \u7d2f\u7a4d\u78ba\u7387\u5206\u5e03\u306f \\(C(x;\\lambda) = 1-\\exp(-{\\lambda}x)\\) \u3068\u306a\u308b\u306e\u3067, \u4e00\u69d8\u5206\u5e03\u304b\u3089\u751f\u6210\u3057\u305f\u4e71\u6570 \\(u\\) \u3092\u3064\u304b\u3063\u3066\u4ee5\u4e0b\u306e\u5909\u63db\u3092\u3059\u308b\u3053\u3068\u3067\u6307\u6570\u5206\u5e03\u306b\u5f93\u3046\u4e71\u6570\u3092\u751f\u6210\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \\[ x' \\gets -\\frac{1}{\\lambda}\\log(1-u). \\] \u4ee5\u4e0b\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u306f\u4e00\u69d8\u4e71\u6570 \\(u\\) \u3092 1000 \u500b\u751f\u6210\u3057\u3066, \\(\\lambda = 3\\) \u306e\u6307\u6570\u5206\u5e03\u306b\u5f93\u3046\u4e71\u6570\u306b\u5909\u63db\u3057\u3066\u3044\u307e\u3059. \u751f\u6210\u3057\u305f\u4e71\u6570\u306e\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u3068\u78ba\u7387\u5206\u5e03 \\(P(x;\\lambda)\\) \u3092\u540c\u3058\u56f3\u306b\u30d7\u30ed\u30c3\u30c8\u3057\u3066\u76f8\u9055\u304c\u306a\u3044\u3053\u3068\u3092\u78ba\u8a8d\u3057\u3066\u3044\u307e\u3059. import matplotlib.pyplot as plt from numpy.random import default_rng import numpy as np gen = default_rng ( 2021 ) lam = 3.0 X = np . linspace ( 0 , 5 , 100 ) Y = lam * np . exp ( - lam * X ) u = gen . uniform ( 0 , 1 , size = ( 10000 )) x = - 1.0 / lam * np . log ( 1.0 - u ) fig = plt . figure () ax = fig . add_subplot () ax . hist ( x , bins = 50 , density = True ) ax . plot ( X , Y ) ax . set_ylabel ( 'frequency' ) ax . set_xlabel ( 'variable: x' ) plt . tight_layout () plt . show () \u8a08\u7b97\u7d50\u679c","title":"\u6307\u6570\u5206\u5e03\u306b\u5f93\u3046\u4e71\u6570"},{"location":"mcmc/generate_random_variables/#-box-muller","text":"\u3082\u3046\u3072\u3068\u3064, \u9006\u95a2\u6570\u6cd5\u306e\u30b5\u30f3\u30d7\u30eb\u3068\u3057\u3066\u5e73\u5747\u304c 0 \u3067\u5206\u6563\u304c 1 \u306e\u6a19\u6e96\u6b63\u898f\u5206\u5e03 \\(\\mathcal{N}(0,1)\\) \u3092\u5c0e\u51fa\u3057\u307e\u3059. \u6a19\u6e96\u6b63\u898f\u5206\u5e03\u306f\u7d2f\u7a4d\u78ba\u7387\u5206\u5e03\u3092\u967d\u306b\u8a08\u7b97\u3059\u308b\u3053\u3068\u306f\u3067\u304d\u306a\u3044\u305f\u3081, \u9006\u95a2\u6570\u6cd5\u3092\u5358\u7d14\u306b\u5f53\u3066\u306f\u3081\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u305b\u3093. \u3057\u304b\u3057, Box-Muller \u5909\u63db\u3068\u3044\u3046\u624b\u6cd5\u3092\u4f7f\u3046\u3053\u3068\u3067\u4e00\u69d8\u5206\u5e03\u306b\u5f93\u3046 2 \u3064\u306e\u4e71\u6570\u304b\u3089 2 \u3064\u306e\u72ec\u7acb\u3057\u305f\u6a19\u6e96\u6b63\u898f\u5206\u5e03\u304b\u3089\u306a\u308b\u78ba\u7387\u5909\u6570 \\(x\\) , \\(y\\) \u3092\u5f97\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u307e\u305a\u306f, \\(x\\) , \\(y\\) \u306e\u540c\u6642\u78ba\u7387\u5206\u5e03 \\(P(x,y)\\) \u3092\u8003\u3048\u307e\u3059. \\[ P(x,y) = \\frac{1}{2\\pi}\\exp\\left(-\\frac{x^2+y^2}{2}\\right). \\] \u3053\u3053\u3067, \\(x = r\\cos\\theta\\) , \\(y = r\\sin\\theta\\) \u3068\u304a\u3044\u3066\u6975\u5ea7\u6a19\u7cfb\u306b\u5909\u63db\u3057\u3066\u304b\u3089\u7d2f\u7a4d\u78ba\u7387\u5206\u5e03\u3092\u8003\u3048\u307e\u3059. \u305f\u3060\u3057, \u78ba\u7387\u306f \\(\\theta\\) \u306b\u306f\u4f9d\u5b58\u3057\u306a\u3044\u305f\u3081 \\([0,2\\pi)\\) \u306b\u4e00\u69d8\u306b\u5206\u5e03\u3057\u3066\u3044\u308b\u3068\u8003\u3048\u3066\u3088\u3055\u305d\u3046\u3067\u3059. \u554f\u984c\u3092\u7c21\u5358\u306b\u3059\u308b\u305f\u3081\u306b \\(\\theta\\) \u306f\u7a4d\u5206\u3057\u3066\u6d88\u3057\u3066\u3057\u307e\u3063\u3066, \\(r\\) \u306b\u5bfe\u3059\u308b\u7d2f\u7a4d\u78ba\u7387\u5206\u5e03\u3092\u8003\u3048\u307e\u3059. \\[ C(r) = \\frac{1}{2\\pi}\\int_0^{2\\pi}\\mathrm{d}\\theta' \\int_0^r\\mathrm{d}r' r\\exp\\left(-\\frac{r^2}{2}\\right) = 1 - \\exp\\left(-\\frac{r^2}{2}\\right). \\] \u3053\u308c\u3067\u5148\u307b\u3069\u3068\u540c\u69d8\u306b\u9006\u95a2\u6570\u6cd5\u3092\u4f7f\u3046\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \\([0,1)\\) \u306e\u4e00\u69d8\u5206\u5e03\u306b\u5f93\u3046\u4e71\u6570 \\(u\\) , \\(v\\) \u3092\u4f7f\u3063\u3066 \\(r\\) , \\(\\theta\\) \u306b\u5909\u63db\u3057\u307e\u3059. \u3055\u3089\u306b \\(r\\) , \\(\\theta\\) \u3092\u76f4\u884c\u5ea7\u6a19\u3067\u306e\u5024\u306b\u5909\u63db\u3059\u308b\u3053\u3068\u3067, \u6b63\u898f\u5206\u5e03\u306b\u5f93\u3046\u78ba\u7387\u5909\u6570 \\(x\\) , \\(y\\) \u3092\u5f97\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \\[ \\left\\{~\\begin{aligned} r &= \\sqrt{-2\\log(1-u)} \\\\ \\theta &= 2\\pi v \\end{aligned}\\right. \\quad\\Rightarrow\\quad \\left\\{~\\begin{aligned} x &= r\\cos\\theta \\\\ y &= r\\sin\\theta \\end{aligned}\\right.. \\] \u4ee5\u4e0b\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u306f\u4e00\u69d8\u5206\u5e03\u304b\u3089 Box-Muller \u5909\u63db\u306b\u3088\u3063\u3066\u30b5\u30f3\u30d7\u30eb\u3057\u305f \\(x\\) \u306e\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u3068\u6a19\u6e96\u6b63\u898f\u5206\u5e03\u306e\u78ba\u7387\u5206\u5e03\u95a2\u6570\u3092\u540c\u3058\u56f3\u306b\u30d7\u30ed\u30c3\u30c8\u3057\u3066\u76f8\u9055\u304c\u306a\u3044\u3053\u3068\u3092\u78ba\u8a8d\u3057\u3066\u3044\u307e\u3059. import matplotlib.pyplot as plt from numpy.random import default_rng import numpy as np gen = default_rng ( 2021 ) X = np . linspace ( - 5 , 5 , 500 ) Y = np . exp ( - X * X / 2.0 ) / np . sqrt ( 2 * np . pi ) u = gen . uniform ( 0 , 1 , size = ( 30000 )) v = gen . uniform ( 0 , 1 , size = ( 30000 )) r = np . sqrt ( - 2 * np . log ( 1 - u )) t = 2 * np . pi * v x = r * np . cos ( t ) y = r * np . sin ( t ) fig = plt . figure () ax = fig . add_subplot () ax . hist ( x , bins = 50 , density = True ) ax . plot ( X , Y ) ax . set_ylabel ( 'frequency' ) ax . set_xlabel ( 'variable: x' ) plt . tight_layout () plt . show () \u8a08\u7b97\u7d50\u679c \u9006\u95a2\u6570\u6cd5\u306f\u7279\u5b9a\u306e\u78ba\u7387\u5206\u5e03\u306b\u5f93\u3046\u4e71\u6570\u3092\u751f\u6210\u3059\u308b\u65b9\u6cd5\u3068\u3057\u3066\u6975\u3081\u3066\u5f37\u529b\u3067\u3059. \u3057\u304b\u3057\u306a\u304c\u3089, \u9006\u95a2\u6570\u6cd5\u3092\u9069\u7528\u3059\u308b\u305f\u3081\u306b\u306f\u7d2f\u7a4d\u78ba\u7387\u5206\u5e03\u306e\u9006\u95a2\u6570\u3092\u52b9\u7387\u3088\u304f\u8a08\u7b97\u3067\u304d\u308b\u3068\u3044\u3046\u6761\u4ef6\u3092\u6e80\u305f\u3059\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059. \u9650\u3089\u308c\u305f\u30af\u30e9\u30b9\u306e\u78ba\u7387\u5206\u5e03\u306b\u3057\u304b\u9069\u7528\u3059\u308b\u3053\u3068\u306f\u3067\u304d\u307e\u305b\u3093.","title":"\u6b63\u898f\u5206\u5e03\u306b\u5f93\u3046\u4e71\u6570 --- Box-Muller \u5909\u63db"},{"location":"mcmc/generate_random_variables/#_6","text":"","title":"\u68c4\u5374\u6cd5"},{"location":"mcmc/generate_random_variables/#_7","text":"\u68c4\u5374\u6cd5\u306f\u6975\u3081\u3066\u30b7\u30f3\u30d7\u30eb\u306a\u624b\u7d9a\u304d\u306b\u3088\u3063\u3066\u4e71\u6570\u3092\u751f\u6210\u3059\u308b\u65b9\u6cd5\u3067\u3059. \u4f8b\u3048\u3070\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u624b\u7d9a\u304d\u306b\u3088\u3063\u3066\u751f\u6210\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u4e00\u69d8\u5206\u5e03\u304b\u3089\u5019\u88dc \\(x\\) \u3092\u30b5\u30f3\u30d7\u30eb\u3059\u308b. \\([0,\\alpha)\\) \u306e\u4e00\u69d8\u5206\u5e03 \\({\\operatorname{Unif}}(0,\\alpha)\\) \u304b\u3089 \\(u\\) \u3092\u30b5\u30f3\u30d7\u30eb\u3059\u308b. 3 \\(u \\leq P(x)\\) \u3067\u3042\u308c\u3070 \\(x\\) \u3092\u63a1\u7528\u3059\u308b. \u305d\u3046\u3067\u306a\u3051\u308c\u3070 \\(x\\) \u3092\u68c4\u5374\u3059\u308b. \u5fc5\u8981\u306a\u30b5\u30f3\u30d7\u30eb\u6570\u304c\u63c3\u3046\u307e\u3067\u4e0a\u8a18\u306e\u624b\u7d9a\u304d\u3092\u7e70\u308a\u8fd4\u3059. \\(P(x)\\) \u306e\u5024\u306b\u5fdc\u3058\u3066\u63a1\u7528\u3055\u308c\u308b\u78ba\u7387\u304c\u9ad8\u304f\u306a\u308b\u305f\u3081, \u5fc5\u7136\u7684\u306b \\(P(x)\\) \u306b\u5f93\u3046\u4e71\u6570\u3092\u5f97\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \\(P(x)\\) \u306e\u5024\u3092\u8a55\u4fa1\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308c\u3070\u9069\u7528\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u305f\u3081, \u307b\u307c\u4efb\u610f\u306e\u5f62\u72b6\u306e\u78ba\u7387\u5206\u5e03\u306b\u5bfe\u3057\u3066\u4f7f\u3046\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u307e\u305f, \u3053\u306e\u624b\u7d9a\u304d\u3067\u306f\u78ba\u7387\u5909\u6570 \\(x\\) , \\(x'\\) \u304c\u63a1\u7528\u3055\u308c\u308b\u78ba\u7387\u306e\u6bd4 \\(P(x)/P(x')\\) \u306b\u3088\u3063\u3066 \\(x\\) \u304c\u5f93\u3046\u78ba\u7387\u5206\u5e03\u306e\u5f62\u72b6\u304c\u6c7a\u307e\u308a\u307e\u3059. \u305d\u306e\u305f\u3081, \u78ba\u7387\u5206\u5e03\u95a2\u6570\u306e\u5f62\u72b6\u306f\u308f\u304b\u3063\u3066\u3044\u308b\u304c\u898f\u683c\u5316\u5b9a\u6570\u304c\u308f\u304b\u3089\u306a\u3044 4 \u3068\u3044\u3046\u30b1\u30fc\u30b9\u3067\u3082\u9069\u7528\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u4ee5\u4e0b\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u306f\u78ba\u7387\u5206\u5e03 \\(P(x) \\propto \\sqrt{1-x^2}\\) \u306b\u5f93\u3046\u4e71\u6570\u3092\u68c4\u5374\u6cd5\u306b\u3088\u3063\u3066\u751f\u6210\u3057\u3066\u3044\u307e\u3059. \u751f\u6210\u3057\u305f\u4e71\u6570\u306e\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u304c\u78ba\u7387\u5206\u5e03\u3068\u76f8\u9055\u304c\u306a\u3044\u3053\u3068\u3092\u78ba\u8a8d\u3057\u3066\u3044\u307e\u3059. \u307e\u305f\u5408\u8a08\u3067 30000 \u4ef6\u306e\u30c7\u30fc\u30bf\u3092\u751f\u6210\u3059\u308b\u305f\u3081\u306b\u5408\u8a08\u3067\u4f55\u56de\u4e0a\u8a18\u306e\u624b\u7d9a\u304d\u3092\u7e70\u308a\u8fd4\u3057\u305f\u306e\u304b\u3092\u8868\u793a\u3057\u307e\u3059. import matplotlib.pyplot as plt from numpy.random import default_rng import numpy as np gen = default_rng ( 2021 ) func = lambda x : np . sqrt ( np . clip ( 1 - x * x , 0 , 1 )) / np . pi * 2.0 X = np . linspace ( - 1.2 , 1.2 , 500 ) Y = func ( X ) trial = 0 x = [] while len ( x ) < 30000 : u = gen . uniform ( - 2 , 2 ) v = gen . uniform ( 0 , 2.0 / np . pi ) if v < func ( u ): x . append ( u ) trial += 1 x = np . array ( x ) print ( f 'total trial: { trial } ' ) fig = plt . figure () ax = fig . add_subplot () ax . hist ( x , bins = 50 , density = True ) ax . plot ( X , Y ) ax . set_ylabel ( 'frequency' ) ax . set_xlabel ( 'variable: x' ) plt . tight_layout () plt . show () \u8a08\u7b97\u7d50\u679c total trial : 76247","title":"\u68c4\u5374\u6cd5\u306b\u3088\u308b\u4e71\u6570\u751f\u6210"},{"location":"mcmc/generate_random_variables/#_8","text":"\u4e0a\u8a18\u306e\u624b\u7d9a\u304d\u3067\u306f \\(x\\) \u3092\u4e00\u69d8\u306a\u5206\u5e03\u304b\u3089\u30b5\u30f3\u30d7\u30eb\u3057\u3066\u3044\u307e\u3057\u305f. \u3053\u3053\u3067, \u6700\u521d\u306b \\(x\\) \u3092\u62bd\u51fa\u3059\u308b\u5206\u5e03\u306e\u3053\u3068\u3092\u63d0\u6848\u5206\u5e03\u3068\u547c\u3073\u307e\u3059. \u63d0\u6848\u5206\u5e03\u306f\u4e00\u69d8\u5206\u5e03\u3067\u3042\u308b\u5fc5\u8981\u306f\u3042\u308a\u307e\u305b\u3093. \u63d0\u6848\u5206\u5e03\u3068\u3057\u3066 \\(P(x)\\) \u306b\u8fd1\u3044\u5206\u5e03\u3092\u7528\u3044\u308b\u3053\u3068\u3067, \u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3092\u52b9\u7387\u5316\u3059\u308b (\u68c4\u5374\u7387\u3092\u4e0b\u3052\u308b) \u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u63d0\u6848\u5206\u5e03\u3068\u3057\u3066 \\(Q(x)\\) \u3092\u3082\u3061\u3044\u305f\u5834\u5408\u306e\u624b\u7d9a\u304d\u3092\u4ee5\u4e0b\u306b\u793a\u3057\u307e\u3059. 5 \u63d0\u6848\u5206\u5e03 \\(Q(x)\\) \u304b\u3089\u5019\u88dc \\(x\\) \u3092\u30b5\u30f3\u30d7\u30eb\u3059\u308b. 6 \\([0,\\alpha)\\) \u306e\u4e00\u69d8\u5206\u5e03 \\({\\operatorname{Unif}}(0,\\alpha)\\) \u304b\u3089 \\(u\\) \u3092\u30b5\u30f3\u30d7\u30eb\u3059\u308b. 7 \\(u \\leq P(x)/Q(x)\\) \u3067\u3042\u308c\u3070 \\(x\\) \u3092\u63a1\u7528\u3059\u308b. \u305d\u3046\u3067\u306a\u3051\u308c\u3070 \\(x\\) \u3092\u68c4\u5374\u3059\u308b. \u5fc5\u8981\u306a\u30b5\u30f3\u30d7\u30eb\u6570\u304c\u63c3\u3046\u307e\u3067\u4e0a\u8a18\u306e\u624b\u7d9a\u304d\u3092\u7e70\u308a\u8fd4\u3059. \u4ee5\u4e0b\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u306f\u6a19\u6e96\u6b63\u898f\u5206\u5e03\u3092\u63d0\u6848\u5206\u5e03\u3068\u3057\u3066\u63a1\u7528\u3057\u305f\u78ba\u7387\u5206\u5e03 \\(P(x) \\propto \\sqrt{1-x^2}\\) \u306b\u5f93\u3046\u4e71\u6570\u3092\u68c4\u5374\u6cd5\u306b\u3088\u3063\u3066\u751f\u6210\u3057\u3066\u3044\u307e\u3059. \u751f\u6210\u3057\u305f\u4e71\u6570\u306e\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u304c\u6c42\u3081\u308b\u78ba\u7387\u5206\u5e03\u3068\u76f8\u9055\u306a\u3044\u3053\u3068\u3092\u78ba\u8a8d\u3057\u3066\u3044\u307e\u3059. \u307e\u305f\u5408\u8a08\u3067 30000 \u4ef6\u306e\u30c7\u30fc\u30bf\u3092\u751f\u6210\u3059\u308b\u305f\u3081\u306b\u5408\u8a08\u3067\u4f55\u56de\u4e0a\u8a18\u306e\u624b\u7d9a\u304d\u3092\u7e70\u308a\u8fd4\u3057\u305f\u306e\u304b\u3092\u8868\u793a\u3057\u307e\u3059. import matplotlib.pyplot as plt from numpy.random import default_rng import numpy as np gen = default_rng ( 2021 ) func = lambda x : np . sqrt ( np . clip ( 1 - x * x , 0 , 1 )) / np . pi * 2.0 prop = lambda x : np . exp ( - x * x / 2.0 ) / np . sqrt ( 2.0 * np . pi ) X = np . linspace ( - 1.2 , 1.2 , 500 ) Y = func ( X ) trial = 0 x = [] while len ( x ) < 30000 : u = gen . normal ( 0 , 1 ) v = gen . uniform ( 0 , np . sqrt ( 8 / np . pi )) if v < func ( u ) / prop ( u ): x . append ( u ) trial += 1 x = np . array ( x ) print ( f 'total trial: { trial } ' ) fig = plt . figure () ax = fig . add_subplot () ax . hist ( x , bins = 50 , density = True ) ax . plot ( X , Y ) ax . set_ylabel ( 'frequency' ) ax . set_xlabel ( 'variable: x' ) plt . tight_layout () plt . show () \u8a08\u7b97\u7d50\u679c total trial : 47650 \u76ee\u7684\u3068\u3059\u308b\u5206\u5e03\u306b\u8fd1\u3044\u5206\u5e03\u3092\u63d0\u6848\u5206\u5e03\u3068\u3057\u3066\u7528\u3044\u308b\u3053\u3068\u306b\u3088\u3063\u3066, \u52b9\u7387\u7684\u306b\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3067\u304d\u3066\u3044\u308b\u3053\u3068\u304c\u5206\u304b\u308a\u307e\u3059.","title":"\u63d0\u6848\u5206\u5e03\u306b\u3088\u308b\u52b9\u7387\u5316"},{"location":"mcmc/generate_random_variables/#_9","text":"\u68c4\u5374\u6cd5\u306f\u30b7\u30f3\u30d7\u30eb\u3067\u3042\u308a\u5e45\u5e83\u3044\u30af\u30e9\u30b9\u306e\u554f\u984c\u306b\u5bfe\u3057\u3066\u9069\u7528\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u4e00\u65b9\u3067, \u78ba\u7387\u5206\u5e03\u304c\u5c40\u6240\u7684\u306b\u9ad8\u3044\u5024\u3092\u6301\u3064\u5834\u5408\u306b\u306f, \u68c4\u5374\u7387\u304c\u9ad8\u304f\u306a\u3063\u3066\u3057\u307e\u3044, \u52b9\u7387\u7684\u306b\u30b5\u30f3\u30d7\u30eb\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u304f\u306a\u308b\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059. \u4ee5\u4e0b\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u306f \\(x \\in [0,10)\\) \u3067\u5b9a\u7fa9\u3055\u308c\u305f \\(\\lambda = 3\\) \u306e\u6307\u6570\u5206\u5e03\u306b\u5bfe\u3057\u3066 \\(\\alpha = \\lambda\\) \u3068\u3057\u3066\u68c4\u5374\u6cd5\u3092\u8a66\u3057\u3066\u307f\u307e\u3059. 10000 \u56de\u7e70\u308a\u8fd4\u3057\u305f\u3068\u304d\u306b\u68c4\u5374\u3055\u308c\u305f\u5272\u5408\u3092\u8a08\u7b97\u3057\u3066\u307f\u307e\u3059. from numpy.random import default_rng import numpy as np gen = default_rng ( 2021 ) lam = 3.0 ub = 10.0 func = lambda x : lam * np . exp ( - lam * x ) / ( 1.0 - np . exp ( - lam * ub )) x = gen . uniform ( 0 , ub , size = ( 10000 )) a = gen . uniform ( 0 , lam , size = ( 10000 )) rejected = a > func ( x ) print ( 'rejected fraction: {} ' . format ( rejected . sum () / rejected . size )) \u8a08\u7b97\u7d50\u679c rejected fraction : 0.9693 \u4eca\u56de\u306e\u30b1\u30fc\u30b9\u3067\u306f\u304a\u3088\u305d 96% \u306e\u8a66\u884c\u304c reject \u3055\u308c\u307e\u3057\u305f. \u671b\u3093\u3060\u6570\u3060\u3051\u4e71\u6570\u3092\u5f97\u308b\u305f\u3081\u306b\u304a\u3088\u305d 30 \u500d\u4ee5\u4e0a\u306e\u8a66\u884c\u3092\u8cbb\u3084\u3055\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u3053\u3068\u306b\u306a\u308a\u307e\u3059. \u68c4\u5374\u6cd5\u306f\u5b9f\u88c5\u3057\u3084\u3059\u304f, \u9069\u7528\u7bc4\u56f2\u306e\u5e83\u3044\u65b9\u6cd5\u3067\u306f\u3042\u308b\u306e\u3067\u3059\u304c, \u554f\u984c\u306b\u3088\u3063\u3066\u306f\u5fc5\u305a\u3057\u3082\u52b9\u7387\u306e\u826f\u3044\u65b9\u6cd5\u3068\u306f\u8a00\u3048\u307e\u305b\u3093. \u3082\u3061\u308d\u3093\u8a08\u7b97\u6a5f\u306b\u3088\u3063\u3066\u751f\u6210\u3055\u308c\u308b\u4e71\u6570\u306f\u64ec\u4f3c\u4e71\u6570\u3067\u3057\u304b\u306a\u3044\u306e\u3067\u3059\u304c, \u3053\u3053\u3067\u306f\u8003\u3048\u306a\u3044\u3053\u3068\u306b\u3057\u307e\u3057\u3087\u3046. \u21a9 \u4e00\u822c\u306b\u7d2f\u7a4d\u78ba\u7387\u5206\u5e03\u3092 \\(C(x)\\) , \u78ba\u7387\u5206\u5e03\u3092 \\(P(x)\\) \u3067\u8868\u3059\u3053\u3068\u306b\u3057\u307e\u3059. \u21a9 \u305f\u3060\u3057 \\(\\alpha \\geq \\max\\limits_x P(x)\\) \u3068\u3057\u307e\u3059. \u21a9 \u78ba\u7387\u3092 Bayes \u7684\u306b\u8a55\u4fa1\u3057\u3088\u3046\u3068\u3059\u308b\u3068\u3053\u306e\u30b1\u30fc\u30b9\u306b\u306f\u983b\u7e41\u306b\u906d\u9047\u3057\u307e\u3059. \u7279\u306b\u591a\u6b21\u5143\u306e\u91cf\u3092\u6271\u3063\u3066\u3044\u308b\u5834\u5408\u306b\u306f, \u898f\u683c\u5316\u3059\u308b\u305f\u3081\u306b\u591a\u6b21\u5143\u7a7a\u9593\u3067\u306e\u7a4d\u5206\u304c\u5fc5\u8981\u306b\u306a\u308b\u305f\u3081\u300c2 \u70b9\u306e\u78ba\u7387\u306e\u6bd4\u300d\u3055\u3048\u5206\u304b\u308c\u3070\u9069\u7528\u3067\u304d\u308b\u624b\u6cd5\u306f\u3068\u3066\u3082\u6709\u7528\u3067\u3059 (\u305d\u3057\u3066\u4eca\u56de MCMC \u3067\u7528\u3044\u308b Metropolis-Hasting \u6cd5\u3082\u3053\u306e\u30b1\u30fc\u30b9\u306b\u8a72\u5f53\u3057\u307e\u3059). \u21a9 \u3053\u3053\u3067\u306f\u4f8b\u5916\u7684\u306b\u78ba\u7387\u5206\u5e03\u95a2\u6570\u306b \\(Q(x)\\) \u3068\u3044\u3046\u8868\u73fe\u3092\u4f7f\u3063\u3066\u3044\u307e\u3059. \u5b9f\u614b\u3092\u53cd\u6620\u3057\u3066\u3044\u308b\u308f\u3051\u3067\u306f\u306a\u3044\u304c \\(P(x)\\) \u3092\u8fd1\u4f3c\u3059\u308b\u305f\u3081\u306b\u4f7f\u3044\u3084\u3059\u3044\u95a2\u6570\u3068\u3057\u3066\u63a1\u7528\u3057\u3066\u3044\u307e\u3059. \u21a9 \u3053\u3053\u3067 \\(P(x) > 0\\) \u3067\u3042\u308b\u3088\u3046\u306a \\(x\\) \u306b\u3064\u3044\u3066\u306f\u5fc5\u305a \\(Q(x) > 0\\) \u3067\u3042\u308b\u3088\u3046\u306a \\(Q(x)\\) \u3092\u9078\u3076\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059. \u63d0\u6848\u3055\u308c\u308b\u3053\u3068\u306e\u306a\u3044\u9818\u57df\u306f\u6c7a\u3057\u3066\u30b5\u30f3\u30d7\u30eb\u306b\u73fe\u308c\u307e\u305b\u3093. \u21a9 \u305f\u3060\u3057 \\(\\alpha \\geq \\max\\limits_x {P(x)}/{Q(x)}\\) \u3068\u3057\u307e\u3059. \u21a9","title":"\u68c4\u5374\u6cd5\u306e\u5f31\u70b9"},{"location":"mcmc/linear_regression/","text":"\u6f14\u7fd2\u554f\u984c: \u7dda\u5f62\u56de\u5e30 \u3053\u3053\u3067\u306f\u6700\u3082\u30b7\u30f3\u30d7\u30eb\u306a\u7dda\u5f62\u56de\u5e30\u554f\u984c\u306b\u5bfe\u3057\u3066 MCMC \u3092\u4f7f\u7528\u3057\u3066\u307f\u307e\u3059. \u984c\u6750\u3068\u3057\u3066\u4f7f\u7528\u3059\u308b\u306e\u306f\u9280\u6cb3\u306e\u4e2d\u5fc3\u306b\u3042\u308b\u8d85\u5927\u8cea\u91cf\u30d6\u30e9\u30c3\u30af\u30db\u30fc\u30eb (supermassive blackhole) \u3068, \u9280\u6cb3\u30d0\u30eb\u30b8 (bulge) \u306e\u901f\u5ea6\u5206\u6563\u306e\u95a2\u4fc2\u3067\u3059. \u30c7\u30fc\u30bf Harris et al. (2013) \u306f\u9280\u6cb3\u306b\u304a\u3051\u308b\u7403\u72b6\u661f\u56e3\u306e\u6027\u8cea\u3092\u8abf\u3079\u308b\u305f\u3081\u306b, \u5148\u884c\u7814\u7a76\u306b\u3088\u3063\u3066\u6e2c\u5b9a\u3055\u308c\u305f\u3055\u307e\u3056\u307e\u306a\u9280\u6cb3\u306e\u7269\u7406\u91cf\u3092\u307e\u3068\u3081\u305f \u30ab\u30bf\u30ed\u30b0 \u3092\u4f5c\u6210\u3057\u307e\u3057\u305f. \u4eca\u56de\u306f\u305d\u306e\u306a\u304b\u304b\u3089\u9280\u6cb3\u30d0\u30eb\u30b8\u306e\u901f\u5ea6\u5206\u6563 (\u4e3b\u306b\u53ef\u8996\u5149\u306e\u5206\u5149\u89b3\u6e2c\u304b\u3089\u63a8\u5b9a) \u3068\u9280\u6cb3\u4e2d\u5fc3\u306e\u8d85\u5927\u8cea\u91cf\u30d6\u30e9\u30c3\u30af\u30db\u30fc\u30eb\u306e\u8cea\u91cf (X \u7dda\u5149\u5ea6\u306a\u3069\u304b\u3089\u63a8\u5b9a) \u306e\u5024\u3092\u4f7f\u7528\u3057\u307e\u3059. \u6f14\u7fd2\u7528\u306b\u6574\u5f62\u3057\u305f\u30c7\u30fc\u30bf\u3092\u4ee5\u4e0b\u304b\u3089\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u304f\u3060\u3055\u3044. \u30d5\u30a1\u30a4\u30eb\u540d \u5f62\u5f0f exercise_linear_regression.csv csv \u30c7\u30fc\u30bf\u30c6\u30fc\u30d6\u30eb\u306b\u306f\u4ee5\u4e0b\u306e\u30ab\u30e9\u30e0\u304c\u542b\u307e\u308c\u3066\u3044\u307e\u3059. \u30ab\u30e9\u30e0\u540d \u8aac\u660e galaxy \u9280\u6cb3\u540d/\u30ab\u30bf\u30ed\u30b0 ID 1 ra \u8d64\u7d4c\u5ea7\u6a19 (J2000) 1 dec \u8d64\u7def\u5ea7\u6a19 (J2000) 1 dist \u8ddd\u96e2 (Mpc) 1 dist_err \u8ddd\u96e2\u306e\u4e0d\u5b9a\u6027 (Mpc) 1 logsig \u9280\u6cb3\u30d0\u30eb\u30b8\u306e\u901f\u5ea6\u5206\u6563 (\u5bfe\u6570) \\(\\log_{10}\\sigma_e\\) (km/s) logsig_err \u9280\u6cb3\u30d0\u30eb\u30b8\u306e\u901f\u5ea6\u5206\u6563\u306e\u4e0d\u5b9a\u6027 \\(\\varepsilon_\\sigma\\) logM_B \u8d85\u5927\u8cea\u91cf\u30d6\u30e9\u30c3\u30af\u30db\u30fc\u30eb\u306e\u8cea\u91cf (\u5bfe\u6570) \\(\\log_{10}{M_B}\\) ( \\({M_\\odot}\\) ) logM_B_err \u8d85\u5927\u8cea\u91cf\u30d6\u30e9\u30c3\u30af\u30db\u30fc\u30eb\u306e\u8cea\u91cf\u306e\u4e0d\u5b9a\u6027 \\(\\varepsilon_M\\) \u307e\u305a\u306f\u30c7\u30fc\u30bf\u306e\u95a2\u4fc2\u3092\u56f3\u793a\u3057\u307e\u3059. import numpy as np import pandas as pd import matplotlib.pyplot as plt table = pd . read_csv ( './exercise_linear_regression.csv' ) print ( table ) fig = plt . figure () ax = fig . add_subplot () ax . errorbar ( x = table . logsig , y = table . logM_B , xerr = table . logsig_err , yerr = table . logM_B_err , fmt = '.' ) ax . set_xlabel ( '$\\log_ {10} \\sigma_e$ (km/s)' ) ax . set_ylabel ( '$\\log_ {10} M_B$ ($M_\\odot$)' ) fig . tight_layout () plt . show () \u8a08\u7b97\u7d50\u679c galaxy ra dec dist dist_err logsig logsig_err logM_B logM_B_err 0 MilkyWay 0.000000 0.000000 0.00 0.00 2.021 0.076 6.61 0.040 1 NGC221 0.711607 40.865165 0.76 0.07 1.875 0.017 6.46 0.090 2 NGC224 0.712316 41.268883 0.77 0.02 2.204 0.021 8.18 0.150 3 NGC253 0.792531 -25.288442 3.54 0.20 2.011 0.073 7.00 0.300 4 NGC821 2.139199 10.995008 23.38 1.24 2.320 0.020 8.23 0.205 5 NGC1023 2.673329 39.063253 11.43 1.00 2.320 0.020 7.64 0.040 6 NGC1316 3.378256 -37.208211 21.09 0.30 2.357 0.006 8.24 0.200 7 NGC1332 3.438111 -21.335276 22.91 0.20 2.506 0.018 9.17 0.060 8 NGC1399 3.641408 -35.450626 20.68 0.50 2.528 0.020 8.69 0.065 9 NGC2778 9.206775 35.027417 22.91 3.39 2.243 0.019 7.15 0.300 10 NGC3031 9.925869 69.065438 3.55 0.07 2.155 0.021 7.84 0.085 11 NGC3115 10.087214 -7.718556 10.00 0.50 2.362 0.020 8.96 0.170 12 NGC3377 10.795104 13.985641 11.04 0.25 2.161 0.020 8.25 0.240 13 NGC3379 10.797108 12.581611 10.20 0.50 2.314 0.021 8.04 0.240 14 NGC3384 10.804699 12.629401 10.80 0.77 2.155 0.021 7.04 0.210 15 NGC3414 10.854492 27.974833 25.23 4.14 2.374 0.014 8.40 0.070 16 NGC3585 11.221418 -26.754864 21.20 1.73 2.328 0.020 8.51 0.140 17 NGC3607 11.281816 18.051899 20.00 2.00 2.360 0.020 8.15 0.125 18 NGC3608 11.283036 18.148538 23.00 2.00 2.260 0.021 8.67 0.095 19 NGC3842 11.733936 19.949696 94.90 6.70 2.498 0.011 9.99 0.125 20 NGC4261 12.323060 5.825041 31.62 2.89 2.498 0.020 8.71 0.085 21 NGC4291 12.338247 75.370944 26.18 4.16 2.384 0.021 8.98 0.140 22 NGC4350 12.399394 16.693471 15.50 0.78 2.256 0.017 8.74 0.100 23 NGC4374 12.417685 12.887071 18.51 0.61 2.471 0.020 8.96 0.045 24 NGC4459 12.483339 13.978556 16.01 0.55 2.223 0.020 7.84 0.080 25 NGC4472 12.496331 8.000389 17.03 0.21 2.468 0.004 9.26 0.150 26 NGC4473 12.496907 13.429397 15.25 0.51 2.279 0.020 7.95 0.240 27 NGC4486 12.513724 12.391217 17.00 0.30 2.574 0.020 9.77 0.030 28 NGC4486A 12.516033 12.270333 18.36 0.64 2.045 0.019 7.15 0.120 29 NGC4552 12.594402 12.556115 15.89 0.55 2.402 0.006 8.68 0.045 30 NGC4564 12.607493 11.439400 15.87 0.53 2.210 0.021 7.92 0.120 31 NGC4594 12.666513 -11.623010 9.77 0.84 2.380 0.021 8.72 0.435 32 NGC4621 12.700637 11.647308 14.85 0.50 2.352 0.006 8.60 0.065 33 NGC4649 12.727789 11.552672 17.09 0.61 2.585 0.021 9.63 0.100 34 NGC4697 12.809995 -5.800602 12.01 0.78 2.248 0.019 8.28 0.090 35 NGC4889 13.002237 27.977031 96.60 6.80 2.603 0.006 10.32 0.435 36 NGC5128 13.424479 -43.018118 3.80 0.07 2.176 0.020 7.71 0.160 37 IC4296 13.610847 -33.965822 49.68 2.73 2.508 0.021 9.13 0.065 38 NGC5813 15.019805 1.702009 32.21 2.78 2.374 0.006 8.84 0.070 39 NGC5845 15.100215 1.633972 25.94 2.63 2.369 0.020 8.69 0.140 40 NGC5846 15.108124 1.606291 24.89 2.40 2.379 0.008 9.04 0.080 41 NGC6086 16.209883 29.484478 137.30 9.60 2.524 0.012 9.56 0.160 42 NGC7332 22.623476 23.798260 23.01 2.22 2.097 0.011 7.11 0.190 43 IC1459 22.952945 -36.462176 29.24 4.02 2.486 0.011 9.45 0.195 44 NGC7457 23.016647 30.144889 13.24 1.34 1.826 0.019 7.00 0.300 45 NGC7768 23.849610 27.147336 112.10 7.90 2.495 0.021 9.11 0.150 \u56de\u5e30\u76f4\u7dda\u306e\u5c0e\u51fa Y \u8ef8\u306e\u4e0d\u5b9a\u6027\u3092\u8003\u616e\u3057\u305f\u56de\u5e30 \u304a\u304a\u3088\u305d\u7dda\u5f62\u306e\u95a2\u4fc2\u3067\u8fd1\u4f3c\u3067\u304d\u305d\u3046\u306a\u3053\u3068\u304c\u5206\u304b\u308a\u307e\u3057\u305f. \u3053\u3053\u3067\u306f Harris et al. (2013) \u3092\u53c2\u8003\u306b\u3057\u3066\u4ee5\u4e0b\u306e\u5f0f\u3092\u63a1\u7528\u3057\u307e\u3059. \u305f\u3060\u3057 \\(\\sigma_0\\) \u306f 200 km/s \u3068\u3057\u307e\u3059. \\[ \\log_{10} \\frac{M_B}{M_\\odot} = \\alpha + \\beta \\log_{10}\\frac{\\sigma_e}{\\sigma_0}. \\] \u8aa4\u5dee\u306f\u6b63\u898f\u5206\u5e03\u3067\u8fd1\u4f3c\u3067\u304d\u308b\u3068\u3044\u3046\u5358\u7d14\u306a\u30e2\u30c7\u30eb\u3092\u63a1\u7528\u3057\u307e\u3059. \u307e\u305a\u306f Y \u8ef8 ( \\(\\log{M_B}\\) ) \u306e\u4e0d\u5b9a\u6027\u3060\u3051\u3092\u8003\u3048\u3066\u5c24\u5ea6\u95a2\u6570 (\u78ba\u7387) \u3092\u5c0e\u51fa\u3057\u307e\u3059. 2 3 \\[ \\log{L(\\alpha,\\beta; D)} = -\\sum_{i=1}^n \\frac{ \\left( \\log_{10}{M_{B,i}} - \\alpha - \\beta\\log_{10}\\sigma_{e,i} \\right)^2 }{2{\\varepsilon_{M,i}}^2}. \\] \u3053\u306e\u5c24\u5ea6\u95a2\u6570\u306b\u5bfe\u3057\u3066 MCMC \u3092\u7528\u3044\u3066 \\(\\alpha\\) , \\(\\beta\\) \u306e\u5206\u5e03\u3092\u6c42\u3081\u3066\u304f\u3060\u3055\u3044. \u307e\u305f \\(\\alpha\\) , \\(\\beta\\) \u306e\u5e73\u5747\u5024\u3092 polynomial fitting ( numpy.polyfit ) \u306e\u7d50\u679c\u3068\u6bd4\u8f03\u3057\u3066\u304f\u3060\u3055\u3044. Example import numpy as np import pandas as pd import matplotlib.pyplot as plt from mhmcmc import MHMCMCSampler , GaussianStep table = pd . read_csv ( './exercise_linear_regression.csv' ) def log_likelihood ( x ): delta = table . logM_B - ( x [ 0 ] + x [ 1 ] * ( table . logsig - np . log10 ( 200 ))) sigma = table . logM_B_err return - np . sum ( delta ** 2 / sigma ** 2 / 2 ) step = GaussianStep ( np . array ([ 0.02 , 0.15 ])) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . array ([ 8.0 , 5.0 ]) model . initialize ( x0 ) sample = model . generate ( 51000 ) sample = sample [ 1000 :] x = np . linspace ( - 0.5 , 0.5 , 50 ) a , b = sample . mean ( axis = 0 ) fig = plt . figure ( figsize = ( 8 , 6 )) ax = fig . add_subplot () for _a , _b in sample [:: 1000 ,:]: ax . plot ( x , _a + _b * x , color = 'orange' , alpha = 0.1 ) ax . errorbar ( x = table . logsig - np . log10 ( 200 ), y = table . logM_B , xerr = table . logsig_err , yerr = table . logM_B_err , fmt = '.' ) ax . plot ( x , a + b * x ) ax . set_xlabel ( '$\\log\\sigma_e$ (km/s)' ) ax . set_ylabel ( '$\\log M_B$ ($M_\\odot$)' ) fig . tight_layout () plt . show () p = np . polyfit ( table . logsig - np . log10 ( 200 ), table . logM_B , 1 , w = 1. / table . logM_B_err ) print ( f 'MCMC inference: alpha= { a : .3f } , beta= { b : .3f } ' ) print ( f 'polyfit result: alpha= { p [ 1 ] : .3f } , beta= { p [ 0 ] : .3f } ' ) \u8a08\u7b97\u7d50\u679c MCMC inference: alpha=8.195, beta=5.001 polyfit result: alpha=8.195, beta=5.002 \u53c2\u8003\u307e\u3067\u306b\u4e0a\u8a18\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u51fa\u529b\u3057\u305f\u30c8\u30ec\u30fc\u30b9\u3068\u81ea\u5df1\u76f8\u95a2\u95a2\u6570\u3092\u793a\u3057\u307e\u3059. \u7dda\u5f62\u56de\u5e30\u76f4\u7dda\u304c\u53ce\u675f\u3059\u308b\u69d8\u5b50 \u4ee5\u4e0b\u306e\u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9\u3067\u4f5c\u6210\u3057\u307e\u3057\u305f. #!/usr/bin/env python # -*- coding: utf-8 -*- import numpy as np import pandas as pd import matplotlib.pyplot as plt from mhmcmc import MHMCMCSampler , GaussianStep from mhmcmc import display_trace , autocorrelation table = pd . read_csv ( '../../data/mcmc/exercise_linear_regression.csv' ) def log_likelihood ( x ): delta = table . logM_B - ( x [ 0 ] + x [ 1 ] * ( table . logsig - np . log10 ( 200 ))) sigma = table . logM_B_err return - np . sum ( delta ** 2 / sigma ** 2 / 2 ) step = GaussianStep ( np . array ([ 0.02 , 0.15 ])) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . array ([ 7.0 , 8.0 ]) model . initialize ( x0 ) sample = model . generate ( 1000 ) x = np . linspace ( - 0.5 , 0.5 , 50 ) a , b = sample [ 400 :] . mean ( axis = 0 ) fig = plt . figure ( figsize = ( 8 , 6 )) def update ( i , sample ): fig . clf () ax = fig . add_subplot () ax . errorbar ( x = table . logsig - np . log10 ( 200 ), y = table . logM_B , xerr = table . logsig_err , yerr = table . logM_B_err , fmt = '.' ) for n in range ( 10 ): _a , _b = sample [ 10 * i + n ,:] ax . plot ( x , _a + _b * x , color = 'orange' , alpha = 0.1 ) ax . plot ( x , a + b * x ) ax . text ( - 0.48 , 10.78 , f 'epoch: { 10 * i + 1 : 3d } - { 10 * i + 10 } ' , fontsize = 12 ) ax . set_xlim ([ - 0.5 , 0.5 ]) ax . set_ylim ([ 5.5 , 11.0 ]) ax . set_xlabel ( '$\\log_ {10} \\sigma_e$ (km/s)' ) ax . set_ylabel ( '$\\log_ {10} M_B$ ($M_\\odot$)' ) fig . tight_layout () import matplotlib.animation as animation ani = animation . FuncAnimation ( fig , update , fargs = ( sample ,), interval = 100 , frames = 60 ) ani . save ( 'execrcise_linear_regression_convergence.gif' , writer = 'imagemagick' ) X,Y \u8ef8\u306e\u4e0d\u5b9a\u6027\u3092\u8003\u616e\u3057\u305f\u56de\u5e30 \u30c7\u30fc\u30bf\u306b\u306f\u901f\u5ea6\u5206\u6563\u306e\u4e0d\u5b9a\u6027\u3082\u4e0e\u3048\u3089\u308c\u3066\u3044\u307e\u3057\u305f. \u5c24\u5ea6\u95a2\u6570\u3092\u5909\u66f4\u3057\u3066\u901f\u5ea6\u5206\u6563\u306e\u4e0d\u5b9a\u6027\u3082\u8003\u616e\u306b\u5165\u308c\u3066\u304f\u3060\u3055\u3044. \u901f\u5ea6\u5206\u6563\u304c \\(\\Delta\\) \u3060\u3051\u5909\u308f\u308b\u3068\u7e26\u8ef8\u306f \\(\\beta\\Delta\\) \u3060\u3051\u5909\u52d5\u3057\u307e\u3059. \u3088\u3063\u3066\u901f\u5ea6\u5206\u6563\u306e\u4e0d\u5b9a\u6027\u3092\u8003\u616e\u306b\u5165\u308c\u308b\u3068\u5c24\u5ea6\u95a2\u6570\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u66f8\u3051\u307e\u3059. \\[ \\begin{aligned} \\log{L(\\alpha,\\beta; D)} = -\\sum_{i=1}^n \\left[ \\frac{\\Delta_i^2}{2S_i^2} + \\log{S_i}\\right],\\qquad\\qquad &\\\\ \\left\\{~\\begin{aligned} \\Delta_i &= \\log_{10}{M_{B,i}} - \\alpha - \\beta\\log_{10}\\sigma_{e,i}, \\\\ S_i &= {\\varepsilon_{M,i}}^2 + \\beta^2{\\varepsilon_{\\sigma,i}}^2. \\end{aligned}\\right.& \\end{aligned} \\] \u3053\u306e\u5c24\u5ea6\u95a2\u6570\u306b\u5bfe\u3057\u3066 MCMC \u3092\u7528\u3044\u3066 \\(\\alpha\\) , \\(\\beta\\) \u306e\u5206\u5e03\u3092\u6c42\u3081\u3066\u304f\u3060\u3055\u3044. Example import numpy as np import pandas as pd import matplotlib.pyplot as plt from mhmcmc import MHMCMCSampler , GaussianStep table = pd . read_csv ( '../../data/mcmc/exercise_linear_regression.csv' ) def log_likelihood ( x ): delta = table . logM_B - ( x [ 0 ] + x [ 1 ] * ( table . logsig - np . log10 ( 200 ))) sqsig = table . logM_B_err ** 2 + x [ 1 ] ** 2 * table . logsig_err ** 2 return - np . sum ( delta ** 2 / sqsig / 2 ) step = GaussianStep ( np . array ([ 0.02 , 0.15 ])) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . array ([ 8.0 , 5.0 ]) model . initialize ( x0 ) sample = model . generate ( 51000 ) sample = sample [ 1000 :] x = np . linspace ( - 0.5 , 0.5 , 50 ) a , b = sample . mean ( axis = 0 ) fig = plt . figure ( figsize = ( 8 , 6 )) ax = fig . add_subplot () for _a , _b in sample [:: 1000 ,:]: ax . plot ( x , _a + _b * x , color = 'orange' , alpha = 0.1 ) ax . errorbar ( x = table . logsig - np . log10 ( 200 ), y = table . logM_B , xerr = table . logsig_err , yerr = table . logM_B_err , fmt = '.' ) ax . plot ( x , a + b * x ) ax . set_xlabel ( '$\\log_ {10} \\sigma_e$ (km/s)' ) ax . set_ylabel ( '$\\log_ {10} M_B$ ($M_\\odot$)' ) fig . tight_layout () fig . savefig ( 'execrcise_linear_regression_xyerror.png' ) plt . show () \u8a08\u7b97\u7d50\u679c MCMC inference: alpha=8.300, beta=4.919 \u53c2\u8003\u307e\u3067\u306b\u4e0a\u8a18\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u51fa\u529b\u3057\u305f\u30c8\u30ec\u30fc\u30b9\u3068\u81ea\u5df1\u76f8\u95a2\u95a2\u6570\u3092\u793a\u3057\u307e\u3059. \u30e2\u30c7\u30eb\u306e\u4e0d\u5b9a\u6027\u3092\u8003\u616e\u3057\u305f\u56de\u5e30 \u3053\u308c\u307e\u3067\u306e\u8a08\u7b97\u3067 \\(\\alpha\\) , \\(\\beta\\) \u306e\u78ba\u7387\u5206\u5e03\u3092\u6c42\u3081\u307e\u3057\u305f\u304c, \u6563\u5e03\u56f3\u306b\u91cd\u306d\u3066\u30d7\u30ed\u30c3\u30c8\u3092\u3057\u3066\u307f\u308b\u3068, \u6e2c\u5b9a\u8aa4\u5dee\u3067\u306f\u8aac\u660e\u304c\u3067\u304d\u306a\u3044\u307b\u3069\u50be\u5411\u304b\u3089\u5916\u308c\u305f\u70b9\u3082\u591a\u3044\u3053\u3068\u304c\u5206\u304b\u308a\u307e\u3059. \u3072\u3068\u3064\u306e\u53ef\u80fd\u6027\u306f\u6e2c\u5b9a\u8aa4\u5dee\u3092\u904e\u5c0f\u8a55\u4fa1\u3057\u3066\u3044\u308b\u3068\u3044\u3046\u3053\u3068\u3067\u3059. \u307e\u305f\u5225\u306e\u53ef\u80fd\u6027\u3068\u3057\u3066, \u3053\u3053\u3067\u306f\u8003\u616e\u3067\u304d\u3066\u3044\u306a\u3044\u7269\u7406\u91cf\u304c\u3042\u308b\u305f\u3081, \u76f4\u7dda\u304b\u3089\u306e\u30d0\u30e9\u3064\u304d\u3068\u3057\u3066 intrinsic scatter \u304c\u73fe\u308c\u3066\u3044\u308b\u3068\u898b\u308b\u3053\u3068\u3082\u3067\u304d\u307e\u3059. \u3053\u3053\u3067\u306f intrinsic scatter \u306e\u5927\u304d\u3055\u3092\u898b\u7a4d\u3082\u308b\u305f\u3081\u306b\u5909\u6570\u3092\u3072\u3068\u3064\u5897\u3084\u3057\u3066\u8a08\u7b97\u3092\u3057\u3066\u307f\u307e\u3059. \u7dda\u5f62\u56de\u5e30\u3067\u5f97\u3089\u308c\u308b\u5024\u306b\u4e00\u69d8\u306b\u4e0d\u5b9a\u6027 \\(\\varepsilon\\) \u3092\u52a0\u3048\u3066\u5c24\u5ea6\u95a2\u6570\u3092\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u5b9a\u7fa9\u3057\u307e\u3059. \\[ \\begin{aligned} \\log{L(\\alpha,\\beta,\\varepsilon; D)} = -\\sum_{i=1}^n \\left[ \\frac{\\Delta_i^2}{2S_i^2} + \\frac{1}{2}\\log{S_i^2}\\right] + \\log{\\operatorname{Gamma}(\\tau, k, \\theta)},\\qquad &\\\\ \\left\\{~\\begin{aligned} \\Delta_i &= \\log_{10}{M_{B,i}} - \\alpha - \\beta\\log_{10}\\sigma_{e,i}, \\\\ S_i^2 &= {\\varepsilon_{M,i}}^2 + \\beta^2{\\varepsilon_{\\sigma,i}}^2 + \\varepsilon^2, \\\\ \\tau~ &= \\varepsilon^{-2}. \\end{aligned}\\right.& \\end{aligned} \\] \\(\\tau\\) \u304c\u8ca0\u5024\u3092\u53d6\u3089\u306a\u3044\u3088\u3046\u306b\u4e8b\u524d\u5206\u5e03\u3068\u3057\u3066 Gamma \u5206\u5e03\u3092\u4eee\u5b9a\u3057\u307e\u3057\u305f. \u4ee5\u4e0b\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u306f\u7121\u60c5\u5831\u3067\u3042\u308b\u3053\u3068\u3092\u610f\u5473\u3059\u308b\u305f\u3081 \\(k\\) , \\(\\theta\\) \u306b\u305d\u308c\u305e\u308c \\(10^{-3}\\) , \\(10^3\\) \u3092\u4e0e\u3048\u3066\u3044\u307e\u3059. 4 Example import numpy as np import pandas as pd import matplotlib.pyplot as plt from mhmcmc import MHMCMCSampler , GaussianStep table = pd . read_csv ( '../../data/mcmc/exercise_linear_regression.csv' ) def log_gamma ( x , k = 1e-3 , t = 1e3 ): return ( k - 1 ) * np . log ( x ) - x / t if x > 0 else - 1e10 def log_likelihood ( x ): if x [ 2 ] < 0 : return - 1e10 delta = table . logM_B - ( x [ 0 ] + x [ 1 ] * ( table . logsig - np . log10 ( 200 ))) sqsig = table . logM_B_err ** 2 + x [ 1 ] ** 2 * table . logsig_err ** 2 + x [ 2 ] logpdf = - ( delta ** 2 / sqsig / 2 + np . log ( sqsig ) / 2 ) return np . sum ( logpdf ) + log_gamma ( 1 / x [ 2 ]) step = GaussianStep ( np . array ([ 0.02 , 0.15 , 0.03 ])) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . array ([ 8.0 , 5.0 , 0.5 ]) model . initialize ( x0 ) sample = model . generate ( 51000 ) sample = sample [ 1000 :] sample [:, 2 ] = np . sqrt ( sample [:, 2 ]) x = np . linspace ( - 0.5 , 0.5 , 50 ) a , b , e = sample . mean ( axis = 0 ) fig = plt . figure ( figsize = ( 8 , 6 )) ax = fig . add_subplot () ax . fill_between ( x , a + b * x - 3 * e , a + b * x + 3 * e , color = 'gray' , alpha = 0.05 ) ax . fill_between ( x , a + b * x - e , a + b * x + e , color = 'gray' , alpha = 0.10 ) for _a , _b , _e in sample [:: 1000 ,:]: ax . plot ( x , _a + _b * x , color = 'orange' , alpha = 0.05 ) ax . errorbar ( x = table . logsig - np . log10 ( 200 ), y = table . logM_B , xerr = table . logsig_err , yerr = table . logM_B_err , fmt = '.' ) ax . plot ( x , a + b * x ) ax . set_xlabel ( '$\\log_ {10} \\sigma_e$ (km/s)' ) ax . set_ylabel ( '$\\log_ {10} M_B$ ($M_\\odot$)' ) fig . tight_layout () plt . show () print ( f 'MCMC inference: alpha= { a : .3f } , beta= { b : .3f } , epsilon= { e : .3f } ' ) \u8a08\u7b97\u7d50\u679c MCMC inference: alpha=8.332, beta=4.430, epsilon=0.366 1-\u03c3, 3-\u03c3 \u306e\u4e0d\u5b9a\u6027\u3092\u30b0\u30ec\u30fc\u306e\u9818\u57df\u3067\u8868\u3057\u3066\u3044\u307e\u3059. \u53c2\u8003\u307e\u3067\u306b\u4e0a\u8a18\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u51fa\u529b\u3057\u305f\u30c8\u30ec\u30fc\u30b9\u3068\u81ea\u5df1\u76f8\u95a2\u95a2\u6570\u3092\u793a\u3057\u307e\u3059. \u4eca\u56de\u306f\u3053\u306e\u30ab\u30e9\u30e0\u306f\u4f7f\u3044\u307e\u305b\u3093. \u21a9 \u21a9 \u21a9 \u21a9 \u21a9 \u4ee5\u4e0b \\(\\sigma_{e,i}\\) \u306f \\(\\sigma_0\\) \u3067\u898f\u683c\u5316\u3055\u308c\u305f\u5024\u3068\u3057\u307e\u3059. \u21a9 \u3053\u308c\u306f\u5c24\u5ea6\u95a2\u6570\u306a\u306e\u3067\u4e8b\u524d\u5206\u5e03\u3092\u4eee\u5b9a\u3057\u3066\u639b\u3051\u306a\u3044\u3068\u6b63\u3057\u304f\u78ba\u7387\u3068\u3057\u3066\u306f\u6271\u3048\u307e\u305b\u3093\u304c, \u3053\u3053\u3067\u306f\u4e00\u69d8\u306a\u7121\u60c5\u5831\u4e8b\u524d\u5206\u5e03\u3092\u4eee\u5b9a\u3057\u305f\u3068\u3057\u3066, \u3053\u306e\u307e\u307e\u78ba\u7387\u3068\u3057\u3066\u8a08\u7b97\u3092\u3057\u3066\u3057\u307e\u3044\u307e\u3059. \u21a9 \u3053\u306e\u3068\u304d \\(\\tau\\) \u304c\u5927\u304d\u304f\u306a\u3044\u7bc4\u56f2\u3067\u306f \\({\\operatorname{Gamma}(\\tau,k,\\theta)} \\sim k\\tau^{-1}\\) \u3068\u8fd1\u4f3c\u3067\u304d, Jefferys \u306e\u7121\u60c5\u5831\u4e8b\u524d\u5206\u5e03\u3068\u4e00\u81f4\u3057\u307e\u3059. Gamma \u5206\u5e03\u306f\u30d1\u30e9\u30e1\u30bf\u306e\u5b9a\u7fa9\u306e\u4ed5\u65b9\u306b \\((k,\\theta)\\) \u3068 \\((\\alpha,\\beta)\\) \u306e 2 \u901a\u308a\u3042\u308b\u306e\u3067\u6c17\u3092\u3064\u3051\u3066\u4f7f\u3063\u3066\u304f\u3060\u3055\u3044. \u21a9","title":"\u6f14\u7fd2\u554f\u984c: \u7dda\u5f62\u56de\u5e30"},{"location":"mcmc/linear_regression/#_1","text":"\u3053\u3053\u3067\u306f\u6700\u3082\u30b7\u30f3\u30d7\u30eb\u306a\u7dda\u5f62\u56de\u5e30\u554f\u984c\u306b\u5bfe\u3057\u3066 MCMC \u3092\u4f7f\u7528\u3057\u3066\u307f\u307e\u3059. \u984c\u6750\u3068\u3057\u3066\u4f7f\u7528\u3059\u308b\u306e\u306f\u9280\u6cb3\u306e\u4e2d\u5fc3\u306b\u3042\u308b\u8d85\u5927\u8cea\u91cf\u30d6\u30e9\u30c3\u30af\u30db\u30fc\u30eb (supermassive blackhole) \u3068, \u9280\u6cb3\u30d0\u30eb\u30b8 (bulge) \u306e\u901f\u5ea6\u5206\u6563\u306e\u95a2\u4fc2\u3067\u3059.","title":"\u6f14\u7fd2\u554f\u984c: \u7dda\u5f62\u56de\u5e30"},{"location":"mcmc/linear_regression/#_2","text":"Harris et al. (2013) \u306f\u9280\u6cb3\u306b\u304a\u3051\u308b\u7403\u72b6\u661f\u56e3\u306e\u6027\u8cea\u3092\u8abf\u3079\u308b\u305f\u3081\u306b, \u5148\u884c\u7814\u7a76\u306b\u3088\u3063\u3066\u6e2c\u5b9a\u3055\u308c\u305f\u3055\u307e\u3056\u307e\u306a\u9280\u6cb3\u306e\u7269\u7406\u91cf\u3092\u307e\u3068\u3081\u305f \u30ab\u30bf\u30ed\u30b0 \u3092\u4f5c\u6210\u3057\u307e\u3057\u305f. \u4eca\u56de\u306f\u305d\u306e\u306a\u304b\u304b\u3089\u9280\u6cb3\u30d0\u30eb\u30b8\u306e\u901f\u5ea6\u5206\u6563 (\u4e3b\u306b\u53ef\u8996\u5149\u306e\u5206\u5149\u89b3\u6e2c\u304b\u3089\u63a8\u5b9a) \u3068\u9280\u6cb3\u4e2d\u5fc3\u306e\u8d85\u5927\u8cea\u91cf\u30d6\u30e9\u30c3\u30af\u30db\u30fc\u30eb\u306e\u8cea\u91cf (X \u7dda\u5149\u5ea6\u306a\u3069\u304b\u3089\u63a8\u5b9a) \u306e\u5024\u3092\u4f7f\u7528\u3057\u307e\u3059. \u6f14\u7fd2\u7528\u306b\u6574\u5f62\u3057\u305f\u30c7\u30fc\u30bf\u3092\u4ee5\u4e0b\u304b\u3089\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u304f\u3060\u3055\u3044. \u30d5\u30a1\u30a4\u30eb\u540d \u5f62\u5f0f exercise_linear_regression.csv csv \u30c7\u30fc\u30bf\u30c6\u30fc\u30d6\u30eb\u306b\u306f\u4ee5\u4e0b\u306e\u30ab\u30e9\u30e0\u304c\u542b\u307e\u308c\u3066\u3044\u307e\u3059. \u30ab\u30e9\u30e0\u540d \u8aac\u660e galaxy \u9280\u6cb3\u540d/\u30ab\u30bf\u30ed\u30b0 ID 1 ra \u8d64\u7d4c\u5ea7\u6a19 (J2000) 1 dec \u8d64\u7def\u5ea7\u6a19 (J2000) 1 dist \u8ddd\u96e2 (Mpc) 1 dist_err \u8ddd\u96e2\u306e\u4e0d\u5b9a\u6027 (Mpc) 1 logsig \u9280\u6cb3\u30d0\u30eb\u30b8\u306e\u901f\u5ea6\u5206\u6563 (\u5bfe\u6570) \\(\\log_{10}\\sigma_e\\) (km/s) logsig_err \u9280\u6cb3\u30d0\u30eb\u30b8\u306e\u901f\u5ea6\u5206\u6563\u306e\u4e0d\u5b9a\u6027 \\(\\varepsilon_\\sigma\\) logM_B \u8d85\u5927\u8cea\u91cf\u30d6\u30e9\u30c3\u30af\u30db\u30fc\u30eb\u306e\u8cea\u91cf (\u5bfe\u6570) \\(\\log_{10}{M_B}\\) ( \\({M_\\odot}\\) ) logM_B_err \u8d85\u5927\u8cea\u91cf\u30d6\u30e9\u30c3\u30af\u30db\u30fc\u30eb\u306e\u8cea\u91cf\u306e\u4e0d\u5b9a\u6027 \\(\\varepsilon_M\\) \u307e\u305a\u306f\u30c7\u30fc\u30bf\u306e\u95a2\u4fc2\u3092\u56f3\u793a\u3057\u307e\u3059. import numpy as np import pandas as pd import matplotlib.pyplot as plt table = pd . read_csv ( './exercise_linear_regression.csv' ) print ( table ) fig = plt . figure () ax = fig . add_subplot () ax . errorbar ( x = table . logsig , y = table . logM_B , xerr = table . logsig_err , yerr = table . logM_B_err , fmt = '.' ) ax . set_xlabel ( '$\\log_ {10} \\sigma_e$ (km/s)' ) ax . set_ylabel ( '$\\log_ {10} M_B$ ($M_\\odot$)' ) fig . tight_layout () plt . show () \u8a08\u7b97\u7d50\u679c galaxy ra dec dist dist_err logsig logsig_err logM_B logM_B_err 0 MilkyWay 0.000000 0.000000 0.00 0.00 2.021 0.076 6.61 0.040 1 NGC221 0.711607 40.865165 0.76 0.07 1.875 0.017 6.46 0.090 2 NGC224 0.712316 41.268883 0.77 0.02 2.204 0.021 8.18 0.150 3 NGC253 0.792531 -25.288442 3.54 0.20 2.011 0.073 7.00 0.300 4 NGC821 2.139199 10.995008 23.38 1.24 2.320 0.020 8.23 0.205 5 NGC1023 2.673329 39.063253 11.43 1.00 2.320 0.020 7.64 0.040 6 NGC1316 3.378256 -37.208211 21.09 0.30 2.357 0.006 8.24 0.200 7 NGC1332 3.438111 -21.335276 22.91 0.20 2.506 0.018 9.17 0.060 8 NGC1399 3.641408 -35.450626 20.68 0.50 2.528 0.020 8.69 0.065 9 NGC2778 9.206775 35.027417 22.91 3.39 2.243 0.019 7.15 0.300 10 NGC3031 9.925869 69.065438 3.55 0.07 2.155 0.021 7.84 0.085 11 NGC3115 10.087214 -7.718556 10.00 0.50 2.362 0.020 8.96 0.170 12 NGC3377 10.795104 13.985641 11.04 0.25 2.161 0.020 8.25 0.240 13 NGC3379 10.797108 12.581611 10.20 0.50 2.314 0.021 8.04 0.240 14 NGC3384 10.804699 12.629401 10.80 0.77 2.155 0.021 7.04 0.210 15 NGC3414 10.854492 27.974833 25.23 4.14 2.374 0.014 8.40 0.070 16 NGC3585 11.221418 -26.754864 21.20 1.73 2.328 0.020 8.51 0.140 17 NGC3607 11.281816 18.051899 20.00 2.00 2.360 0.020 8.15 0.125 18 NGC3608 11.283036 18.148538 23.00 2.00 2.260 0.021 8.67 0.095 19 NGC3842 11.733936 19.949696 94.90 6.70 2.498 0.011 9.99 0.125 20 NGC4261 12.323060 5.825041 31.62 2.89 2.498 0.020 8.71 0.085 21 NGC4291 12.338247 75.370944 26.18 4.16 2.384 0.021 8.98 0.140 22 NGC4350 12.399394 16.693471 15.50 0.78 2.256 0.017 8.74 0.100 23 NGC4374 12.417685 12.887071 18.51 0.61 2.471 0.020 8.96 0.045 24 NGC4459 12.483339 13.978556 16.01 0.55 2.223 0.020 7.84 0.080 25 NGC4472 12.496331 8.000389 17.03 0.21 2.468 0.004 9.26 0.150 26 NGC4473 12.496907 13.429397 15.25 0.51 2.279 0.020 7.95 0.240 27 NGC4486 12.513724 12.391217 17.00 0.30 2.574 0.020 9.77 0.030 28 NGC4486A 12.516033 12.270333 18.36 0.64 2.045 0.019 7.15 0.120 29 NGC4552 12.594402 12.556115 15.89 0.55 2.402 0.006 8.68 0.045 30 NGC4564 12.607493 11.439400 15.87 0.53 2.210 0.021 7.92 0.120 31 NGC4594 12.666513 -11.623010 9.77 0.84 2.380 0.021 8.72 0.435 32 NGC4621 12.700637 11.647308 14.85 0.50 2.352 0.006 8.60 0.065 33 NGC4649 12.727789 11.552672 17.09 0.61 2.585 0.021 9.63 0.100 34 NGC4697 12.809995 -5.800602 12.01 0.78 2.248 0.019 8.28 0.090 35 NGC4889 13.002237 27.977031 96.60 6.80 2.603 0.006 10.32 0.435 36 NGC5128 13.424479 -43.018118 3.80 0.07 2.176 0.020 7.71 0.160 37 IC4296 13.610847 -33.965822 49.68 2.73 2.508 0.021 9.13 0.065 38 NGC5813 15.019805 1.702009 32.21 2.78 2.374 0.006 8.84 0.070 39 NGC5845 15.100215 1.633972 25.94 2.63 2.369 0.020 8.69 0.140 40 NGC5846 15.108124 1.606291 24.89 2.40 2.379 0.008 9.04 0.080 41 NGC6086 16.209883 29.484478 137.30 9.60 2.524 0.012 9.56 0.160 42 NGC7332 22.623476 23.798260 23.01 2.22 2.097 0.011 7.11 0.190 43 IC1459 22.952945 -36.462176 29.24 4.02 2.486 0.011 9.45 0.195 44 NGC7457 23.016647 30.144889 13.24 1.34 1.826 0.019 7.00 0.300 45 NGC7768 23.849610 27.147336 112.10 7.90 2.495 0.021 9.11 0.150","title":"\u30c7\u30fc\u30bf"},{"location":"mcmc/linear_regression/#_3","text":"","title":"\u56de\u5e30\u76f4\u7dda\u306e\u5c0e\u51fa"},{"location":"mcmc/linear_regression/#y","text":"\u304a\u304a\u3088\u305d\u7dda\u5f62\u306e\u95a2\u4fc2\u3067\u8fd1\u4f3c\u3067\u304d\u305d\u3046\u306a\u3053\u3068\u304c\u5206\u304b\u308a\u307e\u3057\u305f. \u3053\u3053\u3067\u306f Harris et al. (2013) \u3092\u53c2\u8003\u306b\u3057\u3066\u4ee5\u4e0b\u306e\u5f0f\u3092\u63a1\u7528\u3057\u307e\u3059. \u305f\u3060\u3057 \\(\\sigma_0\\) \u306f 200 km/s \u3068\u3057\u307e\u3059. \\[ \\log_{10} \\frac{M_B}{M_\\odot} = \\alpha + \\beta \\log_{10}\\frac{\\sigma_e}{\\sigma_0}. \\] \u8aa4\u5dee\u306f\u6b63\u898f\u5206\u5e03\u3067\u8fd1\u4f3c\u3067\u304d\u308b\u3068\u3044\u3046\u5358\u7d14\u306a\u30e2\u30c7\u30eb\u3092\u63a1\u7528\u3057\u307e\u3059. \u307e\u305a\u306f Y \u8ef8 ( \\(\\log{M_B}\\) ) \u306e\u4e0d\u5b9a\u6027\u3060\u3051\u3092\u8003\u3048\u3066\u5c24\u5ea6\u95a2\u6570 (\u78ba\u7387) \u3092\u5c0e\u51fa\u3057\u307e\u3059. 2 3 \\[ \\log{L(\\alpha,\\beta; D)} = -\\sum_{i=1}^n \\frac{ \\left( \\log_{10}{M_{B,i}} - \\alpha - \\beta\\log_{10}\\sigma_{e,i} \\right)^2 }{2{\\varepsilon_{M,i}}^2}. \\] \u3053\u306e\u5c24\u5ea6\u95a2\u6570\u306b\u5bfe\u3057\u3066 MCMC \u3092\u7528\u3044\u3066 \\(\\alpha\\) , \\(\\beta\\) \u306e\u5206\u5e03\u3092\u6c42\u3081\u3066\u304f\u3060\u3055\u3044. \u307e\u305f \\(\\alpha\\) , \\(\\beta\\) \u306e\u5e73\u5747\u5024\u3092 polynomial fitting ( numpy.polyfit ) \u306e\u7d50\u679c\u3068\u6bd4\u8f03\u3057\u3066\u304f\u3060\u3055\u3044. Example import numpy as np import pandas as pd import matplotlib.pyplot as plt from mhmcmc import MHMCMCSampler , GaussianStep table = pd . read_csv ( './exercise_linear_regression.csv' ) def log_likelihood ( x ): delta = table . logM_B - ( x [ 0 ] + x [ 1 ] * ( table . logsig - np . log10 ( 200 ))) sigma = table . logM_B_err return - np . sum ( delta ** 2 / sigma ** 2 / 2 ) step = GaussianStep ( np . array ([ 0.02 , 0.15 ])) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . array ([ 8.0 , 5.0 ]) model . initialize ( x0 ) sample = model . generate ( 51000 ) sample = sample [ 1000 :] x = np . linspace ( - 0.5 , 0.5 , 50 ) a , b = sample . mean ( axis = 0 ) fig = plt . figure ( figsize = ( 8 , 6 )) ax = fig . add_subplot () for _a , _b in sample [:: 1000 ,:]: ax . plot ( x , _a + _b * x , color = 'orange' , alpha = 0.1 ) ax . errorbar ( x = table . logsig - np . log10 ( 200 ), y = table . logM_B , xerr = table . logsig_err , yerr = table . logM_B_err , fmt = '.' ) ax . plot ( x , a + b * x ) ax . set_xlabel ( '$\\log\\sigma_e$ (km/s)' ) ax . set_ylabel ( '$\\log M_B$ ($M_\\odot$)' ) fig . tight_layout () plt . show () p = np . polyfit ( table . logsig - np . log10 ( 200 ), table . logM_B , 1 , w = 1. / table . logM_B_err ) print ( f 'MCMC inference: alpha= { a : .3f } , beta= { b : .3f } ' ) print ( f 'polyfit result: alpha= { p [ 1 ] : .3f } , beta= { p [ 0 ] : .3f } ' ) \u8a08\u7b97\u7d50\u679c MCMC inference: alpha=8.195, beta=5.001 polyfit result: alpha=8.195, beta=5.002 \u53c2\u8003\u307e\u3067\u306b\u4e0a\u8a18\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u51fa\u529b\u3057\u305f\u30c8\u30ec\u30fc\u30b9\u3068\u81ea\u5df1\u76f8\u95a2\u95a2\u6570\u3092\u793a\u3057\u307e\u3059. \u7dda\u5f62\u56de\u5e30\u76f4\u7dda\u304c\u53ce\u675f\u3059\u308b\u69d8\u5b50 \u4ee5\u4e0b\u306e\u30b5\u30f3\u30d7\u30eb\u30b3\u30fc\u30c9\u3067\u4f5c\u6210\u3057\u307e\u3057\u305f. #!/usr/bin/env python # -*- coding: utf-8 -*- import numpy as np import pandas as pd import matplotlib.pyplot as plt from mhmcmc import MHMCMCSampler , GaussianStep from mhmcmc import display_trace , autocorrelation table = pd . read_csv ( '../../data/mcmc/exercise_linear_regression.csv' ) def log_likelihood ( x ): delta = table . logM_B - ( x [ 0 ] + x [ 1 ] * ( table . logsig - np . log10 ( 200 ))) sigma = table . logM_B_err return - np . sum ( delta ** 2 / sigma ** 2 / 2 ) step = GaussianStep ( np . array ([ 0.02 , 0.15 ])) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . array ([ 7.0 , 8.0 ]) model . initialize ( x0 ) sample = model . generate ( 1000 ) x = np . linspace ( - 0.5 , 0.5 , 50 ) a , b = sample [ 400 :] . mean ( axis = 0 ) fig = plt . figure ( figsize = ( 8 , 6 )) def update ( i , sample ): fig . clf () ax = fig . add_subplot () ax . errorbar ( x = table . logsig - np . log10 ( 200 ), y = table . logM_B , xerr = table . logsig_err , yerr = table . logM_B_err , fmt = '.' ) for n in range ( 10 ): _a , _b = sample [ 10 * i + n ,:] ax . plot ( x , _a + _b * x , color = 'orange' , alpha = 0.1 ) ax . plot ( x , a + b * x ) ax . text ( - 0.48 , 10.78 , f 'epoch: { 10 * i + 1 : 3d } - { 10 * i + 10 } ' , fontsize = 12 ) ax . set_xlim ([ - 0.5 , 0.5 ]) ax . set_ylim ([ 5.5 , 11.0 ]) ax . set_xlabel ( '$\\log_ {10} \\sigma_e$ (km/s)' ) ax . set_ylabel ( '$\\log_ {10} M_B$ ($M_\\odot$)' ) fig . tight_layout () import matplotlib.animation as animation ani = animation . FuncAnimation ( fig , update , fargs = ( sample ,), interval = 100 , frames = 60 ) ani . save ( 'execrcise_linear_regression_convergence.gif' , writer = 'imagemagick' )","title":"Y \u8ef8\u306e\u4e0d\u5b9a\u6027\u3092\u8003\u616e\u3057\u305f\u56de\u5e30"},{"location":"mcmc/linear_regression/#xy","text":"\u30c7\u30fc\u30bf\u306b\u306f\u901f\u5ea6\u5206\u6563\u306e\u4e0d\u5b9a\u6027\u3082\u4e0e\u3048\u3089\u308c\u3066\u3044\u307e\u3057\u305f. \u5c24\u5ea6\u95a2\u6570\u3092\u5909\u66f4\u3057\u3066\u901f\u5ea6\u5206\u6563\u306e\u4e0d\u5b9a\u6027\u3082\u8003\u616e\u306b\u5165\u308c\u3066\u304f\u3060\u3055\u3044. \u901f\u5ea6\u5206\u6563\u304c \\(\\Delta\\) \u3060\u3051\u5909\u308f\u308b\u3068\u7e26\u8ef8\u306f \\(\\beta\\Delta\\) \u3060\u3051\u5909\u52d5\u3057\u307e\u3059. \u3088\u3063\u3066\u901f\u5ea6\u5206\u6563\u306e\u4e0d\u5b9a\u6027\u3092\u8003\u616e\u306b\u5165\u308c\u308b\u3068\u5c24\u5ea6\u95a2\u6570\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u66f8\u3051\u307e\u3059. \\[ \\begin{aligned} \\log{L(\\alpha,\\beta; D)} = -\\sum_{i=1}^n \\left[ \\frac{\\Delta_i^2}{2S_i^2} + \\log{S_i}\\right],\\qquad\\qquad &\\\\ \\left\\{~\\begin{aligned} \\Delta_i &= \\log_{10}{M_{B,i}} - \\alpha - \\beta\\log_{10}\\sigma_{e,i}, \\\\ S_i &= {\\varepsilon_{M,i}}^2 + \\beta^2{\\varepsilon_{\\sigma,i}}^2. \\end{aligned}\\right.& \\end{aligned} \\] \u3053\u306e\u5c24\u5ea6\u95a2\u6570\u306b\u5bfe\u3057\u3066 MCMC \u3092\u7528\u3044\u3066 \\(\\alpha\\) , \\(\\beta\\) \u306e\u5206\u5e03\u3092\u6c42\u3081\u3066\u304f\u3060\u3055\u3044. Example import numpy as np import pandas as pd import matplotlib.pyplot as plt from mhmcmc import MHMCMCSampler , GaussianStep table = pd . read_csv ( '../../data/mcmc/exercise_linear_regression.csv' ) def log_likelihood ( x ): delta = table . logM_B - ( x [ 0 ] + x [ 1 ] * ( table . logsig - np . log10 ( 200 ))) sqsig = table . logM_B_err ** 2 + x [ 1 ] ** 2 * table . logsig_err ** 2 return - np . sum ( delta ** 2 / sqsig / 2 ) step = GaussianStep ( np . array ([ 0.02 , 0.15 ])) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . array ([ 8.0 , 5.0 ]) model . initialize ( x0 ) sample = model . generate ( 51000 ) sample = sample [ 1000 :] x = np . linspace ( - 0.5 , 0.5 , 50 ) a , b = sample . mean ( axis = 0 ) fig = plt . figure ( figsize = ( 8 , 6 )) ax = fig . add_subplot () for _a , _b in sample [:: 1000 ,:]: ax . plot ( x , _a + _b * x , color = 'orange' , alpha = 0.1 ) ax . errorbar ( x = table . logsig - np . log10 ( 200 ), y = table . logM_B , xerr = table . logsig_err , yerr = table . logM_B_err , fmt = '.' ) ax . plot ( x , a + b * x ) ax . set_xlabel ( '$\\log_ {10} \\sigma_e$ (km/s)' ) ax . set_ylabel ( '$\\log_ {10} M_B$ ($M_\\odot$)' ) fig . tight_layout () fig . savefig ( 'execrcise_linear_regression_xyerror.png' ) plt . show () \u8a08\u7b97\u7d50\u679c MCMC inference: alpha=8.300, beta=4.919 \u53c2\u8003\u307e\u3067\u306b\u4e0a\u8a18\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u51fa\u529b\u3057\u305f\u30c8\u30ec\u30fc\u30b9\u3068\u81ea\u5df1\u76f8\u95a2\u95a2\u6570\u3092\u793a\u3057\u307e\u3059.","title":"X,Y \u8ef8\u306e\u4e0d\u5b9a\u6027\u3092\u8003\u616e\u3057\u305f\u56de\u5e30"},{"location":"mcmc/linear_regression/#_4","text":"\u3053\u308c\u307e\u3067\u306e\u8a08\u7b97\u3067 \\(\\alpha\\) , \\(\\beta\\) \u306e\u78ba\u7387\u5206\u5e03\u3092\u6c42\u3081\u307e\u3057\u305f\u304c, \u6563\u5e03\u56f3\u306b\u91cd\u306d\u3066\u30d7\u30ed\u30c3\u30c8\u3092\u3057\u3066\u307f\u308b\u3068, \u6e2c\u5b9a\u8aa4\u5dee\u3067\u306f\u8aac\u660e\u304c\u3067\u304d\u306a\u3044\u307b\u3069\u50be\u5411\u304b\u3089\u5916\u308c\u305f\u70b9\u3082\u591a\u3044\u3053\u3068\u304c\u5206\u304b\u308a\u307e\u3059. \u3072\u3068\u3064\u306e\u53ef\u80fd\u6027\u306f\u6e2c\u5b9a\u8aa4\u5dee\u3092\u904e\u5c0f\u8a55\u4fa1\u3057\u3066\u3044\u308b\u3068\u3044\u3046\u3053\u3068\u3067\u3059. \u307e\u305f\u5225\u306e\u53ef\u80fd\u6027\u3068\u3057\u3066, \u3053\u3053\u3067\u306f\u8003\u616e\u3067\u304d\u3066\u3044\u306a\u3044\u7269\u7406\u91cf\u304c\u3042\u308b\u305f\u3081, \u76f4\u7dda\u304b\u3089\u306e\u30d0\u30e9\u3064\u304d\u3068\u3057\u3066 intrinsic scatter \u304c\u73fe\u308c\u3066\u3044\u308b\u3068\u898b\u308b\u3053\u3068\u3082\u3067\u304d\u307e\u3059. \u3053\u3053\u3067\u306f intrinsic scatter \u306e\u5927\u304d\u3055\u3092\u898b\u7a4d\u3082\u308b\u305f\u3081\u306b\u5909\u6570\u3092\u3072\u3068\u3064\u5897\u3084\u3057\u3066\u8a08\u7b97\u3092\u3057\u3066\u307f\u307e\u3059. \u7dda\u5f62\u56de\u5e30\u3067\u5f97\u3089\u308c\u308b\u5024\u306b\u4e00\u69d8\u306b\u4e0d\u5b9a\u6027 \\(\\varepsilon\\) \u3092\u52a0\u3048\u3066\u5c24\u5ea6\u95a2\u6570\u3092\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u5b9a\u7fa9\u3057\u307e\u3059. \\[ \\begin{aligned} \\log{L(\\alpha,\\beta,\\varepsilon; D)} = -\\sum_{i=1}^n \\left[ \\frac{\\Delta_i^2}{2S_i^2} + \\frac{1}{2}\\log{S_i^2}\\right] + \\log{\\operatorname{Gamma}(\\tau, k, \\theta)},\\qquad &\\\\ \\left\\{~\\begin{aligned} \\Delta_i &= \\log_{10}{M_{B,i}} - \\alpha - \\beta\\log_{10}\\sigma_{e,i}, \\\\ S_i^2 &= {\\varepsilon_{M,i}}^2 + \\beta^2{\\varepsilon_{\\sigma,i}}^2 + \\varepsilon^2, \\\\ \\tau~ &= \\varepsilon^{-2}. \\end{aligned}\\right.& \\end{aligned} \\] \\(\\tau\\) \u304c\u8ca0\u5024\u3092\u53d6\u3089\u306a\u3044\u3088\u3046\u306b\u4e8b\u524d\u5206\u5e03\u3068\u3057\u3066 Gamma \u5206\u5e03\u3092\u4eee\u5b9a\u3057\u307e\u3057\u305f. \u4ee5\u4e0b\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u306f\u7121\u60c5\u5831\u3067\u3042\u308b\u3053\u3068\u3092\u610f\u5473\u3059\u308b\u305f\u3081 \\(k\\) , \\(\\theta\\) \u306b\u305d\u308c\u305e\u308c \\(10^{-3}\\) , \\(10^3\\) \u3092\u4e0e\u3048\u3066\u3044\u307e\u3059. 4 Example import numpy as np import pandas as pd import matplotlib.pyplot as plt from mhmcmc import MHMCMCSampler , GaussianStep table = pd . read_csv ( '../../data/mcmc/exercise_linear_regression.csv' ) def log_gamma ( x , k = 1e-3 , t = 1e3 ): return ( k - 1 ) * np . log ( x ) - x / t if x > 0 else - 1e10 def log_likelihood ( x ): if x [ 2 ] < 0 : return - 1e10 delta = table . logM_B - ( x [ 0 ] + x [ 1 ] * ( table . logsig - np . log10 ( 200 ))) sqsig = table . logM_B_err ** 2 + x [ 1 ] ** 2 * table . logsig_err ** 2 + x [ 2 ] logpdf = - ( delta ** 2 / sqsig / 2 + np . log ( sqsig ) / 2 ) return np . sum ( logpdf ) + log_gamma ( 1 / x [ 2 ]) step = GaussianStep ( np . array ([ 0.02 , 0.15 , 0.03 ])) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . array ([ 8.0 , 5.0 , 0.5 ]) model . initialize ( x0 ) sample = model . generate ( 51000 ) sample = sample [ 1000 :] sample [:, 2 ] = np . sqrt ( sample [:, 2 ]) x = np . linspace ( - 0.5 , 0.5 , 50 ) a , b , e = sample . mean ( axis = 0 ) fig = plt . figure ( figsize = ( 8 , 6 )) ax = fig . add_subplot () ax . fill_between ( x , a + b * x - 3 * e , a + b * x + 3 * e , color = 'gray' , alpha = 0.05 ) ax . fill_between ( x , a + b * x - e , a + b * x + e , color = 'gray' , alpha = 0.10 ) for _a , _b , _e in sample [:: 1000 ,:]: ax . plot ( x , _a + _b * x , color = 'orange' , alpha = 0.05 ) ax . errorbar ( x = table . logsig - np . log10 ( 200 ), y = table . logM_B , xerr = table . logsig_err , yerr = table . logM_B_err , fmt = '.' ) ax . plot ( x , a + b * x ) ax . set_xlabel ( '$\\log_ {10} \\sigma_e$ (km/s)' ) ax . set_ylabel ( '$\\log_ {10} M_B$ ($M_\\odot$)' ) fig . tight_layout () plt . show () print ( f 'MCMC inference: alpha= { a : .3f } , beta= { b : .3f } , epsilon= { e : .3f } ' ) \u8a08\u7b97\u7d50\u679c MCMC inference: alpha=8.332, beta=4.430, epsilon=0.366 1-\u03c3, 3-\u03c3 \u306e\u4e0d\u5b9a\u6027\u3092\u30b0\u30ec\u30fc\u306e\u9818\u57df\u3067\u8868\u3057\u3066\u3044\u307e\u3059. \u53c2\u8003\u307e\u3067\u306b\u4e0a\u8a18\u306e\u30b5\u30f3\u30d7\u30eb\u3067\u51fa\u529b\u3057\u305f\u30c8\u30ec\u30fc\u30b9\u3068\u81ea\u5df1\u76f8\u95a2\u95a2\u6570\u3092\u793a\u3057\u307e\u3059. \u4eca\u56de\u306f\u3053\u306e\u30ab\u30e9\u30e0\u306f\u4f7f\u3044\u307e\u305b\u3093. \u21a9 \u21a9 \u21a9 \u21a9 \u21a9 \u4ee5\u4e0b \\(\\sigma_{e,i}\\) \u306f \\(\\sigma_0\\) \u3067\u898f\u683c\u5316\u3055\u308c\u305f\u5024\u3068\u3057\u307e\u3059. \u21a9 \u3053\u308c\u306f\u5c24\u5ea6\u95a2\u6570\u306a\u306e\u3067\u4e8b\u524d\u5206\u5e03\u3092\u4eee\u5b9a\u3057\u3066\u639b\u3051\u306a\u3044\u3068\u6b63\u3057\u304f\u78ba\u7387\u3068\u3057\u3066\u306f\u6271\u3048\u307e\u305b\u3093\u304c, \u3053\u3053\u3067\u306f\u4e00\u69d8\u306a\u7121\u60c5\u5831\u4e8b\u524d\u5206\u5e03\u3092\u4eee\u5b9a\u3057\u305f\u3068\u3057\u3066, \u3053\u306e\u307e\u307e\u78ba\u7387\u3068\u3057\u3066\u8a08\u7b97\u3092\u3057\u3066\u3057\u307e\u3044\u307e\u3059. \u21a9 \u3053\u306e\u3068\u304d \\(\\tau\\) \u304c\u5927\u304d\u304f\u306a\u3044\u7bc4\u56f2\u3067\u306f \\({\\operatorname{Gamma}(\\tau,k,\\theta)} \\sim k\\tau^{-1}\\) \u3068\u8fd1\u4f3c\u3067\u304d, Jefferys \u306e\u7121\u60c5\u5831\u4e8b\u524d\u5206\u5e03\u3068\u4e00\u81f4\u3057\u307e\u3059. Gamma \u5206\u5e03\u306f\u30d1\u30e9\u30e1\u30bf\u306e\u5b9a\u7fa9\u306e\u4ed5\u65b9\u306b \\((k,\\theta)\\) \u3068 \\((\\alpha,\\beta)\\) \u306e 2 \u901a\u308a\u3042\u308b\u306e\u3067\u6c17\u3092\u3064\u3051\u3066\u4f7f\u3063\u3066\u304f\u3060\u3055\u3044. \u21a9","title":"\u30e2\u30c7\u30eb\u306e\u4e0d\u5b9a\u6027\u3092\u8003\u616e\u3057\u305f\u56de\u5e30"},{"location":"mcmc/markov_chain/","text":"\u52d5\u7684\u306a\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5 \u524d\u9805 \u3067\u306f\u554f\u984c\u306e\u6b21\u5143\u304c\u5927\u304d\u304f\u306a\u308b\u3068, \u9759\u7684\u306a\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5\u3067\u306f\u30bf\u30fc\u30b2\u30c3\u30c8\u3068\u306a\u308b\u5206\u5e03\u306b\u30d2\u30c3\u30c8\u3059\u308b\u78ba\u7387\u304c\u8457\u3057\u304f\u4e0b\u304c\u308b\u305f\u3081, \u52b9\u7387\u3088\u304f\u8a08\u7b97\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u306a\u3044\u3068\u3044\u3046\u554f\u984c\u306b\u3064\u3044\u3066\u89e6\u308c\u307e\u3057\u305f. \u3053\u308c\u306f\u30bf\u30fc\u30b2\u30c3\u30c8\u3068\u306a\u308b\u78ba\u7387\u5206\u5e03\u3092\u63d0\u6848\u5206\u5e03\u3067\u3046\u307e\u304f\u8fd1\u4f3c\u3067\u304d\u3066\u3044\u306a\u3044\u3053\u3068\u306b\u8d77\u56e0\u3057\u307e\u3059. \u305d\u3053\u3067, \u78ba\u7387\u5206\u5e03\u5168\u4f53\u3092\u3046\u307e\u304f\u8fd1\u4f3c\u3059\u308b\u3053\u3068\u3092\u3042\u304d\u3089\u3081\u3066, \u3042\u308b\u30c7\u30fc\u30bf\u306e\u8fd1\u508d\u3067\u306e\u307f\u3046\u307e\u304f\u8fd1\u4f3c\u3059\u308b\u3053\u3068\u3092\u8003\u3048\u307e\u3059. \u3054\u304f\u8fd1\u508d\u3067\u3057\u304b\u3064\u3058\u3064\u307e\u304c\u5408\u3063\u3066\u3044\u306a\u304f\u3066\u3082, \u305d\u306e\u60c5\u5831\u3092\u9069\u5207\u306b\u3064\u306a\u304e\u5408\u308f\u305b\u308b\u3053\u3068\u304c\u3067\u304d\u308c\u3070, \u78ba\u7387\u5206\u5e03\u5168\u4f53\u3092\u3046\u307e\u304f\u8868\u73fe\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u306f\u305a\u3067\u3059. \u3053\u3053\u3067\u306f\u300c\u30de\u30eb\u30b3\u30d5\u9023\u9396\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5\u300d\u306b\u3064\u3044\u3066\u8aac\u660e\u3057\u307e\u3059. \u30c7\u30fc\u30bf\u3092\u52b9\u7387\u3088\u304f\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3059\u308b\u305f\u3081\u306b, \u3042\u308b\u30c7\u30fc\u30bf\u306e\u8fd1\u508d\u3067\u306e\u307f\u6b21\u306e\u30b5\u30f3\u30d7\u30eb\u3092\u63a2\u3059\u3068\u3044\u3046\u6226\u7565\u3092\u3068\u308a\u307e\u3059. \u4e00\u56de\u306e\u64cd\u4f5c\u3067\u306f\u78ba\u7387\u5206\u5e03\u95a2\u6570\u306e\u3054\u304f\u4e00\u90e8\u3057\u304b\u63a2\u7d22\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u305b\u3093\u304c, \u3053\u306e\u64cd\u4f5c\u3092\u591a\u6570\u56de\u7e70\u308a\u8fd4\u3059\u3053\u3068\u306b\u3088\u3063\u3066\u78ba\u7387\u5206\u5e03\u95a2\u6570\u5168\u4f53\u306e\u5f62\u72b6\u3092\u3092\u6d6e\u304b\u3073\u4e0a\u304c\u3089\u305b\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u30de\u30eb\u30b3\u30d5\u9023\u9396\u3068\u306f \u30de\u30eb\u30b3\u30d5\u9023\u9396\u3068\u306f\u30de\u30eb\u30b3\u30d5\u904e\u7a0b\u306b\u3088\u3063\u3066\u751f\u6210\u3055\u308c\u305f\u72b6\u614b (\u30c7\u30fc\u30bf) \u306e\u5217 \\(\\{x_t\\}_{t=0{\\ldots}}\\) \u3092\u8868\u3057\u307e\u3059. 1 \u30de\u30eb\u30b3\u30d5\u904e\u7a0b\u3068\u306f \u201c\u73fe\u5728\u306e\u72b6\u614b \\(x\\) \u304b\u3089\u6b21\u306e\u72b6\u614b \\(x'\\) \u3078\u9077\u79fb\u3059\u308b\u78ba\u7387 \\(\\pi(x \\to x')\\) \u304c\u73fe\u5728\u306e\u72b6\u614b\u306b\u3088\u3063\u3066\u6c7a\u307e\u308b\u201d \u3068\u3044\u3046\u904e\u7a0b\u3092\u8868\u3057\u3066\u3044\u307e\u3059. 2 \u3042\u308b\u6761\u4ef6\u306e\u3082\u3068\u3067\u306f\u5341\u5206\u306b\u9577\u3044\u6642\u9593\u9077\u79fb\u3092\u7e70\u308a\u8fd4\u3057\u305f\u3068\u304d\u306e \\(\\{x_t\\}_{t=0{\\ldots}}\\) \u306e\u5206\u5e03\u304c (\u521d\u671f\u5024 \\(x_0\\) \u306b\u4f9d\u3089\u305a) \u3042\u308b\u5206\u5e03 \\(\\mathcal{P}(x)\\) \u306b\u53ce\u675f\u3059\u308b\u3053\u3068\u304c\u671f\u5f85\u3055\u308c\u307e\u3059. 3 \u3053\u306e\u5206\u5e03\u306e\u3053\u3068\u3092\u5b9a\u5e38\u5206\u5e03\u3068\u547c\u3073\u307e\u3059. \u3042\u308b\u6642\u523b \\(t\\) \u307e\u3067\u30de\u30eb\u30b3\u30d5\u9023\u9396\u3092\u7e70\u308a\u8fd4\u3057\u305f\u3068\u304d\u306b\u671f\u5f85\u3055\u308c\u308b \\(x\\) \u306e\u78ba\u7387\u5206\u5e03\u95a2\u6570\u3092 \\(\\mathcal{P}_t(x)\\) \u3068\u3057\u307e\u3059. \u3053\u3053\u304b\u3089\u6642\u523b \\(t+1\\) \u306b\u304a\u3051\u308b\u5206\u5e03 \\(\\mathcal{P}_{t+1}(x)\\) \u3092\u8a08\u7b97\u3059\u308b\u3068\u4ee5\u4e0b\u306e\u5f0f\u306b\u306a\u308a\u307e\u3059. 4 \\[ \\mathcal{P}_{t+1}(x') = \\int\\mathrm{d}x\\,\\mathcal{P}_{t}(x)\\pi(x \\to x'). \\] \\(t \\to \\infty\\) \u306e\u3068\u304d\u306b \\(\\mathcal{P}_{t}(x)\\) \u304c\u5b9a\u5e38\u5206\u5e03\u306b\u53ce\u675f\u3059\u308b\u306e\u3067\u3042\u308c\u3070 \\(\\mathcal{P}(x)\\) \u306f, \\[ \\mathcal{P}(x') = \\int\\mathrm{d}x\\,\\mathcal{P}(x)\\pi(x \\to x'). \\] \u3092\u6e80\u305f\u3057\u3066\u3044\u308b\u3053\u3068\u304c\u5fc5\u8981\u306b\u306a\u308a\u307e\u3059. \u307e\u305f, \u3053\u3046\u3057\u305f\u5b9a\u5e38\u5206\u5e03\u304c\u5b58\u5728\u3059\u308b\u305f\u3081\u306b\u306f, \u72b6\u614b\u9077\u79fb\u306e\u30eb\u30fc\u30eb\u306b\u3082\u5236\u7d04\u304c\u3042\u308a\u307e\u3059. \u307e\u305a, \u5b58\u5728\u3059\u308b\u3069\u306e\u72b6\u614b\u30da\u30a2 \\((x, x')\\) \u3082\u6709\u9650\u56de\u306e\u64cd\u4f5c\u3067\u9077\u79fb\u3067\u304d\u308b (\u72b6\u614b\u304c\u5206\u65ad\u3055\u308c\u3066\u3044\u306a\u3044) \u3053\u3068\u304c\u5fc5\u8981\u3067\u3059. \u52a0\u3048\u3066, \u72b6\u614b\u306e\u9077\u79fb\u306b\u306f\u975e\u5468\u671f\u6027\u3082\u5fc5\u8981\u3068\u3055\u308c\u307e\u3059\u304c, \u3053\u3053\u3067\u306f\u8a73\u7d30\u306b\u3064\u3044\u3066\u306f\u7701\u7565\u3057\u307e\u3059. 5 \u5341\u5206\u306b\u9577\u3044\u6642\u9593\u30de\u30eb\u30b3\u30d5\u9023\u9396\u306e\u30b9\u30c6\u30c3\u30d7\u3092\u7e70\u308a\u8fd4\u3059\u3053\u3068\u3067, \u30de\u30eb\u30b3\u30d5\u9023\u9396\u5217 \\(\\{x_t\\}_{t=0{\\ldots}}\\) \u3092\u5b9a\u5e38\u5206\u5e03 \\(\\mathcal{P}(x)\\) \u304b\u3089\u30b5\u30f3\u30d7\u30eb\u3057\u305f\u4e71\u6570\u3068\u307f\u306a\u3059\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u3053\u3053\u3067\u72b6\u614b\u9077\u79fb\u306e\u30eb\u30fc\u30eb\u3092\u3046\u307e\u304f\u8a2d\u5b9a\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066, \u53ce\u675f\u5148\u306e\u5b9a\u5e38\u5206\u5e03\u3092\u30b3\u30f3\u30c8\u30ed\u30fc\u30eb\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u30bf\u30fc\u30b2\u30c3\u30c8\u3068\u306a\u308b\u78ba\u7387\u5206\u5e03\u95a2\u6570 \\(P(x)\\) \u306b\u53ce\u675f\u3059\u308b\u3088\u3046\u306a\u30de\u30eb\u30b3\u30d5\u9023\u9396\u3092\u8a2d\u8a08\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308c\u3070, \u4efb\u610f\u306e\u78ba\u7387\u5206\u5e03\u95a2\u6570\u304b\u3089\u306e\u4e71\u6570\u3092\u52b9\u7387\u3088\u304f\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u305d\u3046\u3067\u3059. \u5206\u5e03\u306e\u53ce\u675f\u6027\u306b\u3064\u3044\u3066\u306e\u30b3\u30e1\u30f3\u30c8 \u3053\u3053\u3067\u306f\u64cd\u4f5c\u3092\u7e70\u308a\u8fd4\u3059\u3053\u3068\u306b\u3088\u3063\u3066\u671f\u5f85\u3055\u308c\u308b\u5206\u5e03\u304c\u3069\u306e\u3088\u3046\u306b\u5909\u308f\u3063\u3066\u3044\u304f\u304b\u3092\u8003\u3048\u308b\u3053\u3068\u3067, \u5206\u5e03\u306e\u53ce\u675f\u6027\u306b\u3064\u3044\u3066\u8aac\u660e\u3057\u307e\u3059. \\(t=0\\) \u306e\u3068\u304d\u306b\u671f\u5f85\u3055\u308c\u308b \\(x\\) \u306e\u5206\u5e03\u3092 \\(\\mathcal{P}_0{x}\\) \u3068\u3057\u307e\u3059. \u3053\u308c\u306f\u521d\u671f\u72b6\u614b\u3068\u3057\u3066\u5b9a\u7fa9\u3057\u3066\u3044\u308b\u3060\u3051\u3067\u4efb\u610f\u306e\u5206\u5e03\u3067\u3059. 1 \u30b9\u30c6\u30c3\u30d7\u5f8c\u306e\u5206\u5e03\u3092\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u66f8\u304f\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \\[ \\mathcal{P}_1(x) = \\int\\mathrm{d}x'\\,\\mathcal{P}_0(x')\\pi(x' \\to x) = c\\mathcal{P}(x) + (1-c)R_0(x). \\] \u305f\u3060\u3057 \\(0 < c < 1\\) \u3067 \\(\\mathcal{P}_0(x)\\) \u306b\u4f9d\u3089\u306a\u3044\u5b9a\u6570\u306b\u306a\u308a\u307e\u3059 (\u3053\u306e\u5f62\u3067\u66f8\u3051\u308b\u3053\u3068\u306e\u8a3c\u660e\u306f\u7701\u7565\u3057\u307e\u3059). \\(\\pi(x \\to x')\\) \u306e\u64cd\u4f5c\u3092\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066 \\(\\mathcal{P}_1(x)\\) \u304b\u3089 \\(c\\) \u500d\u3060\u3051 \\(\\mathcal{P}(x)\\) \u3092\u524a\u308a\u51fa\u3059\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u540c\u3058\u72b6\u614b\u9077\u79fb\u3092\u5b9f\u884c\u3059\u308b\u3068, \\[ \\begin{aligned} \\mathcal{P}_2(x) &= c\\mathcal{P}(x) + (1-c)(c\\mathcal{P}(x) + (1-c)R_1(x)) \\\\ &= \\left(1 - (1-c)^2\\right) \\mathcal{P}(x) + (1-c)^2 R_1(x) \\end{aligned} \\] \u3068\u5909\u63db\u3067\u304d\u307e\u3059. \u305f\u3060\u3057 \\(R_0(x)\\) \u3092\u521d\u671f\u5206\u5e03\u3068\u3057\u3066 \\(c\\mathcal{P}(x)\\) \u3092\u524a\u308a\u3060\u3059\u64cd\u4f5c\u3092\u518d\u3073\u304a\u3053\u3063\u3066\u3044\u307e\u3059. \u72b6\u614b\u9077\u79fb\u3092 \\(m\\) \u56de\u7e70\u308a\u8fd4\u3059\u3053\u3068\u306b\u3088\u3063\u3066\u4ee5\u4e0b\u306e\u5f0f\u3092\u5f97\u307e\u3059. \\[ \\mathcal{P}_m(x) = \\left(1 - (1-c)^m\\right) \\mathcal{P}(x) + (1-c)^m R_{m-1}(x). \\] \\(m \\to \\infty\\) \u306e\u6975\u9650\u3067\u4efb\u610f\u306e\u5206\u5e03 \\(\\mathcal{P}_0(x)\\) \u304b\u3089 \\(\\mathcal{P}(x)\\) \u306b\u53ce\u675f\u3059\u308b\u3053\u3068\u304c\u793a\u305b\u307e\u3057\u305f. \u30de\u30eb\u30b3\u30d5\u9023\u9396\u306b\u3088\u308b\u30b5\u30f3\u30d7\u30eb\u751f\u6210 \u3053\u3053\u307e\u3067, \u30de\u30eb\u30b3\u30d5\u9023\u9396\u306b\u3088\u3063\u3066\u5b9a\u5e38\u5206\u5e03 \\(P(x)\\) \u306b\u5f93\u3046\u4e71\u6570\u3092\u751f\u6210\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3053\u3068\u3092\u78ba\u8a8d\u3057\u307e\u3057\u305f. \u6b21\u306b\u5b9a\u5e38\u5206\u5e03 \\(\\mathcal{P}(x)\\) \u3092\u4efb\u610f\u306e\u78ba\u7387\u5206\u5e03\u95a2\u6570 \\(P(x)\\) \u306b\u3059\u308b\u305f\u3081\u306e\u65b9\u6cd5\u306b\u3064\u3044\u3066\u7d39\u4ecb\u3057\u307e\u3059. \u5b9a\u5e38\u5206\u5e03\u304c\u6e80\u305f\u3059\u3079\u304d\u5f0f\u306f \\[ \\mathcal{P}(x') = \\int\\mathrm{d}x\\,\\mathcal{P}(x)\\pi(x \\to x') \\] \u3067\u3059. \u3053\u306e\u5f0f\u304c \\(\\mathcal{P}(x) \\gets P(x)\\) \u3067\u6210\u7acb\u3059\u308b\u9077\u79fb\u78ba\u7387 \\(\\pi(x \\to x')\\) \u3092\u8a2d\u8a08\u3059\u308b\u305f\u3081\u306b\u306f, \u3042\u3089\u3086\u308b\u9077\u79fb\u306b\u3064\u3044\u3066\u77db\u76fe\u304c\u7121\u3044\u3088\u3046\u306b\u3064\u3058\u3064\u307e\u3092\u5408\u308f\u305b\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059. \u3053\u308c\u3092\u6e80\u305f\u3059\u9077\u79fb\u3092\u8003\u3048\u308b\u306e\u306f\u304b\u306a\u308a\u96e3\u3057\u3044\u306e\u3067, \u4e0a\u8a18\u306e\u3064\u308a\u3042\u3044\u3092\u6e80\u305f\u3059\u305f\u3081\u306e\u5341\u5206\u6761\u4ef6\u3068\u3057\u3066\u4ee5\u4e0b\u3092\u8003\u3048\u307e\u3059. \\[ \\mathcal{P}(x')\\pi(x' \\to x) = \\mathcal{P}(x)\\pi(x \\to x'). \\] \u3053\u308c\u3092\u8a73\u7d30\u3064\u308a\u3042\u3044\u6761\u4ef6\u3068\u547c\u3073\u307e\u3059. \u4e21\u8fba\u3092 \\(x\\) \u306b\u3064\u3044\u3066\u7a4d\u5206\u3059\u308c\u3070\u5143\u306e\u5f0f\u306b\u623b\u308b\u305f\u3081, \u5341\u5206\u6761\u4ef6\u3068\u3057\u3066\u6210\u7acb\u3057\u3066\u3044\u308b\u3053\u3068\u306f\u81ea\u660e\u3067\u3059. \u4efb\u610f\u306e \\((x, x')\\) \u306b\u3064\u3044\u3066 \\[ {P}(x')\\pi(x' \\to x) = {P}(x)\\pi(x \\to x') \\] \u304c\u6210\u308a\u7acb\u3064\u3088\u3046\u306b\u72b6\u614b\u9077\u79fb\u3092\u8a2d\u8a08\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u30de\u30eb\u30b3\u30d5\u9023\u9396\u304b\u3089 \\(P(x)\\) \u306b\u5f93\u3046\u4e71\u6570\u3092\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u305d\u306e\u305f\u3081\u306e\u624b\u6cd5\u306e\u3072\u3068\u3064\u304c Metropolis-Hastings \u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3067\u3059. Metropolis-Hastings algorithm Metropolis-Hastings \u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306f\u4ee5\u4e0b\u306e\u624b\u9806\u306b\u5f93\u3063\u3066\u30de\u30eb\u30b3\u30d5\u9023\u9396\u3092\u751f\u6210\u3057\u307e\u3059. \u73fe\u5728\u306e\u72b6\u614b \\(x_t\\) \u304b\u3089\u6b21\u306e\u72b6\u614b\u306e\u5019\u88dc \\(x_p\\) \u3092\u78ba\u7387\u5206\u5e03 \\(Q(x_p; x_t)\\) \u304b\u3089\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3059\u308b. 6 \\(P(x)\\) , \\(Q(x_p; x)\\) \u304b\u3089\u4ee5\u4e0b\u306e\u91cf\u3092\u8a08\u7b97\u3059\u308b. 7 \\[ \\alpha = \\frac{P(x_p)}{P(x_t)}\\frac{Q(x_t;x_p)}{Q(x_p; x_t)} \\] \\([0,1)\\) \u306e\u4e00\u69d8\u5206\u5e03\u304b\u3089\u4e71\u6570 \\(u\\) \u3092\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3059\u308b. \\(u \\leq \\alpha\\) \u3067\u3042\u308c\u3070\u63d0\u6848\u3055\u308c\u305f\u72b6\u614b \\(x_p\\) \u3092 \\(x_{t+1}\\) \u3068\u3057\u3066\u63a1\u7528\u3059\u308b. \\(u > \\alpha\\) \u3067\u3042\u308c\u3070\u73fe\u5728\u306e\u72b6\u614b \\(x_t\\) \u3092 \\(x_{t+1}\\) \u3068\u3057\u3066\u63a1\u7528\u3059\u308b. \u3053\u306e\u3088\u3046\u306b\u72b6\u614b\u9077\u79fb\u3092\u5b9a\u7fa9\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066, \u78ba\u7387\u5206\u5e03 \\(P(x)\\) \u306b\u5f93\u3046\u4e71\u6570\u3092\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3067\u304d\u307e\u3059. \u305f\u3060\u3057, \u6b21\u306e\u72b6\u614b\u3092\u63d0\u6848\u3059\u308b\u78ba\u7387\u5206\u5e03 \\(Q(x_p; x)\\) \u306e\u9078\u629e\u306b\u3088\u3063\u3066\u306f\u51fa\u529b\u3055\u308c\u308b\u30c7\u30fc\u30bf\u5217 \\(\\{x_t\\}_{t=0{\\ldots}}\\) \u306e\u5206\u5e03\u304c \\(P(x)\\) \u3078\u3068\u53ce\u675f\u3059\u308b\u307e\u3067\u306b\u6570\u591a\u304f\u306e\u72b6\u614b\u9077\u79fb\u304c\u5fc5\u8981\u306b\u306a\u308a\u307e\u3059. \u72b6\u614b \\(x\\) \u306e\u8fd1\u508d\u3092\u63a2\u7d22\u3059\u308b\u305f\u3081\u306b\u306f, \u63d0\u6848\u5206\u5e03 \\(Q(x_p; x)\\) \u306f \\(x\\) \u3092\u4e2d\u5fc3\u3068\u3057\u305f\u591a\u6b21\u5143\u6b63\u898f\u5206\u5e03\u306e\u3088\u3046\u306a\u5206\u5e03\u304c\u591a\u304f\u63a1\u7528\u3055\u308c\u307e\u3059. \u3053\u306e\u63d0\u6848\u5206\u5e03\u306e\u30b9\u30c6\u30c3\u30d7\u5e45\u304c\u5e83\u3059\u304e\u308b\u3068\u9759\u7684\u306a\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5\u3067\u76f4\u9762\u3057\u305f\u554f\u984c\u304c\u518d\u71c3\u3057\u3066\u53ce\u675f\u304c\u9045\u304f\u306a\u308a\u307e\u3059. \u4e00\u65b9\u3067, \u30b9\u30c6\u30c3\u30d7\u5e45\u304c\u72ed\u3059\u304e\u3066\u3082\u78ba\u7387\u5206\u5e03\u3092\u8986\u3044\u5c3d\u304f\u3059\u307e\u3067\u306b\u6642\u9593\u304c\u304b\u304b\u308b\u305f\u3081\u306b\u53ce\u675f\u304c\u9045\u304f\u306a\u308a\u307e\u3059. \u63d0\u6848\u5206\u5e03\u306e\u9078\u629e\u306f\u3042\u308b\u7a0b\u5ea6\u8a66\u884c\u932f\u8aa4\u3057\u306a\u304c\u3089\u6c7a\u3081\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059. Metropolis-Hastings \u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u304c\u8a73\u7d30\u3064\u308a\u3042\u3044\u6761\u4ef6\u3092\u6e80\u305f\u3059\u3053\u3068\u306e\u78ba\u8a8d \u307e\u305a\u306f \\(\\alpha \\leq 1\\) \u306e\u30b1\u30fc\u30b9\u3092\u8003\u3048\u307e\u3059. \\(x_t \\to x_p\\) \u3078\u3068\u9077\u79fb\u3059\u308b\u78ba\u7387 \\(\\pi(x_t \\to x_p)\\) \u306f \\(Q(x_p; x_t)\\) \u304b\u3089 \\(x_p\\) \u304c\u9078\u3070\u308c, \u304b\u3064\u78ba\u7387 \\(\\alpha\\) \u3067\u63a1\u629e\u3055\u308c\u308b\u3068\u3044\u3046\u6761\u4ef6\u306b\u306a\u308a\u307e\u3059. \u4e00\u65b9, \\(x_p \\to x_t\\) \u3078\u3068\u9077\u79fb\u3059\u308b\u904e\u7a0b\u3067\u306f \\(\\alpha\\) \u306b\u76f8\u5f53\u3059\u308b\u91cf\u304c\u304b\u306a\u3089\u305a 1 \u3092\u8d85\u3048\u308b (\u9006\u6570\u306b\u306a\u308b) \u306e\u3067\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u66f8\u3051\u307e\u3059. \\[ \\left\\{~\\begin{aligned} \\pi(x_t \\to x_p) &= \\alpha Q(x_p; x_t) \\\\ \\pi(x_p \\to x_t) &= Q(x_t; x_p) \\end{aligned}\\right., \\] \u3088\u3063\u3066 \\(P(x_t)\\pi(x_t \\to x_p)\\) \u3092\u8a08\u7b97\u3059\u308b\u3068, \\[ P(x_t)\\pi(x_t \\to x_p) = P(x_t) \\frac{P(x_p)}{P(x_t)}\\frac{Q(x_t; x_p)}{Q(x_p; x_t)}Q(x_p; x_t) = P(x_p)Q(x_t; x_p) \\] \u3068\u306a\u308a\u307e\u3059. \u540c\u69d8\u306b \\(P(x_p)\\pi(x_p \\to x_t)\\) \u3092\u8a08\u7b97\u3059\u308b\u3068, \\[ P(x_p)\\pi(x_p \\to x_t) = P(x_p)Q(x_t; x_p) \\] \u3068\u306a\u308b\u305f\u3081, \u8a73\u7d30\u3064\u308a\u3042\u3044\u6761\u4ef6\u3092\u6e80\u305f\u3057\u3066\u3044\u308b\u3053\u3068\u304c\u5206\u304b\u308a\u307e\u3059. \\(\\alpha > 1\\) \u306e\u5834\u5408\u3082\u540c\u69d8\u306b\u793a\u3059\u3053\u3068\u304c\u3067\u304d\u307e\u3059. Gibbs sampling Metropolis-Hastings \u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306e\u7279\u6b8a\u306a\u4f8b\u306b Gibbs \u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3068\u3044\u3046\u624b\u6cd5\u304c\u3042\u308a\u307e\u3059. \u591a\u6b21\u5143\u306e\u78ba\u7387\u5bc6\u5ea6\u5206\u5e03 \\(P(x)\\) \u5168\u4f53\u3092\u4e00\u5ea6\u306b\u30e2\u30c7\u30eb\u5316\u3059\u308b\u3053\u3068\u306f\u96e3\u3057\u3044\u3068\u3057\u3066\u3082, \u3042\u308b 1 \u6b21\u5143\u3060\u3051, \u3042\u308b\u3044\u306f\u3042\u308b\u90e8\u5206\u7a7a\u9593\u3060\u3051\u3092\u629c\u304d\u51fa\u3057\u305f\u6761\u4ef6\u4ed8\u304d\u5206\u5e03\u3060\u3051\u306f\u53b3\u5bc6\u306b\u6c42\u3081\u3089\u308c\u308b\u3068\u3044\u3046\u5834\u5408\u304c\u3042\u308a\u307e\u3059. Gibbls \u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3067\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u3057\u3066\u30de\u30eb\u30b3\u30d5\u9023\u9396\u3092\u751f\u6210\u3057\u307e\u3059. \u73fe\u5728\u306e\u72b6\u614b \\(x_t\\) \u304b\u3089\u66f4\u65b0\u3059\u308b\u6b21\u5143 \\(i\\) \u3092\u30e9\u30f3\u30c0\u30e0\u306b\u9078\u629e\u3059\u308b. 8 \u6b21\u306e\u72b6\u614b \\(x_p\\) \u3092 \\(P(x_t^{(i)}|x_t^{({\\neg}\\,i)})\\) \u304b\u3089\u30b5\u30f3\u30d7\u30eb\u3059\u308b. \\(x^i\\) , \\(x^{\\neg i}\\) \u306f\u305d\u308c\u305e\u308c \\(x\\) \u306e \\(i\\) \u756a\u76ee\u306e\u6b21\u5143\u306e\u307f\u306e\u6210\u5206\u3068 \\(i\\) \u756a\u76ee\u306e\u6b21\u5143\u3092\u3092\u9664\u3044\u305f\u6210\u5206\u3092\u8868\u3057\u3066\u3044\u307e\u3059. \u6b21\u306e\u72b6\u614b \\(x_p\\) \u3092\u9078\u629e\u3059\u308b\u63d0\u6848\u5206\u5e03 \\(Q(x_p; x)\\) \u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u66f8\u3051\u307e\u3059. \\[ Q(x_p; x_t) = P(i)P(x_p^{i}|x_t^{{\\neg}i}), \\quad Q(x_t; x_p) = P(i)P(x_t^{i}|x_t^{{\\neg}i}) \\] \u3053\u3053\u3067 \\(P(i)\\) \u306f \\(i\\) \u756a\u76ee\u306e\u6b21\u5143\u304c\u9078\u3070\u308c\u308b\u78ba\u7387\u3067\u3059. \\(\\alpha\\) \u306e\u5024\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u66f8\u3051\u307e\u3059. \\[ \\alpha = \\frac{P(x_p)}{P(x_t)} \\frac{P(i)P(x_t^{i}|x_t^{{\\neg}i})}{P(i)P(x_p^{i}|x_t^{{\\neg}i})} \\] \u5206\u6bcd\u5206\u5b50\u306b \\(P(x_t^{\\neg{i}})\\) \u3092\u304b\u3051\u308b\u3068 \\(\\alpha = 1\\) \u3067\u3042\u308b\u3053\u3068\u304c\u78ba\u8a8d\u3067\u304d\u307e\u3059. Gibbs \u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u306f\u63d0\u6848\u5206\u5e03\u306b\u53b3\u5bc6\u306a\u6761\u4ef6\u4ed8\u304d\u78ba\u7387\u5206\u5e03\u3092\u7528\u3044\u308b\u3053\u3068\u306b\u3088\u3063\u3066, \u5fc5\u305a\u63a1\u629e\u3055\u308c\u308b\u3053\u3068\u304c\u4fdd\u8a3c\u3055\u308c\u305f Metropolis-Hastings \u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3060\u3068\u89e3\u91c8\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u307e\u305f, \u30de\u30eb\u30b3\u30d5\u9023\u9396\u306e\u521d\u671f\u306e\u30b9\u30c6\u30c3\u30d7\u306b\u3064\u3044\u3066\u306f\u521d\u671f\u72b6\u614b\u306b\u4f9d\u5b58\u3057\u3066\u3044\u308b\u6642\u671f\u304c\u3042\u308a\u307e\u3059. \u8a08\u7b97\u7d50\u679c\u304c\u521d\u671f\u72b6\u614b\u306b\u4f9d\u3089\u306a\u3044\u3053\u3068\u3092\u671f\u5f85\u3057\u3066, \u8a08\u7b97\u3092\u59cb\u3081\u3066\u304b\u3089\u3044\u304f\u3089\u304b\u306e\u5272\u5408\u3092\u6368\u3066\u53bb\u308b\u3053\u3068\u304c\u3042\u308a\u307e\u3059. \u521d\u671f\u72b6\u614b\u3092\u5fd8\u308c\u308b\u307e\u3067\u306b\u8cbb\u3084\u3059\u671f\u9593\u3092 warm up \u3068\u547c\u3093\u3060\u308a, \u521d\u671f\u306e\u30b5\u30f3\u30d7\u30eb\u3092\u6368\u3066\u53bb\u308b\u4f5c\u696d\u3092 burn-in \u3068\u547c\u3093\u3060\u308a\u3057\u307e\u3059. \u6642\u7cfb\u5217\u3063\u307d\u3055\u3092\u610f\u8b58\u3057\u3066\u306a\u3093\u3068\u306a\u304f index \u3092 \\(t\\) \u306b\u3057\u3066\u3044\u307e\u3059\u304c, \u3042\u307e\u308a\u6df1\u3044\u610f\u5473\u306f\u3042\u308a\u307e\u305b\u3093. \u21a9 \u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u3092\u30e2\u30c7\u30ea\u30f3\u30b0\u3059\u308b\u5834\u5408 (\u72b6\u614b\u7a7a\u9593\u30e2\u30c7\u30eb) \u306a\u3069\u3067\u306f \\(x_t\\) \u304b\u3089 \\(x_{t+1}\\) \u3078\u306e\u9077\u79fb\u78ba\u7387\u3092\u5b9a\u3081\u308b \u201c\u73fe\u5728\u306e\u72b6\u614b\u201d \u3068\u3057\u3066 \\(\\tilde{x}_t = (x_{t-2},x_{t-1},x_{t})^T\\) \u306e\u3088\u3046\u306b\u904e\u53bb\u306e\u60c5\u5831\u3092\u542b\u3081\u308b\u3053\u3068\u3082\u3042\u308a\u307e\u3059. \u21a9 \u4e71\u6570\u3092\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u305f\u3044\u78ba\u7387\u5206\u5e03\u95a2\u6570 \\(P(x)\\) \u3068\u306e\u6df7\u540c\u3092\u907f\u3051\u308b\u305f\u3081\u306b, \u30de\u30eb\u30b3\u30d5\u9023\u9396\u306b\u3088\u3063\u3066\u751f\u6210\u3055\u308c\u308b\u30c7\u30fc\u30bf\u5217\u306b\u671f\u5f85\u3055\u308c\u308b\u78ba\u7387\u5206\u5e03\u95a2\u6570\u3092 \\(\\mathcal{P}(x)\\) \u3068\u30d5\u30a9\u30f3\u30c8\u3092\u5c11\u3057\u5909\u3048\u3066\u8a18\u8ff0\u3057\u3066\u3044\u307e\u3059. \u21a9 \u9023\u7d9a\u5206\u5e03\u3068\u3057\u3066\u66f8\u3044\u3066\u3044\u307e\u3059\u304c \\(x\\) \u304c\u96e2\u6563\u7684\u306a\u5834\u5408\u306f\u548c\u306b\u7f6e\u304d\u63db\u3048\u3066\u304f\u3060\u3055\u3044. \u21a9 \u30c1\u30a7\u30c3\u30ab\u30fc\u30dc\u30fc\u30c9\u306e\u4e0a\u3092 1 \u30de\u30b9\u305a\u3064\u79fb\u52d5\u3059\u308b\u30b3\u30de\u3092\u8003\u3048\u3066\u307f\u307e\u3059. \u30b3\u30de\u306e\u5206\u5e03\u306f\u3053\u306e\u5834\u5408 \\(t\\) \u304c\u5947\u6570\u306e\u3068\u304d\u3068\u5076\u6570\u306e\u3068\u304d\u3067\u305d\u308c\u305e\u308c\u5b9a\u5e38\u5206\u5e03\u306b\u53ce\u675f\u3057\u307e\u3059\u304c, \u5168\u4f53\u3067\u898b\u305f\u3068\u304d\u306f \\(\\mathcal{P}_\\mathrm{odd}(x)\\) , \\(\\mathcal{P}_\\mathrm{even}(x)\\) \u3067\u632f\u52d5\u3057\u3066\u3057\u307e\u3044\u53ce\u675f\u3057\u307e\u305b\u3093. \u975e\u5468\u671f\u6027\u306f\u3053\u3046\u3057\u305f\u30b1\u30fc\u30b9\u3092\u6392\u9664\u3059\u308b\u305f\u3081\u306b\u8981\u6c42\u3055\u308c\u307e\u3059. \u21a9 \\(x\\) \u306e\u8fd1\u508d\u3092\u30b5\u30f3\u30d7\u30eb\u3057\u305f\u3044\u306e\u3067 \\(x\\) \u3092\u30d1\u30e9\u30e1\u30bf\u3068\u3057\u3066\u6301\u3061\u307e\u3059. \u78ba\u7387\u5206\u5e03\u3067\u306f\u3042\u308a\u307e\u3059\u304c\u7269\u7406\u7684\u306b\u610f\u5473\u304c\u3042\u308b\u308f\u3051\u3067\u306f\u306a\u3044 (\u3042\u308b\u3068\u306f\u9650\u3089\u306a\u3044) \u306e\u3067\u6587\u5b57\u306b \\(Q\\) \u3092\u4f7f\u3044\u307e\u3057\u305f. \u21a9 \\(\\alpha\\) \u306e\u8a08\u7b97\u3067\u306f\u6bd4\u3092\u3068\u308b\u306e\u3067 \\(P(x)\\) \u306e\u898f\u683c\u5316\u5b9a\u6570\u306f\u672a\u77e5\u306e\u307e\u307e\u3067\u554f\u984c\u3042\u308a\u307e\u305b\u3093. \u21a9 \u5fc5\u305a\u3057\u3082\u30e9\u30f3\u30c0\u30e0\u3067\u3042\u308b\u5fc5\u8981\u306f\u306a\u304f\u9806\u756a\u306b\u9078\u3093\u3067\u3082\u554f\u984c\u3042\u308a\u307e\u305b\u3093. \u21a9","title":"\u52d5\u7684\u306a\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5"},{"location":"mcmc/markov_chain/#_1","text":"\u524d\u9805 \u3067\u306f\u554f\u984c\u306e\u6b21\u5143\u304c\u5927\u304d\u304f\u306a\u308b\u3068, \u9759\u7684\u306a\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5\u3067\u306f\u30bf\u30fc\u30b2\u30c3\u30c8\u3068\u306a\u308b\u5206\u5e03\u306b\u30d2\u30c3\u30c8\u3059\u308b\u78ba\u7387\u304c\u8457\u3057\u304f\u4e0b\u304c\u308b\u305f\u3081, \u52b9\u7387\u3088\u304f\u8a08\u7b97\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u306a\u3044\u3068\u3044\u3046\u554f\u984c\u306b\u3064\u3044\u3066\u89e6\u308c\u307e\u3057\u305f. \u3053\u308c\u306f\u30bf\u30fc\u30b2\u30c3\u30c8\u3068\u306a\u308b\u78ba\u7387\u5206\u5e03\u3092\u63d0\u6848\u5206\u5e03\u3067\u3046\u307e\u304f\u8fd1\u4f3c\u3067\u304d\u3066\u3044\u306a\u3044\u3053\u3068\u306b\u8d77\u56e0\u3057\u307e\u3059. \u305d\u3053\u3067, \u78ba\u7387\u5206\u5e03\u5168\u4f53\u3092\u3046\u307e\u304f\u8fd1\u4f3c\u3059\u308b\u3053\u3068\u3092\u3042\u304d\u3089\u3081\u3066, \u3042\u308b\u30c7\u30fc\u30bf\u306e\u8fd1\u508d\u3067\u306e\u307f\u3046\u307e\u304f\u8fd1\u4f3c\u3059\u308b\u3053\u3068\u3092\u8003\u3048\u307e\u3059. \u3054\u304f\u8fd1\u508d\u3067\u3057\u304b\u3064\u3058\u3064\u307e\u304c\u5408\u3063\u3066\u3044\u306a\u304f\u3066\u3082, \u305d\u306e\u60c5\u5831\u3092\u9069\u5207\u306b\u3064\u306a\u304e\u5408\u308f\u305b\u308b\u3053\u3068\u304c\u3067\u304d\u308c\u3070, \u78ba\u7387\u5206\u5e03\u5168\u4f53\u3092\u3046\u307e\u304f\u8868\u73fe\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u306f\u305a\u3067\u3059. \u3053\u3053\u3067\u306f\u300c\u30de\u30eb\u30b3\u30d5\u9023\u9396\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5\u300d\u306b\u3064\u3044\u3066\u8aac\u660e\u3057\u307e\u3059. \u30c7\u30fc\u30bf\u3092\u52b9\u7387\u3088\u304f\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3059\u308b\u305f\u3081\u306b, \u3042\u308b\u30c7\u30fc\u30bf\u306e\u8fd1\u508d\u3067\u306e\u307f\u6b21\u306e\u30b5\u30f3\u30d7\u30eb\u3092\u63a2\u3059\u3068\u3044\u3046\u6226\u7565\u3092\u3068\u308a\u307e\u3059. \u4e00\u56de\u306e\u64cd\u4f5c\u3067\u306f\u78ba\u7387\u5206\u5e03\u95a2\u6570\u306e\u3054\u304f\u4e00\u90e8\u3057\u304b\u63a2\u7d22\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u305b\u3093\u304c, \u3053\u306e\u64cd\u4f5c\u3092\u591a\u6570\u56de\u7e70\u308a\u8fd4\u3059\u3053\u3068\u306b\u3088\u3063\u3066\u78ba\u7387\u5206\u5e03\u95a2\u6570\u5168\u4f53\u306e\u5f62\u72b6\u3092\u3092\u6d6e\u304b\u3073\u4e0a\u304c\u3089\u305b\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059.","title":"\u52d5\u7684\u306a\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5"},{"location":"mcmc/markov_chain/#_2","text":"\u30de\u30eb\u30b3\u30d5\u9023\u9396\u3068\u306f\u30de\u30eb\u30b3\u30d5\u904e\u7a0b\u306b\u3088\u3063\u3066\u751f\u6210\u3055\u308c\u305f\u72b6\u614b (\u30c7\u30fc\u30bf) \u306e\u5217 \\(\\{x_t\\}_{t=0{\\ldots}}\\) \u3092\u8868\u3057\u307e\u3059. 1 \u30de\u30eb\u30b3\u30d5\u904e\u7a0b\u3068\u306f \u201c\u73fe\u5728\u306e\u72b6\u614b \\(x\\) \u304b\u3089\u6b21\u306e\u72b6\u614b \\(x'\\) \u3078\u9077\u79fb\u3059\u308b\u78ba\u7387 \\(\\pi(x \\to x')\\) \u304c\u73fe\u5728\u306e\u72b6\u614b\u306b\u3088\u3063\u3066\u6c7a\u307e\u308b\u201d \u3068\u3044\u3046\u904e\u7a0b\u3092\u8868\u3057\u3066\u3044\u307e\u3059. 2 \u3042\u308b\u6761\u4ef6\u306e\u3082\u3068\u3067\u306f\u5341\u5206\u306b\u9577\u3044\u6642\u9593\u9077\u79fb\u3092\u7e70\u308a\u8fd4\u3057\u305f\u3068\u304d\u306e \\(\\{x_t\\}_{t=0{\\ldots}}\\) \u306e\u5206\u5e03\u304c (\u521d\u671f\u5024 \\(x_0\\) \u306b\u4f9d\u3089\u305a) \u3042\u308b\u5206\u5e03 \\(\\mathcal{P}(x)\\) \u306b\u53ce\u675f\u3059\u308b\u3053\u3068\u304c\u671f\u5f85\u3055\u308c\u307e\u3059. 3 \u3053\u306e\u5206\u5e03\u306e\u3053\u3068\u3092\u5b9a\u5e38\u5206\u5e03\u3068\u547c\u3073\u307e\u3059. \u3042\u308b\u6642\u523b \\(t\\) \u307e\u3067\u30de\u30eb\u30b3\u30d5\u9023\u9396\u3092\u7e70\u308a\u8fd4\u3057\u305f\u3068\u304d\u306b\u671f\u5f85\u3055\u308c\u308b \\(x\\) \u306e\u78ba\u7387\u5206\u5e03\u95a2\u6570\u3092 \\(\\mathcal{P}_t(x)\\) \u3068\u3057\u307e\u3059. \u3053\u3053\u304b\u3089\u6642\u523b \\(t+1\\) \u306b\u304a\u3051\u308b\u5206\u5e03 \\(\\mathcal{P}_{t+1}(x)\\) \u3092\u8a08\u7b97\u3059\u308b\u3068\u4ee5\u4e0b\u306e\u5f0f\u306b\u306a\u308a\u307e\u3059. 4 \\[ \\mathcal{P}_{t+1}(x') = \\int\\mathrm{d}x\\,\\mathcal{P}_{t}(x)\\pi(x \\to x'). \\] \\(t \\to \\infty\\) \u306e\u3068\u304d\u306b \\(\\mathcal{P}_{t}(x)\\) \u304c\u5b9a\u5e38\u5206\u5e03\u306b\u53ce\u675f\u3059\u308b\u306e\u3067\u3042\u308c\u3070 \\(\\mathcal{P}(x)\\) \u306f, \\[ \\mathcal{P}(x') = \\int\\mathrm{d}x\\,\\mathcal{P}(x)\\pi(x \\to x'). \\] \u3092\u6e80\u305f\u3057\u3066\u3044\u308b\u3053\u3068\u304c\u5fc5\u8981\u306b\u306a\u308a\u307e\u3059. \u307e\u305f, \u3053\u3046\u3057\u305f\u5b9a\u5e38\u5206\u5e03\u304c\u5b58\u5728\u3059\u308b\u305f\u3081\u306b\u306f, \u72b6\u614b\u9077\u79fb\u306e\u30eb\u30fc\u30eb\u306b\u3082\u5236\u7d04\u304c\u3042\u308a\u307e\u3059. \u307e\u305a, \u5b58\u5728\u3059\u308b\u3069\u306e\u72b6\u614b\u30da\u30a2 \\((x, x')\\) \u3082\u6709\u9650\u56de\u306e\u64cd\u4f5c\u3067\u9077\u79fb\u3067\u304d\u308b (\u72b6\u614b\u304c\u5206\u65ad\u3055\u308c\u3066\u3044\u306a\u3044) \u3053\u3068\u304c\u5fc5\u8981\u3067\u3059. \u52a0\u3048\u3066, \u72b6\u614b\u306e\u9077\u79fb\u306b\u306f\u975e\u5468\u671f\u6027\u3082\u5fc5\u8981\u3068\u3055\u308c\u307e\u3059\u304c, \u3053\u3053\u3067\u306f\u8a73\u7d30\u306b\u3064\u3044\u3066\u306f\u7701\u7565\u3057\u307e\u3059. 5 \u5341\u5206\u306b\u9577\u3044\u6642\u9593\u30de\u30eb\u30b3\u30d5\u9023\u9396\u306e\u30b9\u30c6\u30c3\u30d7\u3092\u7e70\u308a\u8fd4\u3059\u3053\u3068\u3067, \u30de\u30eb\u30b3\u30d5\u9023\u9396\u5217 \\(\\{x_t\\}_{t=0{\\ldots}}\\) \u3092\u5b9a\u5e38\u5206\u5e03 \\(\\mathcal{P}(x)\\) \u304b\u3089\u30b5\u30f3\u30d7\u30eb\u3057\u305f\u4e71\u6570\u3068\u307f\u306a\u3059\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u3053\u3053\u3067\u72b6\u614b\u9077\u79fb\u306e\u30eb\u30fc\u30eb\u3092\u3046\u307e\u304f\u8a2d\u5b9a\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066, \u53ce\u675f\u5148\u306e\u5b9a\u5e38\u5206\u5e03\u3092\u30b3\u30f3\u30c8\u30ed\u30fc\u30eb\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u30bf\u30fc\u30b2\u30c3\u30c8\u3068\u306a\u308b\u78ba\u7387\u5206\u5e03\u95a2\u6570 \\(P(x)\\) \u306b\u53ce\u675f\u3059\u308b\u3088\u3046\u306a\u30de\u30eb\u30b3\u30d5\u9023\u9396\u3092\u8a2d\u8a08\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308c\u3070, \u4efb\u610f\u306e\u78ba\u7387\u5206\u5e03\u95a2\u6570\u304b\u3089\u306e\u4e71\u6570\u3092\u52b9\u7387\u3088\u304f\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u305d\u3046\u3067\u3059. \u5206\u5e03\u306e\u53ce\u675f\u6027\u306b\u3064\u3044\u3066\u306e\u30b3\u30e1\u30f3\u30c8 \u3053\u3053\u3067\u306f\u64cd\u4f5c\u3092\u7e70\u308a\u8fd4\u3059\u3053\u3068\u306b\u3088\u3063\u3066\u671f\u5f85\u3055\u308c\u308b\u5206\u5e03\u304c\u3069\u306e\u3088\u3046\u306b\u5909\u308f\u3063\u3066\u3044\u304f\u304b\u3092\u8003\u3048\u308b\u3053\u3068\u3067, \u5206\u5e03\u306e\u53ce\u675f\u6027\u306b\u3064\u3044\u3066\u8aac\u660e\u3057\u307e\u3059. \\(t=0\\) \u306e\u3068\u304d\u306b\u671f\u5f85\u3055\u308c\u308b \\(x\\) \u306e\u5206\u5e03\u3092 \\(\\mathcal{P}_0{x}\\) \u3068\u3057\u307e\u3059. \u3053\u308c\u306f\u521d\u671f\u72b6\u614b\u3068\u3057\u3066\u5b9a\u7fa9\u3057\u3066\u3044\u308b\u3060\u3051\u3067\u4efb\u610f\u306e\u5206\u5e03\u3067\u3059. 1 \u30b9\u30c6\u30c3\u30d7\u5f8c\u306e\u5206\u5e03\u3092\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u66f8\u304f\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \\[ \\mathcal{P}_1(x) = \\int\\mathrm{d}x'\\,\\mathcal{P}_0(x')\\pi(x' \\to x) = c\\mathcal{P}(x) + (1-c)R_0(x). \\] \u305f\u3060\u3057 \\(0 < c < 1\\) \u3067 \\(\\mathcal{P}_0(x)\\) \u306b\u4f9d\u3089\u306a\u3044\u5b9a\u6570\u306b\u306a\u308a\u307e\u3059 (\u3053\u306e\u5f62\u3067\u66f8\u3051\u308b\u3053\u3068\u306e\u8a3c\u660e\u306f\u7701\u7565\u3057\u307e\u3059). \\(\\pi(x \\to x')\\) \u306e\u64cd\u4f5c\u3092\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066 \\(\\mathcal{P}_1(x)\\) \u304b\u3089 \\(c\\) \u500d\u3060\u3051 \\(\\mathcal{P}(x)\\) \u3092\u524a\u308a\u51fa\u3059\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u540c\u3058\u72b6\u614b\u9077\u79fb\u3092\u5b9f\u884c\u3059\u308b\u3068, \\[ \\begin{aligned} \\mathcal{P}_2(x) &= c\\mathcal{P}(x) + (1-c)(c\\mathcal{P}(x) + (1-c)R_1(x)) \\\\ &= \\left(1 - (1-c)^2\\right) \\mathcal{P}(x) + (1-c)^2 R_1(x) \\end{aligned} \\] \u3068\u5909\u63db\u3067\u304d\u307e\u3059. \u305f\u3060\u3057 \\(R_0(x)\\) \u3092\u521d\u671f\u5206\u5e03\u3068\u3057\u3066 \\(c\\mathcal{P}(x)\\) \u3092\u524a\u308a\u3060\u3059\u64cd\u4f5c\u3092\u518d\u3073\u304a\u3053\u3063\u3066\u3044\u307e\u3059. \u72b6\u614b\u9077\u79fb\u3092 \\(m\\) \u56de\u7e70\u308a\u8fd4\u3059\u3053\u3068\u306b\u3088\u3063\u3066\u4ee5\u4e0b\u306e\u5f0f\u3092\u5f97\u307e\u3059. \\[ \\mathcal{P}_m(x) = \\left(1 - (1-c)^m\\right) \\mathcal{P}(x) + (1-c)^m R_{m-1}(x). \\] \\(m \\to \\infty\\) \u306e\u6975\u9650\u3067\u4efb\u610f\u306e\u5206\u5e03 \\(\\mathcal{P}_0(x)\\) \u304b\u3089 \\(\\mathcal{P}(x)\\) \u306b\u53ce\u675f\u3059\u308b\u3053\u3068\u304c\u793a\u305b\u307e\u3057\u305f.","title":"\u30de\u30eb\u30b3\u30d5\u9023\u9396\u3068\u306f"},{"location":"mcmc/markov_chain/#_3","text":"\u3053\u3053\u307e\u3067, \u30de\u30eb\u30b3\u30d5\u9023\u9396\u306b\u3088\u3063\u3066\u5b9a\u5e38\u5206\u5e03 \\(P(x)\\) \u306b\u5f93\u3046\u4e71\u6570\u3092\u751f\u6210\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u3053\u3068\u3092\u78ba\u8a8d\u3057\u307e\u3057\u305f. \u6b21\u306b\u5b9a\u5e38\u5206\u5e03 \\(\\mathcal{P}(x)\\) \u3092\u4efb\u610f\u306e\u78ba\u7387\u5206\u5e03\u95a2\u6570 \\(P(x)\\) \u306b\u3059\u308b\u305f\u3081\u306e\u65b9\u6cd5\u306b\u3064\u3044\u3066\u7d39\u4ecb\u3057\u307e\u3059. \u5b9a\u5e38\u5206\u5e03\u304c\u6e80\u305f\u3059\u3079\u304d\u5f0f\u306f \\[ \\mathcal{P}(x') = \\int\\mathrm{d}x\\,\\mathcal{P}(x)\\pi(x \\to x') \\] \u3067\u3059. \u3053\u306e\u5f0f\u304c \\(\\mathcal{P}(x) \\gets P(x)\\) \u3067\u6210\u7acb\u3059\u308b\u9077\u79fb\u78ba\u7387 \\(\\pi(x \\to x')\\) \u3092\u8a2d\u8a08\u3059\u308b\u305f\u3081\u306b\u306f, \u3042\u3089\u3086\u308b\u9077\u79fb\u306b\u3064\u3044\u3066\u77db\u76fe\u304c\u7121\u3044\u3088\u3046\u306b\u3064\u3058\u3064\u307e\u3092\u5408\u308f\u305b\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059. \u3053\u308c\u3092\u6e80\u305f\u3059\u9077\u79fb\u3092\u8003\u3048\u308b\u306e\u306f\u304b\u306a\u308a\u96e3\u3057\u3044\u306e\u3067, \u4e0a\u8a18\u306e\u3064\u308a\u3042\u3044\u3092\u6e80\u305f\u3059\u305f\u3081\u306e\u5341\u5206\u6761\u4ef6\u3068\u3057\u3066\u4ee5\u4e0b\u3092\u8003\u3048\u307e\u3059. \\[ \\mathcal{P}(x')\\pi(x' \\to x) = \\mathcal{P}(x)\\pi(x \\to x'). \\] \u3053\u308c\u3092\u8a73\u7d30\u3064\u308a\u3042\u3044\u6761\u4ef6\u3068\u547c\u3073\u307e\u3059. \u4e21\u8fba\u3092 \\(x\\) \u306b\u3064\u3044\u3066\u7a4d\u5206\u3059\u308c\u3070\u5143\u306e\u5f0f\u306b\u623b\u308b\u305f\u3081, \u5341\u5206\u6761\u4ef6\u3068\u3057\u3066\u6210\u7acb\u3057\u3066\u3044\u308b\u3053\u3068\u306f\u81ea\u660e\u3067\u3059. \u4efb\u610f\u306e \\((x, x')\\) \u306b\u3064\u3044\u3066 \\[ {P}(x')\\pi(x' \\to x) = {P}(x)\\pi(x \\to x') \\] \u304c\u6210\u308a\u7acb\u3064\u3088\u3046\u306b\u72b6\u614b\u9077\u79fb\u3092\u8a2d\u8a08\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u30de\u30eb\u30b3\u30d5\u9023\u9396\u304b\u3089 \\(P(x)\\) \u306b\u5f93\u3046\u4e71\u6570\u3092\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u305d\u306e\u305f\u3081\u306e\u624b\u6cd5\u306e\u3072\u3068\u3064\u304c Metropolis-Hastings \u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3067\u3059.","title":"\u30de\u30eb\u30b3\u30d5\u9023\u9396\u306b\u3088\u308b\u30b5\u30f3\u30d7\u30eb\u751f\u6210"},{"location":"mcmc/markov_chain/#metropolis-hastings-algorithm","text":"Metropolis-Hastings \u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306f\u4ee5\u4e0b\u306e\u624b\u9806\u306b\u5f93\u3063\u3066\u30de\u30eb\u30b3\u30d5\u9023\u9396\u3092\u751f\u6210\u3057\u307e\u3059. \u73fe\u5728\u306e\u72b6\u614b \\(x_t\\) \u304b\u3089\u6b21\u306e\u72b6\u614b\u306e\u5019\u88dc \\(x_p\\) \u3092\u78ba\u7387\u5206\u5e03 \\(Q(x_p; x_t)\\) \u304b\u3089\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3059\u308b. 6 \\(P(x)\\) , \\(Q(x_p; x)\\) \u304b\u3089\u4ee5\u4e0b\u306e\u91cf\u3092\u8a08\u7b97\u3059\u308b. 7 \\[ \\alpha = \\frac{P(x_p)}{P(x_t)}\\frac{Q(x_t;x_p)}{Q(x_p; x_t)} \\] \\([0,1)\\) \u306e\u4e00\u69d8\u5206\u5e03\u304b\u3089\u4e71\u6570 \\(u\\) \u3092\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3059\u308b. \\(u \\leq \\alpha\\) \u3067\u3042\u308c\u3070\u63d0\u6848\u3055\u308c\u305f\u72b6\u614b \\(x_p\\) \u3092 \\(x_{t+1}\\) \u3068\u3057\u3066\u63a1\u7528\u3059\u308b. \\(u > \\alpha\\) \u3067\u3042\u308c\u3070\u73fe\u5728\u306e\u72b6\u614b \\(x_t\\) \u3092 \\(x_{t+1}\\) \u3068\u3057\u3066\u63a1\u7528\u3059\u308b. \u3053\u306e\u3088\u3046\u306b\u72b6\u614b\u9077\u79fb\u3092\u5b9a\u7fa9\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066, \u78ba\u7387\u5206\u5e03 \\(P(x)\\) \u306b\u5f93\u3046\u4e71\u6570\u3092\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3067\u304d\u307e\u3059. \u305f\u3060\u3057, \u6b21\u306e\u72b6\u614b\u3092\u63d0\u6848\u3059\u308b\u78ba\u7387\u5206\u5e03 \\(Q(x_p; x)\\) \u306e\u9078\u629e\u306b\u3088\u3063\u3066\u306f\u51fa\u529b\u3055\u308c\u308b\u30c7\u30fc\u30bf\u5217 \\(\\{x_t\\}_{t=0{\\ldots}}\\) \u306e\u5206\u5e03\u304c \\(P(x)\\) \u3078\u3068\u53ce\u675f\u3059\u308b\u307e\u3067\u306b\u6570\u591a\u304f\u306e\u72b6\u614b\u9077\u79fb\u304c\u5fc5\u8981\u306b\u306a\u308a\u307e\u3059. \u72b6\u614b \\(x\\) \u306e\u8fd1\u508d\u3092\u63a2\u7d22\u3059\u308b\u305f\u3081\u306b\u306f, \u63d0\u6848\u5206\u5e03 \\(Q(x_p; x)\\) \u306f \\(x\\) \u3092\u4e2d\u5fc3\u3068\u3057\u305f\u591a\u6b21\u5143\u6b63\u898f\u5206\u5e03\u306e\u3088\u3046\u306a\u5206\u5e03\u304c\u591a\u304f\u63a1\u7528\u3055\u308c\u307e\u3059. \u3053\u306e\u63d0\u6848\u5206\u5e03\u306e\u30b9\u30c6\u30c3\u30d7\u5e45\u304c\u5e83\u3059\u304e\u308b\u3068\u9759\u7684\u306a\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5\u3067\u76f4\u9762\u3057\u305f\u554f\u984c\u304c\u518d\u71c3\u3057\u3066\u53ce\u675f\u304c\u9045\u304f\u306a\u308a\u307e\u3059. \u4e00\u65b9\u3067, \u30b9\u30c6\u30c3\u30d7\u5e45\u304c\u72ed\u3059\u304e\u3066\u3082\u78ba\u7387\u5206\u5e03\u3092\u8986\u3044\u5c3d\u304f\u3059\u307e\u3067\u306b\u6642\u9593\u304c\u304b\u304b\u308b\u305f\u3081\u306b\u53ce\u675f\u304c\u9045\u304f\u306a\u308a\u307e\u3059. \u63d0\u6848\u5206\u5e03\u306e\u9078\u629e\u306f\u3042\u308b\u7a0b\u5ea6\u8a66\u884c\u932f\u8aa4\u3057\u306a\u304c\u3089\u6c7a\u3081\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059. Metropolis-Hastings \u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u304c\u8a73\u7d30\u3064\u308a\u3042\u3044\u6761\u4ef6\u3092\u6e80\u305f\u3059\u3053\u3068\u306e\u78ba\u8a8d \u307e\u305a\u306f \\(\\alpha \\leq 1\\) \u306e\u30b1\u30fc\u30b9\u3092\u8003\u3048\u307e\u3059. \\(x_t \\to x_p\\) \u3078\u3068\u9077\u79fb\u3059\u308b\u78ba\u7387 \\(\\pi(x_t \\to x_p)\\) \u306f \\(Q(x_p; x_t)\\) \u304b\u3089 \\(x_p\\) \u304c\u9078\u3070\u308c, \u304b\u3064\u78ba\u7387 \\(\\alpha\\) \u3067\u63a1\u629e\u3055\u308c\u308b\u3068\u3044\u3046\u6761\u4ef6\u306b\u306a\u308a\u307e\u3059. \u4e00\u65b9, \\(x_p \\to x_t\\) \u3078\u3068\u9077\u79fb\u3059\u308b\u904e\u7a0b\u3067\u306f \\(\\alpha\\) \u306b\u76f8\u5f53\u3059\u308b\u91cf\u304c\u304b\u306a\u3089\u305a 1 \u3092\u8d85\u3048\u308b (\u9006\u6570\u306b\u306a\u308b) \u306e\u3067\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u66f8\u3051\u307e\u3059. \\[ \\left\\{~\\begin{aligned} \\pi(x_t \\to x_p) &= \\alpha Q(x_p; x_t) \\\\ \\pi(x_p \\to x_t) &= Q(x_t; x_p) \\end{aligned}\\right., \\] \u3088\u3063\u3066 \\(P(x_t)\\pi(x_t \\to x_p)\\) \u3092\u8a08\u7b97\u3059\u308b\u3068, \\[ P(x_t)\\pi(x_t \\to x_p) = P(x_t) \\frac{P(x_p)}{P(x_t)}\\frac{Q(x_t; x_p)}{Q(x_p; x_t)}Q(x_p; x_t) = P(x_p)Q(x_t; x_p) \\] \u3068\u306a\u308a\u307e\u3059. \u540c\u69d8\u306b \\(P(x_p)\\pi(x_p \\to x_t)\\) \u3092\u8a08\u7b97\u3059\u308b\u3068, \\[ P(x_p)\\pi(x_p \\to x_t) = P(x_p)Q(x_t; x_p) \\] \u3068\u306a\u308b\u305f\u3081, \u8a73\u7d30\u3064\u308a\u3042\u3044\u6761\u4ef6\u3092\u6e80\u305f\u3057\u3066\u3044\u308b\u3053\u3068\u304c\u5206\u304b\u308a\u307e\u3059. \\(\\alpha > 1\\) \u306e\u5834\u5408\u3082\u540c\u69d8\u306b\u793a\u3059\u3053\u3068\u304c\u3067\u304d\u307e\u3059.","title":"Metropolis-Hastings algorithm"},{"location":"mcmc/markov_chain/#gibbs-sampling","text":"Metropolis-Hastings \u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306e\u7279\u6b8a\u306a\u4f8b\u306b Gibbs \u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3068\u3044\u3046\u624b\u6cd5\u304c\u3042\u308a\u307e\u3059. \u591a\u6b21\u5143\u306e\u78ba\u7387\u5bc6\u5ea6\u5206\u5e03 \\(P(x)\\) \u5168\u4f53\u3092\u4e00\u5ea6\u306b\u30e2\u30c7\u30eb\u5316\u3059\u308b\u3053\u3068\u306f\u96e3\u3057\u3044\u3068\u3057\u3066\u3082, \u3042\u308b 1 \u6b21\u5143\u3060\u3051, \u3042\u308b\u3044\u306f\u3042\u308b\u90e8\u5206\u7a7a\u9593\u3060\u3051\u3092\u629c\u304d\u51fa\u3057\u305f\u6761\u4ef6\u4ed8\u304d\u5206\u5e03\u3060\u3051\u306f\u53b3\u5bc6\u306b\u6c42\u3081\u3089\u308c\u308b\u3068\u3044\u3046\u5834\u5408\u304c\u3042\u308a\u307e\u3059. Gibbls \u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3067\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u3057\u3066\u30de\u30eb\u30b3\u30d5\u9023\u9396\u3092\u751f\u6210\u3057\u307e\u3059. \u73fe\u5728\u306e\u72b6\u614b \\(x_t\\) \u304b\u3089\u66f4\u65b0\u3059\u308b\u6b21\u5143 \\(i\\) \u3092\u30e9\u30f3\u30c0\u30e0\u306b\u9078\u629e\u3059\u308b. 8 \u6b21\u306e\u72b6\u614b \\(x_p\\) \u3092 \\(P(x_t^{(i)}|x_t^{({\\neg}\\,i)})\\) \u304b\u3089\u30b5\u30f3\u30d7\u30eb\u3059\u308b. \\(x^i\\) , \\(x^{\\neg i}\\) \u306f\u305d\u308c\u305e\u308c \\(x\\) \u306e \\(i\\) \u756a\u76ee\u306e\u6b21\u5143\u306e\u307f\u306e\u6210\u5206\u3068 \\(i\\) \u756a\u76ee\u306e\u6b21\u5143\u3092\u3092\u9664\u3044\u305f\u6210\u5206\u3092\u8868\u3057\u3066\u3044\u307e\u3059. \u6b21\u306e\u72b6\u614b \\(x_p\\) \u3092\u9078\u629e\u3059\u308b\u63d0\u6848\u5206\u5e03 \\(Q(x_p; x)\\) \u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u66f8\u3051\u307e\u3059. \\[ Q(x_p; x_t) = P(i)P(x_p^{i}|x_t^{{\\neg}i}), \\quad Q(x_t; x_p) = P(i)P(x_t^{i}|x_t^{{\\neg}i}) \\] \u3053\u3053\u3067 \\(P(i)\\) \u306f \\(i\\) \u756a\u76ee\u306e\u6b21\u5143\u304c\u9078\u3070\u308c\u308b\u78ba\u7387\u3067\u3059. \\(\\alpha\\) \u306e\u5024\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u66f8\u3051\u307e\u3059. \\[ \\alpha = \\frac{P(x_p)}{P(x_t)} \\frac{P(i)P(x_t^{i}|x_t^{{\\neg}i})}{P(i)P(x_p^{i}|x_t^{{\\neg}i})} \\] \u5206\u6bcd\u5206\u5b50\u306b \\(P(x_t^{\\neg{i}})\\) \u3092\u304b\u3051\u308b\u3068 \\(\\alpha = 1\\) \u3067\u3042\u308b\u3053\u3068\u304c\u78ba\u8a8d\u3067\u304d\u307e\u3059. Gibbs \u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u306f\u63d0\u6848\u5206\u5e03\u306b\u53b3\u5bc6\u306a\u6761\u4ef6\u4ed8\u304d\u78ba\u7387\u5206\u5e03\u3092\u7528\u3044\u308b\u3053\u3068\u306b\u3088\u3063\u3066, \u5fc5\u305a\u63a1\u629e\u3055\u308c\u308b\u3053\u3068\u304c\u4fdd\u8a3c\u3055\u308c\u305f Metropolis-Hastings \u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3060\u3068\u89e3\u91c8\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u307e\u305f, \u30de\u30eb\u30b3\u30d5\u9023\u9396\u306e\u521d\u671f\u306e\u30b9\u30c6\u30c3\u30d7\u306b\u3064\u3044\u3066\u306f\u521d\u671f\u72b6\u614b\u306b\u4f9d\u5b58\u3057\u3066\u3044\u308b\u6642\u671f\u304c\u3042\u308a\u307e\u3059. \u8a08\u7b97\u7d50\u679c\u304c\u521d\u671f\u72b6\u614b\u306b\u4f9d\u3089\u306a\u3044\u3053\u3068\u3092\u671f\u5f85\u3057\u3066, \u8a08\u7b97\u3092\u59cb\u3081\u3066\u304b\u3089\u3044\u304f\u3089\u304b\u306e\u5272\u5408\u3092\u6368\u3066\u53bb\u308b\u3053\u3068\u304c\u3042\u308a\u307e\u3059. \u521d\u671f\u72b6\u614b\u3092\u5fd8\u308c\u308b\u307e\u3067\u306b\u8cbb\u3084\u3059\u671f\u9593\u3092 warm up \u3068\u547c\u3093\u3060\u308a, \u521d\u671f\u306e\u30b5\u30f3\u30d7\u30eb\u3092\u6368\u3066\u53bb\u308b\u4f5c\u696d\u3092 burn-in \u3068\u547c\u3093\u3060\u308a\u3057\u307e\u3059. \u6642\u7cfb\u5217\u3063\u307d\u3055\u3092\u610f\u8b58\u3057\u3066\u306a\u3093\u3068\u306a\u304f index \u3092 \\(t\\) \u306b\u3057\u3066\u3044\u307e\u3059\u304c, \u3042\u307e\u308a\u6df1\u3044\u610f\u5473\u306f\u3042\u308a\u307e\u305b\u3093. \u21a9 \u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u3092\u30e2\u30c7\u30ea\u30f3\u30b0\u3059\u308b\u5834\u5408 (\u72b6\u614b\u7a7a\u9593\u30e2\u30c7\u30eb) \u306a\u3069\u3067\u306f \\(x_t\\) \u304b\u3089 \\(x_{t+1}\\) \u3078\u306e\u9077\u79fb\u78ba\u7387\u3092\u5b9a\u3081\u308b \u201c\u73fe\u5728\u306e\u72b6\u614b\u201d \u3068\u3057\u3066 \\(\\tilde{x}_t = (x_{t-2},x_{t-1},x_{t})^T\\) \u306e\u3088\u3046\u306b\u904e\u53bb\u306e\u60c5\u5831\u3092\u542b\u3081\u308b\u3053\u3068\u3082\u3042\u308a\u307e\u3059. \u21a9 \u4e71\u6570\u3092\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u305f\u3044\u78ba\u7387\u5206\u5e03\u95a2\u6570 \\(P(x)\\) \u3068\u306e\u6df7\u540c\u3092\u907f\u3051\u308b\u305f\u3081\u306b, \u30de\u30eb\u30b3\u30d5\u9023\u9396\u306b\u3088\u3063\u3066\u751f\u6210\u3055\u308c\u308b\u30c7\u30fc\u30bf\u5217\u306b\u671f\u5f85\u3055\u308c\u308b\u78ba\u7387\u5206\u5e03\u95a2\u6570\u3092 \\(\\mathcal{P}(x)\\) \u3068\u30d5\u30a9\u30f3\u30c8\u3092\u5c11\u3057\u5909\u3048\u3066\u8a18\u8ff0\u3057\u3066\u3044\u307e\u3059. \u21a9 \u9023\u7d9a\u5206\u5e03\u3068\u3057\u3066\u66f8\u3044\u3066\u3044\u307e\u3059\u304c \\(x\\) \u304c\u96e2\u6563\u7684\u306a\u5834\u5408\u306f\u548c\u306b\u7f6e\u304d\u63db\u3048\u3066\u304f\u3060\u3055\u3044. \u21a9 \u30c1\u30a7\u30c3\u30ab\u30fc\u30dc\u30fc\u30c9\u306e\u4e0a\u3092 1 \u30de\u30b9\u305a\u3064\u79fb\u52d5\u3059\u308b\u30b3\u30de\u3092\u8003\u3048\u3066\u307f\u307e\u3059. \u30b3\u30de\u306e\u5206\u5e03\u306f\u3053\u306e\u5834\u5408 \\(t\\) \u304c\u5947\u6570\u306e\u3068\u304d\u3068\u5076\u6570\u306e\u3068\u304d\u3067\u305d\u308c\u305e\u308c\u5b9a\u5e38\u5206\u5e03\u306b\u53ce\u675f\u3057\u307e\u3059\u304c, \u5168\u4f53\u3067\u898b\u305f\u3068\u304d\u306f \\(\\mathcal{P}_\\mathrm{odd}(x)\\) , \\(\\mathcal{P}_\\mathrm{even}(x)\\) \u3067\u632f\u52d5\u3057\u3066\u3057\u307e\u3044\u53ce\u675f\u3057\u307e\u305b\u3093. \u975e\u5468\u671f\u6027\u306f\u3053\u3046\u3057\u305f\u30b1\u30fc\u30b9\u3092\u6392\u9664\u3059\u308b\u305f\u3081\u306b\u8981\u6c42\u3055\u308c\u307e\u3059. \u21a9 \\(x\\) \u306e\u8fd1\u508d\u3092\u30b5\u30f3\u30d7\u30eb\u3057\u305f\u3044\u306e\u3067 \\(x\\) \u3092\u30d1\u30e9\u30e1\u30bf\u3068\u3057\u3066\u6301\u3061\u307e\u3059. \u78ba\u7387\u5206\u5e03\u3067\u306f\u3042\u308a\u307e\u3059\u304c\u7269\u7406\u7684\u306b\u610f\u5473\u304c\u3042\u308b\u308f\u3051\u3067\u306f\u306a\u3044 (\u3042\u308b\u3068\u306f\u9650\u3089\u306a\u3044) \u306e\u3067\u6587\u5b57\u306b \\(Q\\) \u3092\u4f7f\u3044\u307e\u3057\u305f. \u21a9 \\(\\alpha\\) \u306e\u8a08\u7b97\u3067\u306f\u6bd4\u3092\u3068\u308b\u306e\u3067 \\(P(x)\\) \u306e\u898f\u683c\u5316\u5b9a\u6570\u306f\u672a\u77e5\u306e\u307e\u307e\u3067\u554f\u984c\u3042\u308a\u307e\u305b\u3093. \u21a9 \u5fc5\u305a\u3057\u3082\u30e9\u30f3\u30c0\u30e0\u3067\u3042\u308b\u5fc5\u8981\u306f\u306a\u304f\u9806\u756a\u306b\u9078\u3093\u3067\u3082\u554f\u984c\u3042\u308a\u307e\u305b\u3093. \u21a9","title":"Gibbs sampling"},{"location":"mcmc/references/","text":"\u53c2\u8003\u6587\u732e \u3053\u306e\u30c6\u30ad\u30b9\u30c8\u3092\u66f8\u304f\u306b\u3042\u305f\u3063\u3066\u5927\u3044\u306b\u53c2\u8003\u306b\u3057\u305f\u6587\u732e\u3067\u3059. \u7d71\u8a08\u79d1\u5b66\u306e\u30d5\u30ed\u30f3\u30c6\u30a3\u30a2 12 \u8a08\u7b97\u7d71\u8a08II \u30de\u30eb\u30b3\u30d5\u9023\u9396\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5\u3068\u305d\u306e\u5468\u8fba : \u4f0a\u5ead\u5e78\u4eba, \u7a2e\u6751\u6b63\u7f8e, \u5927\u68ee\u88d5\u6d69, \u548c\u5408\u8087, \u4f50\u85e4\u6574\u5c1a, \u9ad8\u6a4b\u660e\u5f66 Stan\u3068R\u3067\u30d9\u30a4\u30ba\u7d71\u8a08\u30e2\u30c7\u30ea\u30f3\u30b0 : \u677e\u6d66\u5065\u592a\u90ce Bayesian Models for Astrophysical Data: Using R, JAGS, Python, and Stan Book : Emille E. O. Ishida, Joseph M. Hilbe, and Rafael S. de Souza (Resource) Bayesian Data Analysis : 3rd Edition : Andrew Gelman, John B. Carlin, Hal S. Stern, and Donald B. Rubin AstroML: Machine Learning and Data Mining for Astronomy Galaxy Zoo Data Learning Hamiltonian Monte Carlo in R : Samuel Thomas and Wanzhu Tu, American Statistician 1\u201311 (2021) doi Rank-normalization, folding, and localization: An improved \\(\\hat{R}\\) for assessing convergence of MCMC Aki Vehtari, Andrew Gelman, Daniel Simpson, Bob Carpenter, Paul-Christian B\u00fcrkner, Bayesian Anal. Advance Publication 1\u201328 (2021) doi A Catalog of Globular Cluster Systems: What Determines the Size of a Galaxy\u2019s Globular Cluster Population? William E. Harris, Gretchen L. H. Harris, and Matthew Alessi, The Astrophysical Journal 772 82 (2013) (Resource) doi","title":"\u53c2\u8003\u6587\u732e"},{"location":"mcmc/references/#_1","text":"\u3053\u306e\u30c6\u30ad\u30b9\u30c8\u3092\u66f8\u304f\u306b\u3042\u305f\u3063\u3066\u5927\u3044\u306b\u53c2\u8003\u306b\u3057\u305f\u6587\u732e\u3067\u3059. \u7d71\u8a08\u79d1\u5b66\u306e\u30d5\u30ed\u30f3\u30c6\u30a3\u30a2 12 \u8a08\u7b97\u7d71\u8a08II \u30de\u30eb\u30b3\u30d5\u9023\u9396\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5\u3068\u305d\u306e\u5468\u8fba : \u4f0a\u5ead\u5e78\u4eba, \u7a2e\u6751\u6b63\u7f8e, \u5927\u68ee\u88d5\u6d69, \u548c\u5408\u8087, \u4f50\u85e4\u6574\u5c1a, \u9ad8\u6a4b\u660e\u5f66 Stan\u3068R\u3067\u30d9\u30a4\u30ba\u7d71\u8a08\u30e2\u30c7\u30ea\u30f3\u30b0 : \u677e\u6d66\u5065\u592a\u90ce Bayesian Models for Astrophysical Data: Using R, JAGS, Python, and Stan Book : Emille E. O. Ishida, Joseph M. Hilbe, and Rafael S. de Souza (Resource) Bayesian Data Analysis : 3rd Edition : Andrew Gelman, John B. Carlin, Hal S. Stern, and Donald B. Rubin AstroML: Machine Learning and Data Mining for Astronomy Galaxy Zoo Data Learning Hamiltonian Monte Carlo in R : Samuel Thomas and Wanzhu Tu, American Statistician 1\u201311 (2021) doi Rank-normalization, folding, and localization: An improved \\(\\hat{R}\\) for assessing convergence of MCMC Aki Vehtari, Andrew Gelman, Daniel Simpson, Bob Carpenter, Paul-Christian B\u00fcrkner, Bayesian Anal. Advance Publication 1\u201328 (2021) doi A Catalog of Globular Cluster Systems: What Determines the Size of a Galaxy\u2019s Globular Cluster Population? William E. Harris, Gretchen L. H. Harris, and Matthew Alessi, The Astrophysical Journal 772 82 (2013) (Resource) doi","title":"\u53c2\u8003\u6587\u732e"},{"location":"mcmc/scratchbuild_mcmc/","text":"MHMCMC \u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb \u3053\u3053\u3067\u306f Metropolis-Hastings \u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u4f7f\u3063\u3066\u30de\u30eb\u30b3\u30d5\u9023\u9396\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u8a08\u7b97\u3092\u3059\u308b\u305f\u3081\u306e\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u4f5c\u6210\u3057\u3066\u307f\u307e\u3059. \u305f\u3060\u3057, \u5b9f\u7fd2\u6642\u9593\u5185\u306b\u3059\u3079\u3066\u3092\u30b9\u30af\u30e9\u30c3\u30c1\u304b\u3089\u4f5c\u6210\u3059\u308b\u306e\u306f\u5927\u5909\u306a\u306e\u3067, \u5927\u307e\u304b\u306a\u9aa8\u7d44\u307f\u3060\u3051 Python \u306e\u30b3\u30fc\u30c9\u3067\u7528\u610f\u3057\u307e\u3057\u305f. \u6838\u5fc3\u3068\u306a\u308b\u30d1\u30fc\u30c4\u3060\u3051\u3092 Python \u3067\u66f8\u304f\u3053\u3068\u3067 MCMC \u8a08\u7b97\u3092\u8d70\u3089\u305b\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. 1 MHMCMC Sampler \u30af\u30e9\u30b9 MCMC \u8a08\u7b97\u3092\u3059\u308b\u305f\u3081\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u3068\u3057\u3066 mhmcmc.py \u3092\u7528\u610f\u3057\u307e\u3057\u305f. \u5404\u81ea\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u4f5c\u696d\u7528\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u914d\u7f6e\u3057\u3066\u304f\u3060\u3055\u3044. \u3053\u3053\u3067\u306f\u4ee5\u4e0b\u306e 2 \u3064\u306e\u30af\u30e9\u30b9\u3092\u4f7f\u7528\u3057\u307e\u3059. MHMCMCSampler : Metropolis-Hastings \u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3067 MCMC \u8a08\u7b97\u3092\u3059\u308b\u305f\u3081\u306e\u30af\u30e9\u30b9. GaussianStep : \u6b63\u898f\u5206\u5e03\u3067\u30e9\u30f3\u30c0\u30e0\u30a6\u30a9\u30fc\u30af\u3059\u308b\u3053\u3068\u3067\u72b6\u614b\u3092\u63d0\u6848\u3059\u308b\u30af\u30e9\u30b9. \u305d\u308c\u305e\u308c\u306e\u30af\u30e9\u30b9\u306e\u4f7f\u3044\u65b9\u306e\u4f8b\u306f\u4ee5\u4e0b\u306e\u3068\u304a\u308a\u3067\u3059. from mhmcmc import MHMCMCSampler , GaussianStep import numpy as np mu = 5.0 # \u5206\u5e03\u306e\u4e2d\u5fc3 sig = 0.7 # \u5206\u5e03\u306e\u5e45 # \u4e71\u6570\u3092\u30b5\u30f3\u30d7\u30eb\u3059\u308b\u78ba\u7387\u5206\u5e03\u3092\u5b9a\u7fa9 def log_likelihood ( x ): return - np . sum ((( x - mu ) ** 2 ) / 2.0 / sig ** 2 ) # sigma = 0.5 \u3067\u30e9\u30f3\u30c0\u30e0\u30a6\u30a9\u30fc\u30af\u3059\u308b\u63d0\u6848\u5206\u5e03\u3092\u4f5c\u6210 step = GaussianStep ( 0.5 ) # \u78ba\u7387\u5206\u5e03\u3068\u63d0\u6848\u5206\u5e03\u3092\u3042\u305f\u3048\u3066 MCMC \u8a08\u7b97\u3059\u308b\u30e2\u30c7\u30eb\u3092\u4f5c\u6210 model = MHMCMCSampler ( log_likelihood , step ) x0 = np . zeros ( 1 ) # [0] \u3092\u521d\u671f\u72b6\u614b\u306b\u6307\u5b9a model . initialize ( x0 ) # \u521d\u671f\u72b6\u614b\u3092\u8a2d\u5b9a sample = model . generate ( 11000 ) # 11000 \u500b\u306e\u30c7\u30fc\u30bf\u3092\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0 sample = sample [ 1000 :] # \u6700\u521d\u306e 1000 \u500b\u3092\u6368\u3066\u308b (burn-in) print ( 'ground truth : [ {} , {} ]' . format ( mu , sig )) print ( 'estimated value: [ {} , {} ]' . format ( sample . mean (), sample . std ())) \u8a08\u7b97\u7d50\u679c ground truth : [5.000, 0.700] estimated value: [4.988, 0.702] \u78ba\u7387\u5206\u5e03\u3092\u4e0e\u3048\u308b log_likelihood \u306f 1 \u6b21\u5143\u306e numpy.ndarray() \u3092\u53d7\u3051\u53d6\u3063\u3066 float \u3092\u8fd4\u3059\u95a2\u6570\u3068\u3057\u3066\u5b9a\u7fa9\u3057\u3066\u304f\u3060\u3055\u3044. Metropolis-Hastings \u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3067\u306f\u78ba\u7387\u5206\u5e03\u306e\u6bd4\u3055\u3048\u4f7f\u3048\u308c\u3070\u826f\u3044\u306e\u3067, \u78ba\u7387\u5206\u5e03\u306f\u898f\u683c\u5316\u3055\u308c\u3066\u3044\u306a\u304f\u3066\u3082\u554f\u984c\u3042\u308a\u307e\u305b\u3093. \u8a08\u7b97\u306e\u6d41\u308c MHMCMCSampler \u3067\u306f generate() \u3068\u3044\u3046\u95a2\u6570\u3092\u547c\u3076\u3053\u3068\u3067\u4efb\u610f\u306e\u500b\u6570\u306e\u30c7\u30fc\u30bf\u3092\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u307e\u3059. \u3053\u3053\u3067\u306f step_forward() \u3068\u3044\u3046\u95a2\u6570\u3067\u73fe\u5728\u306e\u72b6\u614b\u3092\u66f4\u65b0\u3057\u305f\u5f8c\u306b, samples \u306b\u8ffd\u52a0\u3059\u308b\u3053\u3068\u3092\u7e70\u308a\u8fd4\u3057\u3066\u3044\u307e\u3059. def generate ( self , n_sample : int ) -> np . ndarray : ''' Generate N-samples Parameters: n_samples (int): Number of MCMC samples to generate. Returns: numpyn.ndarray: A table of generated MCMC samples. ''' if self . state is None : raise RuntimeError ( 'state is not initialized.' ) samples = [] for n in range ( n_sample ): self . step_forward () samples . append ( self . state ) return np . vstack ( samples ) step_forward() \u306e\u51e6\u7406\u5185\u5bb9\u3092\u4ee5\u4e0b\u306b\u793a\u3057\u307e\u3057\u305f. proposal_dist (\u63d0\u6848\u5206\u5e03\u3092\u751f\u6210\u3059\u308b\u30af\u30e9\u30b9) \u304b\u3089 draw() \u3068\u3044\u3046\u95a2\u6570\u3067\u6b21\u306e\u72b6\u614b\u3078\u306e\u63d0\u6848 proposal \u3092\u751f\u6210\u3057\u307e\u3059. \u6b21\u306b, \u78ba\u7387\u5206\u5e03 (\u5c24\u5ea6\u95a2\u6570) \u306e\u5bfe\u6570\u3092\u8a08\u7b97\u3059\u308b log_likelihood() \u3068\u9077\u79fb\u78ba\u7387\u306e\u5bfe\u6570\u3092\u8a08\u7b97\u3059\u308b\u95a2\u6570 proposal_dist.eval() \u3092\u3064\u304b\u3063\u3066 \\(\\log\\alpha\\) \u3092\u8a08\u7b97\u3057\u307e\u3059. \u307e\u305f, \\([0,1)\\) \u306e\u4e00\u69d8\u5206\u5e03\u304b\u3089\u30b5\u30f3\u30d7\u30eb\u3057\u305f\u5024\u306e\u5bfe\u6570 \\(\\log{u}\\) \u3092\u8a08\u7b97\u3057\u307e\u3059. \\(\\log{u} < \\log\\alpha\\) \u3067\u3042\u308c\u3070\u63d0\u6848\u3055\u308c\u305f proposal \u304c\u6b21\u306e\u72b6\u614b\u3068\u3057\u3066\u63a1\u629e\u3055\u308c\u307e\u3059. \u305d\u3046\u3067\u306a\u3044\u5834\u5408\u306b\u306f\u73fe\u5728\u306e\u72b6\u614b\u306b\u3068\u3069\u307e\u308a\u307e\u3059. \u524d\u7ae0 \u3067\u8aac\u660e\u3057\u305f Metropolis-Hastings \u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u304c\u305d\u306e\u307e\u307e\u5b9f\u88c5\u3055\u308c\u3066\u3044\u308b\u3053\u3068\u304c\u308f\u304b\u308b\u3068\u601d\u3044\u307e\u3059. def step_forward ( self ) -> None : ''' Draw a next Monte-Carlo step. Returns: numpy.ndarray: The newly generated next state. ''' proposal = self . proposal_dist . draw ( self . state ) log_alpha = \\ self . log_likelihood ( proposal ) - self . log_likelihood ( self . state ) \\ + self . proposal_dist . eval ( self . state , proposal ) \\ - self . proposal_dist . eval ( proposal , self . state ) log_u = np . log ( self . random . uniform ( 0 , 1 )) self . state = proposal if ( log_u < log_alpha ) else self . state MHMCMC \u306b\u3088\u308b\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0 \u3053\u3053\u3067\u306f\u7c21\u5358\u306a\u5f62\u72b6\u306e\u78ba\u7387\u5206\u5e03\u95a2\u6570\u306b\u5f93\u3046\u4e71\u6570\u3092\u751f\u6210\u3057\u3066\u307f\u307e\u3059. \u6f14\u7fd2: 1 \u6b21\u5143\u306e\u30b1\u30fc\u30b9 \u78ba\u7387\u5909\u6570 \\(x\\) \u304c 1 \u6b21\u5143\u306e\u30b1\u30fc\u30b9\u306b\u3064\u3044\u3066\u5b9f\u969b\u306b\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u3066\u307f\u307e\u3059. \u4ee5\u4e0b\u306e\u5f62\u72b6\u3092\u6301\u3064\u4ee5\u4e0b\u306e\u5f62\u72b6\u3092\u6301\u3064\u78ba\u7387\u5206\u5e03\u95a2\u6570\u3092\u5b9a\u7fa9\u3057\u3066 MCMC \u306b\u3088\u3063\u3066\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u3066\u304f\u3060\u3055\u3044. \u307e\u305f, \u5f97\u3089\u308c\u305f\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u3092\u78ba\u7387\u5206\u5e03\u95a2\u6570\u304b\u3089\u671f\u5f85\u3055\u308c\u308b\u5f62\u72b6\u3068\u6bd4\u3079\u3066\u304f\u3060\u3055\u3044. 2 \u78ba\u7387\u5206\u5e03\u304c \\(\\sqrt{1-x^2}\\) \u306b\u6bd4\u4f8b\u3059\u308b\u4e71\u6570\u3092\u751f\u6210\u3057\u3066\u304f\u3060\u3055\u3044. Example #!/usr/bin/env python # -*- coding: utf-8 -*- from mhmcmc import MHMCMCSampler , GaussianStep import numpy as np def log_likelihood ( x ): return np . log ( np . sqrt ( np . clip ( 1 - x ** 2 , 1e-15 , 1 ))) step = GaussianStep ( 0.5 ) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . zeros ( 1 ) model . initialize ( x0 ) sample = model . generate ( 101000 ) sample = sample [ 1000 :] x = np . linspace ( - 1.2 , 1.2 , 500 ) f = lambda x : np . sqrt ( np . clip ( 1 - x ** 2 , 0 , 1 )) / np . pi * 2.0 import matplotlib.pyplot as plt fig = plt . figure () ax = fig . add_subplot () ax . hist ( sample , bins = 50 , density = True ) ax . plot ( x , f ( x )) ax . set_xlabel ( 'random variable: x' ) ax . set_ylabel ( 'frequency' ) fig . tight_layout () fig . savefig ( 'try_mhmcmc_sqrt.png' ) plt . show () \u7bc4\u56f2 \\([-2, 3)\\) \u306b\u4e00\u69d8\u306b\u5206\u5e03\u3059\u308b\u4e71\u6570\u3092\u751f\u6210\u3057\u3066\u304f\u3060\u3055\u3044. Example #!/usr/bin/env python # -*- coding: utf-8 -*- from mhmcmc import MHMCMCSampler , GaussianStep import numpy as np lb , ub = - 2 , 3 def log_likelihood ( x ): return 1 if ( lb < x < ub ) else - 9999 step = GaussianStep ( 0.5 ) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . zeros ( 1 ) model . initialize ( x0 ) sample = model . generate ( 101000 ) sample = sample [ 1000 :] x = np . linspace ( - 5 , 5 , 1000 ) f = lambda x : (( lb < x ) & ( x < ub )) / ( ub - lb ) import matplotlib.pyplot as plt fig = plt . figure () ax = fig . add_subplot () ax . hist ( sample , bins = 50 , density = True ) ax . plot ( x , f ( x )) ax . set_xlabel ( 'random variable: x' ) ax . set_ylabel ( 'frequency' ) fig . tight_layout () fig . savefig ( 'try_mhmcmc_uniform.png' ) plt . show () \u30b9\u30b1\u30fc\u30eb\u304c \\(\\lambda\\) \u3067\u3042\u308b\u6307\u6570\u5206\u5e03\u306b\u5f93\u3046\u4e71\u6570\u3092\u751f\u6210\u3057\u3066\u304f\u3060\u3055\u3044. Example #!/usr/bin/env python # -*- coding: utf-8 -*- from mhmcmc import MHMCMCSampler , GaussianStep import numpy as np lam = 3 def log_likelihood ( x ): return - lam * x if x > 0 else - 9999 step = GaussianStep ( 0.5 ) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . ones ( 1 ) model . initialize ( x0 ) sample = model . generate ( 101000 ) sample = sample [ 1000 :] x = np . linspace ( 0 , 5 , 1000 ) f = lambda x : np . exp ( - lam * x ) * lam import matplotlib.pyplot as plt fig = plt . figure () ax = fig . add_subplot () ax . hist ( sample , bins = 50 , density = True ) ax . plot ( x , f ( x )) ax . set_xlabel ( 'random variable: x' ) ax . set_ylabel ( 'frequency' ) fig . tight_layout () fig . savefig ( 'try_mhmcmc_exponential.png' ) plt . show () \u6f14\u7fd2: 2 \u6b21\u5143\u306e\u30b1\u30fc\u30b9 \u78ba\u7387\u5909\u6570 \\(x\\) \u304c 2 \u6b21\u5143\u306e\u30b1\u30fc\u30b9\u306b\u3064\u3044\u3066\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u3066\u307f\u307e\u3059. \u4ee5\u4e0b\u306e\u5f62\u72b6\u3092\u6301\u3064\u4ee5\u4e0b\u306e\u5f62\u72b6\u3092\u6301\u3064\u78ba\u7387\u5206\u5e03\u95a2\u6570\u3092\u5b9a\u7fa9\u3057\u3066 MCMC \u306b\u3088\u3063\u3066\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u3066\u304f\u3060\u3055\u3044. \u307e\u305f, \u5f97\u3089\u308c\u305f\u30c7\u30fc\u30bf\u3067\u6563\u5e03\u56f3\u3092\u4f5c\u6210\u3057\u3066\u671f\u5f85\u901a\u308a\u306e\u30c7\u30fc\u30bf\u304c\u5f97\u3089\u308c\u3066\u3044\u308b\u3053\u3068\u3092\u78ba\u8a8d\u3057\u3066\u304f\u3060\u3055\u3044. \u5206\u6563\u304c\u305d\u308c\u305e\u308c 5, 2, \u5171\u5206\u6563\u304c 2 \u3067\u3042\u308b 2 \u5909\u6570\u6b63\u898f\u5206\u5e03\u304b\u3089\u4e71\u6570\u3092\u751f\u6210\u3057\u3066\u304f\u3060\u3055\u3044. Example #!/usr/bin/env python # -*- coding: utf-8 -*- from mhmcmc import MHMCMCSampler , GaussianStep import numpy as np mu = np . array ([ - 1 , 2 ]) cov = np . array ([[ 5.0 , 2.0 ], [ 2.0 , 2.0 ]]) def log_likelihood ( x ): return - np . sum ( np . dot ( x - mu , np . linalg . solve ( cov , x - mu )) / 2.0 ) step = GaussianStep ( 0.5 ) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . zeros ( 2 ) model . initialize ( x0 ) sample = model . generate ( 101000 ) sample = sample [ 1000 :] import matplotlib.pyplot as plt fig = plt . figure () ax = fig . add_subplot () ax . scatter ( sample [:: 10 , 0 ], sample [:: 10 , 1 ], s = 1 , marker = '.' ) ax . set_xlabel ( 'random variable: x0' ) ax . set_ylabel ( 'random variable: x1' ) fig . tight_layout () fig . savefig ( 'try_mhmcmc_normal.png' ) plt . show () \u4e0a\u8a18\u306e\u6b63\u898f\u5206\u5e03\u306b \\(x_{[1]} < (x_{[0]}+1)^2+1\\) \u3068\u3044\u3046\u4e0d\u7b49\u5f0f\u5236\u7d04\u3092\u52a0\u3048\u3066\u304f\u3060\u3055\u3044. 3 Example #!/usr/bin/env python # -*- coding: utf-8 -*- from mhmcmc import MHMCMCSampler , GaussianStep import numpy as np mu = np . array ([ - 1 , 2 ]) cov = np . array ([[ 5.0 , 2.0 ], [ 2.0 , 2.0 ]]) def condition ( x ): return - 9999 * ( x [ 1 ] > ( x [ 0 ] + 1 ) ** 2 + 1 ) def log_likelihood ( x ): return - np . sum ( np . dot ( x - mu , np . linalg . solve ( cov , x - mu )) / 2.0 ) + condition ( x ) step = GaussianStep ( 0.5 ) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . zeros ( 2 ) model . initialize ( x0 ) sample = model . generate ( 101000 ) sample = sample [ 1000 :] import matplotlib.pyplot as plt fig = plt . figure () ax = fig . add_subplot () ax . scatter ( sample [:: 10 , 0 ], sample [:: 10 , 1 ], s = 1 , marker = '.' ) ax . set_xlabel ( 'random variable: x0' ) ax . set_ylabel ( 'random variable: x1' ) fig . tight_layout () fig . savefig ( 'try_mhmcmc_conditional.png' ) plt . show () \\(P(r) \\propto \\exp\\left(-\\frac{1}{2\\sigma^2}(r-1)^2\\right), ~~ r = \\sqrt{x_{[0]}^2 + x_{[1]}^2}\\) \u304b\u3089\u4e71\u6570\u3092\u751f\u6210\u3057\u3066\u304f\u3060\u3055\u3044. Example #!/usr/bin/env python # -*- coding: utf-8 -*- from mhmcmc import MHMCMCSampler , GaussianStep import numpy as np sigma = 0.2 def log_likelihood ( x ): return - ( np . sqrt ( x [ 0 ] ** 2 + x [ 1 ] ** 2 ) - 2 ) ** 2 / 2.0 / sigma ** 2 step = GaussianStep ( 0.5 ) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . zeros ( 2 ) model . initialize ( x0 ) sample = model . generate ( 101000 ) sample = sample [ 1000 :] import matplotlib.pyplot as plt fig = plt . figure () ax = fig . add_subplot () ax . scatter ( sample [:: 10 , 0 ], sample [:: 10 , 1 ], s = 1 , marker = '.' ) ax . set_xlabel ( 'random variable: x0' ) ax . set_ylabel ( 'random variable: x1' ) fig . tight_layout () fig . savefig ( 'try_mhmcmc_circle.png' ) plt . show () \u5404\u30af\u30e9\u30b9\u306e\u5b9a\u7fa9 \u53c2\u8003\u307e\u3067\u306b MHMCMCSampler \u3068 GaussianStep \u306e\u5b9a\u7fa9\u5168\u4f53\u3092\u4ee5\u4e0b\u306b\u793a\u3057\u307e\u3057\u305f. \u5fc5\u8981\u306b\u5fdc\u3058\u3066\u6a5f\u80fd\u3092\u4ed8\u3051\u52a0\u3048\u308b\u306a\u3069\u306e\u6539\u9020\u3092\u3057\u3066\u307f\u3066\u304f\u3060\u3055\u3044. MHMCMCSampler class MHMCMCSampler ( object ): ''' MCMC sampler with the Metropolis-Hastings algorithm. ''' def __init__ ( self , log_likelihood : Callable [[ np . ndarray ], float ], proposal_dist : AbstractProposalDistribution , seed : int = 2021 ) -> None : ''' Generate a MCMC sampler instatnce. Parameters: likelihood (function): An instance to calculate log-likelihood. A sub-class of AbstractLikelihood is preferred. proposal_dist (AbstractProposalDistribution): An instance to draw from a proposal distribution. A sub-class of AbstractProposalDistribution is preferred. seed (float, optional): Random seed value. ''' self . log_likelihood = log_likelihood self . proposal_dist = proposal_dist self . random = default_rng ( seed ) self . initialize ( None ) def initialize ( self , x0 : np . ndarray ) -> None : ''' Initialize state. Parameters: x0 (numpy.ndarray): An initial state (1-dimensional vector). ''' self . state = x0 def step_forward ( self ) -> None : ''' Draw a next Monte-Carlo step. Returns: numpy.ndarray: The newly generated next state. ''' proposal = self . proposal_dist . draw ( self . state ) log_alpha = \\ self . log_likelihood ( proposal ) - self . log_likelihood ( self . state ) \\ + self . proposal_dist . eval ( self . state , proposal ) \\ - self . proposal_dist . eval ( proposal , self . state ) log_u = np . log ( self . random . uniform ( 0 , 1 )) self . state = proposal if ( log_u < log_alpha ) else self . state def generate ( self , n_sample : int ) -> np . ndarray : ''' Generate N-samples Parameters: n_samples (int): Number of MCMC samples to generate. Returns: numpyn.ndarray: A table of generated MCMC samples. ''' if self . state is None : raise RuntimeError ( 'state is not initialized.' ) samples = [] tqdmfmt = ' {l_bar}{bar} | {n_fmt} / {total_fmt} ' for n in trange ( n_sample , bar_format = tqdmfmt ): self . step_forward () samples . append ( self . state ) return np . vstack ( samples ) GaussianStep class GaussianStep ( AbstractProposalDistribution ): ''' A random-walk proposal distribution with Gaussian distribution. ''' def __init__ ( self , sigma : Union [ float , np . ndarray ], seed : int = 2021 ) -> None : ''' Generate an instance. Args: sigma (float or numpy.ndarray): Length of a Monte Carlo step. seed (int, optional): Seed value for the random value generator. ''' self . sigma = sigma self . gen = default_rng ( seed ) def draw ( self , x0 : np . ndarray ) -> np . ndarray : ''' Propose a new state by random walk. Parameters: x0 (numpy.ndarray): The current state. Returns: numpy.ndarray: A newly-proposed state. ''' return x0 + self . gen . normal ( 0 , self . sigma , size = x0 . shape ) def eval ( self , x : np . ndarray , x0 : np . ndarray ) -> float : ''' Evaluate the log-transition probability for the state `x`. Parameters: x (numpy.ndarray): The proposed state. x0 (numpy.ndarray): The current state. Returns: float: The log-transition probability, logQ(x, x0). ''' return np . sum ( - ( x - x0 ) ** 2 / ( 2 * self . sigma ** 2 )) \u305f\u3060\u3057\u7528\u610f\u3057\u305f\u30b3\u30fc\u30c9\u306f\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u306b\u3064\u3044\u3066\u306f\u4f55\u3082\u8003\u616e\u3055\u308c\u3066\u3044\u307e\u305b\u3093. Python \u306e\u30d1\u30c3\u30b1\u30fc\u30b8\u3068\u3057\u3066\u4f7f\u7528\u53ef\u80fd\u306a MCMC \u8a08\u7b97\u30e9\u30a4\u30d6\u30e9\u30ea\u3068\u306f\u8a08\u7b97\u901f\u5ea6\u306f\u96f2\u6ce5\u306e\u5dee\u304c\u3042\u308b\u3068\u601d\u308f\u308c\u307e\u3059. \u3053\u3053\u3067\u306f, MCMC \u8a08\u7b97\u306e\u52b9\u7387\u3092\u4f53\u9a13\u3059\u308b\u3068\u3044\u3046\u3088\u308a\u306f MCMC \u8a08\u7b97\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u4e2d\u3067\u4f55\u304c\u8d77\u304d\u3066\u3044\u308b\u306e\u304b\u3092\u610f\u8b58\u3057\u306a\u304c\u3089\u30b3\u30fc\u30c9\u3092\u66f8\u304f\u3053\u3068\u3092\u76ee\u7684\u3068\u3057\u3066\u3044\u307e\u3059. \u21a9 \u5f97\u3089\u308c\u305f\u30c7\u30fc\u30bf\u5217\u306e\u5206\u5e03\u3092\u8b70\u8ad6\u3059\u308b\u5834\u5408\u306b\u306f, \u30b5\u30f3\u30d7\u30eb\u9593\u306e\u76f8\u95a2\u304c\u7d50\u679c\u306b\u5f71\u97ff\u3057\u307e\u3059. \u6642\u9593\u7684\u306b\u5341\u5206\u96e2\u308c\u305f\u5834\u6240\u306e\u30b5\u30f3\u30d7\u30eb\u3060\u3051\u306b\u9593\u5f15\u3044\u3066\u304b\u3089\u6271\u3046\u3053\u3068\u3067\u30b5\u30f3\u30d7\u30eb\u9593\u306e\u76f8\u95a2\u3092\u5207\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u305d\u306e\u305f\u3081\u306b\u306f\u3088\u308a\u591a\u304f\u306e\u30c7\u30fc\u30bf\u3092\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u305f\u3081, \u3053\u3053\u3067\u306f\u3053\u306e\u64cd\u4f5c\u306f\u7701\u7565\u3057\u307e\u3059. \u21a9 \u78ba\u7387\u5909\u6570 \\(x\\) \u306e \\(i\\) \u756a\u76ee\u306e\u8981\u7d20\u3092 \\(x_{[i]}\\) \u3067\u8868\u73fe\u3057\u3066\u3044\u307e\u3059. \u21a9","title":"MHMCMC \u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb"},{"location":"mcmc/scratchbuild_mcmc/#mhmcmc","text":"\u3053\u3053\u3067\u306f Metropolis-Hastings \u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u4f7f\u3063\u3066\u30de\u30eb\u30b3\u30d5\u9023\u9396\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u8a08\u7b97\u3092\u3059\u308b\u305f\u3081\u306e\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u4f5c\u6210\u3057\u3066\u307f\u307e\u3059. \u305f\u3060\u3057, \u5b9f\u7fd2\u6642\u9593\u5185\u306b\u3059\u3079\u3066\u3092\u30b9\u30af\u30e9\u30c3\u30c1\u304b\u3089\u4f5c\u6210\u3059\u308b\u306e\u306f\u5927\u5909\u306a\u306e\u3067, \u5927\u307e\u304b\u306a\u9aa8\u7d44\u307f\u3060\u3051 Python \u306e\u30b3\u30fc\u30c9\u3067\u7528\u610f\u3057\u307e\u3057\u305f. \u6838\u5fc3\u3068\u306a\u308b\u30d1\u30fc\u30c4\u3060\u3051\u3092 Python \u3067\u66f8\u304f\u3053\u3068\u3067 MCMC \u8a08\u7b97\u3092\u8d70\u3089\u305b\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. 1","title":"MHMCMC \u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb"},{"location":"mcmc/scratchbuild_mcmc/#mhmcmc-sampler","text":"MCMC \u8a08\u7b97\u3092\u3059\u308b\u305f\u3081\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u3068\u3057\u3066 mhmcmc.py \u3092\u7528\u610f\u3057\u307e\u3057\u305f. \u5404\u81ea\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u4f5c\u696d\u7528\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u914d\u7f6e\u3057\u3066\u304f\u3060\u3055\u3044. \u3053\u3053\u3067\u306f\u4ee5\u4e0b\u306e 2 \u3064\u306e\u30af\u30e9\u30b9\u3092\u4f7f\u7528\u3057\u307e\u3059. MHMCMCSampler : Metropolis-Hastings \u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3067 MCMC \u8a08\u7b97\u3092\u3059\u308b\u305f\u3081\u306e\u30af\u30e9\u30b9. GaussianStep : \u6b63\u898f\u5206\u5e03\u3067\u30e9\u30f3\u30c0\u30e0\u30a6\u30a9\u30fc\u30af\u3059\u308b\u3053\u3068\u3067\u72b6\u614b\u3092\u63d0\u6848\u3059\u308b\u30af\u30e9\u30b9. \u305d\u308c\u305e\u308c\u306e\u30af\u30e9\u30b9\u306e\u4f7f\u3044\u65b9\u306e\u4f8b\u306f\u4ee5\u4e0b\u306e\u3068\u304a\u308a\u3067\u3059. from mhmcmc import MHMCMCSampler , GaussianStep import numpy as np mu = 5.0 # \u5206\u5e03\u306e\u4e2d\u5fc3 sig = 0.7 # \u5206\u5e03\u306e\u5e45 # \u4e71\u6570\u3092\u30b5\u30f3\u30d7\u30eb\u3059\u308b\u78ba\u7387\u5206\u5e03\u3092\u5b9a\u7fa9 def log_likelihood ( x ): return - np . sum ((( x - mu ) ** 2 ) / 2.0 / sig ** 2 ) # sigma = 0.5 \u3067\u30e9\u30f3\u30c0\u30e0\u30a6\u30a9\u30fc\u30af\u3059\u308b\u63d0\u6848\u5206\u5e03\u3092\u4f5c\u6210 step = GaussianStep ( 0.5 ) # \u78ba\u7387\u5206\u5e03\u3068\u63d0\u6848\u5206\u5e03\u3092\u3042\u305f\u3048\u3066 MCMC \u8a08\u7b97\u3059\u308b\u30e2\u30c7\u30eb\u3092\u4f5c\u6210 model = MHMCMCSampler ( log_likelihood , step ) x0 = np . zeros ( 1 ) # [0] \u3092\u521d\u671f\u72b6\u614b\u306b\u6307\u5b9a model . initialize ( x0 ) # \u521d\u671f\u72b6\u614b\u3092\u8a2d\u5b9a sample = model . generate ( 11000 ) # 11000 \u500b\u306e\u30c7\u30fc\u30bf\u3092\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0 sample = sample [ 1000 :] # \u6700\u521d\u306e 1000 \u500b\u3092\u6368\u3066\u308b (burn-in) print ( 'ground truth : [ {} , {} ]' . format ( mu , sig )) print ( 'estimated value: [ {} , {} ]' . format ( sample . mean (), sample . std ())) \u8a08\u7b97\u7d50\u679c ground truth : [5.000, 0.700] estimated value: [4.988, 0.702] \u78ba\u7387\u5206\u5e03\u3092\u4e0e\u3048\u308b log_likelihood \u306f 1 \u6b21\u5143\u306e numpy.ndarray() \u3092\u53d7\u3051\u53d6\u3063\u3066 float \u3092\u8fd4\u3059\u95a2\u6570\u3068\u3057\u3066\u5b9a\u7fa9\u3057\u3066\u304f\u3060\u3055\u3044. Metropolis-Hastings \u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3067\u306f\u78ba\u7387\u5206\u5e03\u306e\u6bd4\u3055\u3048\u4f7f\u3048\u308c\u3070\u826f\u3044\u306e\u3067, \u78ba\u7387\u5206\u5e03\u306f\u898f\u683c\u5316\u3055\u308c\u3066\u3044\u306a\u304f\u3066\u3082\u554f\u984c\u3042\u308a\u307e\u305b\u3093.","title":"MHMCMC Sampler \u30af\u30e9\u30b9"},{"location":"mcmc/scratchbuild_mcmc/#_1","text":"MHMCMCSampler \u3067\u306f generate() \u3068\u3044\u3046\u95a2\u6570\u3092\u547c\u3076\u3053\u3068\u3067\u4efb\u610f\u306e\u500b\u6570\u306e\u30c7\u30fc\u30bf\u3092\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u307e\u3059. \u3053\u3053\u3067\u306f step_forward() \u3068\u3044\u3046\u95a2\u6570\u3067\u73fe\u5728\u306e\u72b6\u614b\u3092\u66f4\u65b0\u3057\u305f\u5f8c\u306b, samples \u306b\u8ffd\u52a0\u3059\u308b\u3053\u3068\u3092\u7e70\u308a\u8fd4\u3057\u3066\u3044\u307e\u3059. def generate ( self , n_sample : int ) -> np . ndarray : ''' Generate N-samples Parameters: n_samples (int): Number of MCMC samples to generate. Returns: numpyn.ndarray: A table of generated MCMC samples. ''' if self . state is None : raise RuntimeError ( 'state is not initialized.' ) samples = [] for n in range ( n_sample ): self . step_forward () samples . append ( self . state ) return np . vstack ( samples ) step_forward() \u306e\u51e6\u7406\u5185\u5bb9\u3092\u4ee5\u4e0b\u306b\u793a\u3057\u307e\u3057\u305f. proposal_dist (\u63d0\u6848\u5206\u5e03\u3092\u751f\u6210\u3059\u308b\u30af\u30e9\u30b9) \u304b\u3089 draw() \u3068\u3044\u3046\u95a2\u6570\u3067\u6b21\u306e\u72b6\u614b\u3078\u306e\u63d0\u6848 proposal \u3092\u751f\u6210\u3057\u307e\u3059. \u6b21\u306b, \u78ba\u7387\u5206\u5e03 (\u5c24\u5ea6\u95a2\u6570) \u306e\u5bfe\u6570\u3092\u8a08\u7b97\u3059\u308b log_likelihood() \u3068\u9077\u79fb\u78ba\u7387\u306e\u5bfe\u6570\u3092\u8a08\u7b97\u3059\u308b\u95a2\u6570 proposal_dist.eval() \u3092\u3064\u304b\u3063\u3066 \\(\\log\\alpha\\) \u3092\u8a08\u7b97\u3057\u307e\u3059. \u307e\u305f, \\([0,1)\\) \u306e\u4e00\u69d8\u5206\u5e03\u304b\u3089\u30b5\u30f3\u30d7\u30eb\u3057\u305f\u5024\u306e\u5bfe\u6570 \\(\\log{u}\\) \u3092\u8a08\u7b97\u3057\u307e\u3059. \\(\\log{u} < \\log\\alpha\\) \u3067\u3042\u308c\u3070\u63d0\u6848\u3055\u308c\u305f proposal \u304c\u6b21\u306e\u72b6\u614b\u3068\u3057\u3066\u63a1\u629e\u3055\u308c\u307e\u3059. \u305d\u3046\u3067\u306a\u3044\u5834\u5408\u306b\u306f\u73fe\u5728\u306e\u72b6\u614b\u306b\u3068\u3069\u307e\u308a\u307e\u3059. \u524d\u7ae0 \u3067\u8aac\u660e\u3057\u305f Metropolis-Hastings \u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u304c\u305d\u306e\u307e\u307e\u5b9f\u88c5\u3055\u308c\u3066\u3044\u308b\u3053\u3068\u304c\u308f\u304b\u308b\u3068\u601d\u3044\u307e\u3059. def step_forward ( self ) -> None : ''' Draw a next Monte-Carlo step. Returns: numpy.ndarray: The newly generated next state. ''' proposal = self . proposal_dist . draw ( self . state ) log_alpha = \\ self . log_likelihood ( proposal ) - self . log_likelihood ( self . state ) \\ + self . proposal_dist . eval ( self . state , proposal ) \\ - self . proposal_dist . eval ( proposal , self . state ) log_u = np . log ( self . random . uniform ( 0 , 1 )) self . state = proposal if ( log_u < log_alpha ) else self . state","title":"\u8a08\u7b97\u306e\u6d41\u308c"},{"location":"mcmc/scratchbuild_mcmc/#mhmcmc_1","text":"\u3053\u3053\u3067\u306f\u7c21\u5358\u306a\u5f62\u72b6\u306e\u78ba\u7387\u5206\u5e03\u95a2\u6570\u306b\u5f93\u3046\u4e71\u6570\u3092\u751f\u6210\u3057\u3066\u307f\u307e\u3059.","title":"MHMCMC \u306b\u3088\u308b\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0"},{"location":"mcmc/scratchbuild_mcmc/#1","text":"\u78ba\u7387\u5909\u6570 \\(x\\) \u304c 1 \u6b21\u5143\u306e\u30b1\u30fc\u30b9\u306b\u3064\u3044\u3066\u5b9f\u969b\u306b\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u3066\u307f\u307e\u3059. \u4ee5\u4e0b\u306e\u5f62\u72b6\u3092\u6301\u3064\u4ee5\u4e0b\u306e\u5f62\u72b6\u3092\u6301\u3064\u78ba\u7387\u5206\u5e03\u95a2\u6570\u3092\u5b9a\u7fa9\u3057\u3066 MCMC \u306b\u3088\u3063\u3066\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u3066\u304f\u3060\u3055\u3044. \u307e\u305f, \u5f97\u3089\u308c\u305f\u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u3092\u78ba\u7387\u5206\u5e03\u95a2\u6570\u304b\u3089\u671f\u5f85\u3055\u308c\u308b\u5f62\u72b6\u3068\u6bd4\u3079\u3066\u304f\u3060\u3055\u3044. 2 \u78ba\u7387\u5206\u5e03\u304c \\(\\sqrt{1-x^2}\\) \u306b\u6bd4\u4f8b\u3059\u308b\u4e71\u6570\u3092\u751f\u6210\u3057\u3066\u304f\u3060\u3055\u3044. Example #!/usr/bin/env python # -*- coding: utf-8 -*- from mhmcmc import MHMCMCSampler , GaussianStep import numpy as np def log_likelihood ( x ): return np . log ( np . sqrt ( np . clip ( 1 - x ** 2 , 1e-15 , 1 ))) step = GaussianStep ( 0.5 ) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . zeros ( 1 ) model . initialize ( x0 ) sample = model . generate ( 101000 ) sample = sample [ 1000 :] x = np . linspace ( - 1.2 , 1.2 , 500 ) f = lambda x : np . sqrt ( np . clip ( 1 - x ** 2 , 0 , 1 )) / np . pi * 2.0 import matplotlib.pyplot as plt fig = plt . figure () ax = fig . add_subplot () ax . hist ( sample , bins = 50 , density = True ) ax . plot ( x , f ( x )) ax . set_xlabel ( 'random variable: x' ) ax . set_ylabel ( 'frequency' ) fig . tight_layout () fig . savefig ( 'try_mhmcmc_sqrt.png' ) plt . show () \u7bc4\u56f2 \\([-2, 3)\\) \u306b\u4e00\u69d8\u306b\u5206\u5e03\u3059\u308b\u4e71\u6570\u3092\u751f\u6210\u3057\u3066\u304f\u3060\u3055\u3044. Example #!/usr/bin/env python # -*- coding: utf-8 -*- from mhmcmc import MHMCMCSampler , GaussianStep import numpy as np lb , ub = - 2 , 3 def log_likelihood ( x ): return 1 if ( lb < x < ub ) else - 9999 step = GaussianStep ( 0.5 ) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . zeros ( 1 ) model . initialize ( x0 ) sample = model . generate ( 101000 ) sample = sample [ 1000 :] x = np . linspace ( - 5 , 5 , 1000 ) f = lambda x : (( lb < x ) & ( x < ub )) / ( ub - lb ) import matplotlib.pyplot as plt fig = plt . figure () ax = fig . add_subplot () ax . hist ( sample , bins = 50 , density = True ) ax . plot ( x , f ( x )) ax . set_xlabel ( 'random variable: x' ) ax . set_ylabel ( 'frequency' ) fig . tight_layout () fig . savefig ( 'try_mhmcmc_uniform.png' ) plt . show () \u30b9\u30b1\u30fc\u30eb\u304c \\(\\lambda\\) \u3067\u3042\u308b\u6307\u6570\u5206\u5e03\u306b\u5f93\u3046\u4e71\u6570\u3092\u751f\u6210\u3057\u3066\u304f\u3060\u3055\u3044. Example #!/usr/bin/env python # -*- coding: utf-8 -*- from mhmcmc import MHMCMCSampler , GaussianStep import numpy as np lam = 3 def log_likelihood ( x ): return - lam * x if x > 0 else - 9999 step = GaussianStep ( 0.5 ) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . ones ( 1 ) model . initialize ( x0 ) sample = model . generate ( 101000 ) sample = sample [ 1000 :] x = np . linspace ( 0 , 5 , 1000 ) f = lambda x : np . exp ( - lam * x ) * lam import matplotlib.pyplot as plt fig = plt . figure () ax = fig . add_subplot () ax . hist ( sample , bins = 50 , density = True ) ax . plot ( x , f ( x )) ax . set_xlabel ( 'random variable: x' ) ax . set_ylabel ( 'frequency' ) fig . tight_layout () fig . savefig ( 'try_mhmcmc_exponential.png' ) plt . show ()","title":"\u6f14\u7fd2: 1 \u6b21\u5143\u306e\u30b1\u30fc\u30b9"},{"location":"mcmc/scratchbuild_mcmc/#2","text":"\u78ba\u7387\u5909\u6570 \\(x\\) \u304c 2 \u6b21\u5143\u306e\u30b1\u30fc\u30b9\u306b\u3064\u3044\u3066\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u3066\u307f\u307e\u3059. \u4ee5\u4e0b\u306e\u5f62\u72b6\u3092\u6301\u3064\u4ee5\u4e0b\u306e\u5f62\u72b6\u3092\u6301\u3064\u78ba\u7387\u5206\u5e03\u95a2\u6570\u3092\u5b9a\u7fa9\u3057\u3066 MCMC \u306b\u3088\u3063\u3066\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u3066\u304f\u3060\u3055\u3044. \u307e\u305f, \u5f97\u3089\u308c\u305f\u30c7\u30fc\u30bf\u3067\u6563\u5e03\u56f3\u3092\u4f5c\u6210\u3057\u3066\u671f\u5f85\u901a\u308a\u306e\u30c7\u30fc\u30bf\u304c\u5f97\u3089\u308c\u3066\u3044\u308b\u3053\u3068\u3092\u78ba\u8a8d\u3057\u3066\u304f\u3060\u3055\u3044. \u5206\u6563\u304c\u305d\u308c\u305e\u308c 5, 2, \u5171\u5206\u6563\u304c 2 \u3067\u3042\u308b 2 \u5909\u6570\u6b63\u898f\u5206\u5e03\u304b\u3089\u4e71\u6570\u3092\u751f\u6210\u3057\u3066\u304f\u3060\u3055\u3044. Example #!/usr/bin/env python # -*- coding: utf-8 -*- from mhmcmc import MHMCMCSampler , GaussianStep import numpy as np mu = np . array ([ - 1 , 2 ]) cov = np . array ([[ 5.0 , 2.0 ], [ 2.0 , 2.0 ]]) def log_likelihood ( x ): return - np . sum ( np . dot ( x - mu , np . linalg . solve ( cov , x - mu )) / 2.0 ) step = GaussianStep ( 0.5 ) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . zeros ( 2 ) model . initialize ( x0 ) sample = model . generate ( 101000 ) sample = sample [ 1000 :] import matplotlib.pyplot as plt fig = plt . figure () ax = fig . add_subplot () ax . scatter ( sample [:: 10 , 0 ], sample [:: 10 , 1 ], s = 1 , marker = '.' ) ax . set_xlabel ( 'random variable: x0' ) ax . set_ylabel ( 'random variable: x1' ) fig . tight_layout () fig . savefig ( 'try_mhmcmc_normal.png' ) plt . show () \u4e0a\u8a18\u306e\u6b63\u898f\u5206\u5e03\u306b \\(x_{[1]} < (x_{[0]}+1)^2+1\\) \u3068\u3044\u3046\u4e0d\u7b49\u5f0f\u5236\u7d04\u3092\u52a0\u3048\u3066\u304f\u3060\u3055\u3044. 3 Example #!/usr/bin/env python # -*- coding: utf-8 -*- from mhmcmc import MHMCMCSampler , GaussianStep import numpy as np mu = np . array ([ - 1 , 2 ]) cov = np . array ([[ 5.0 , 2.0 ], [ 2.0 , 2.0 ]]) def condition ( x ): return - 9999 * ( x [ 1 ] > ( x [ 0 ] + 1 ) ** 2 + 1 ) def log_likelihood ( x ): return - np . sum ( np . dot ( x - mu , np . linalg . solve ( cov , x - mu )) / 2.0 ) + condition ( x ) step = GaussianStep ( 0.5 ) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . zeros ( 2 ) model . initialize ( x0 ) sample = model . generate ( 101000 ) sample = sample [ 1000 :] import matplotlib.pyplot as plt fig = plt . figure () ax = fig . add_subplot () ax . scatter ( sample [:: 10 , 0 ], sample [:: 10 , 1 ], s = 1 , marker = '.' ) ax . set_xlabel ( 'random variable: x0' ) ax . set_ylabel ( 'random variable: x1' ) fig . tight_layout () fig . savefig ( 'try_mhmcmc_conditional.png' ) plt . show () \\(P(r) \\propto \\exp\\left(-\\frac{1}{2\\sigma^2}(r-1)^2\\right), ~~ r = \\sqrt{x_{[0]}^2 + x_{[1]}^2}\\) \u304b\u3089\u4e71\u6570\u3092\u751f\u6210\u3057\u3066\u304f\u3060\u3055\u3044. Example #!/usr/bin/env python # -*- coding: utf-8 -*- from mhmcmc import MHMCMCSampler , GaussianStep import numpy as np sigma = 0.2 def log_likelihood ( x ): return - ( np . sqrt ( x [ 0 ] ** 2 + x [ 1 ] ** 2 ) - 2 ) ** 2 / 2.0 / sigma ** 2 step = GaussianStep ( 0.5 ) model = MHMCMCSampler ( log_likelihood , step ) x0 = np . zeros ( 2 ) model . initialize ( x0 ) sample = model . generate ( 101000 ) sample = sample [ 1000 :] import matplotlib.pyplot as plt fig = plt . figure () ax = fig . add_subplot () ax . scatter ( sample [:: 10 , 0 ], sample [:: 10 , 1 ], s = 1 , marker = '.' ) ax . set_xlabel ( 'random variable: x0' ) ax . set_ylabel ( 'random variable: x1' ) fig . tight_layout () fig . savefig ( 'try_mhmcmc_circle.png' ) plt . show ()","title":"\u6f14\u7fd2: 2 \u6b21\u5143\u306e\u30b1\u30fc\u30b9"},{"location":"mcmc/scratchbuild_mcmc/#_2","text":"\u53c2\u8003\u307e\u3067\u306b MHMCMCSampler \u3068 GaussianStep \u306e\u5b9a\u7fa9\u5168\u4f53\u3092\u4ee5\u4e0b\u306b\u793a\u3057\u307e\u3057\u305f. \u5fc5\u8981\u306b\u5fdc\u3058\u3066\u6a5f\u80fd\u3092\u4ed8\u3051\u52a0\u3048\u308b\u306a\u3069\u306e\u6539\u9020\u3092\u3057\u3066\u307f\u3066\u304f\u3060\u3055\u3044.","title":"\u5404\u30af\u30e9\u30b9\u306e\u5b9a\u7fa9"},{"location":"mcmc/scratchbuild_mcmc/#mhmcmcsampler","text":"class MHMCMCSampler ( object ): ''' MCMC sampler with the Metropolis-Hastings algorithm. ''' def __init__ ( self , log_likelihood : Callable [[ np . ndarray ], float ], proposal_dist : AbstractProposalDistribution , seed : int = 2021 ) -> None : ''' Generate a MCMC sampler instatnce. Parameters: likelihood (function): An instance to calculate log-likelihood. A sub-class of AbstractLikelihood is preferred. proposal_dist (AbstractProposalDistribution): An instance to draw from a proposal distribution. A sub-class of AbstractProposalDistribution is preferred. seed (float, optional): Random seed value. ''' self . log_likelihood = log_likelihood self . proposal_dist = proposal_dist self . random = default_rng ( seed ) self . initialize ( None ) def initialize ( self , x0 : np . ndarray ) -> None : ''' Initialize state. Parameters: x0 (numpy.ndarray): An initial state (1-dimensional vector). ''' self . state = x0 def step_forward ( self ) -> None : ''' Draw a next Monte-Carlo step. Returns: numpy.ndarray: The newly generated next state. ''' proposal = self . proposal_dist . draw ( self . state ) log_alpha = \\ self . log_likelihood ( proposal ) - self . log_likelihood ( self . state ) \\ + self . proposal_dist . eval ( self . state , proposal ) \\ - self . proposal_dist . eval ( proposal , self . state ) log_u = np . log ( self . random . uniform ( 0 , 1 )) self . state = proposal if ( log_u < log_alpha ) else self . state def generate ( self , n_sample : int ) -> np . ndarray : ''' Generate N-samples Parameters: n_samples (int): Number of MCMC samples to generate. Returns: numpyn.ndarray: A table of generated MCMC samples. ''' if self . state is None : raise RuntimeError ( 'state is not initialized.' ) samples = [] tqdmfmt = ' {l_bar}{bar} | {n_fmt} / {total_fmt} ' for n in trange ( n_sample , bar_format = tqdmfmt ): self . step_forward () samples . append ( self . state ) return np . vstack ( samples )","title":"MHMCMCSampler"},{"location":"mcmc/scratchbuild_mcmc/#gaussianstep","text":"class GaussianStep ( AbstractProposalDistribution ): ''' A random-walk proposal distribution with Gaussian distribution. ''' def __init__ ( self , sigma : Union [ float , np . ndarray ], seed : int = 2021 ) -> None : ''' Generate an instance. Args: sigma (float or numpy.ndarray): Length of a Monte Carlo step. seed (int, optional): Seed value for the random value generator. ''' self . sigma = sigma self . gen = default_rng ( seed ) def draw ( self , x0 : np . ndarray ) -> np . ndarray : ''' Propose a new state by random walk. Parameters: x0 (numpy.ndarray): The current state. Returns: numpy.ndarray: A newly-proposed state. ''' return x0 + self . gen . normal ( 0 , self . sigma , size = x0 . shape ) def eval ( self , x : np . ndarray , x0 : np . ndarray ) -> float : ''' Evaluate the log-transition probability for the state `x`. Parameters: x (numpy.ndarray): The proposed state. x0 (numpy.ndarray): The current state. Returns: float: The log-transition probability, logQ(x, x0). ''' return np . sum ( - ( x - x0 ) ** 2 / ( 2 * self . sigma ** 2 )) \u305f\u3060\u3057\u7528\u610f\u3057\u305f\u30b3\u30fc\u30c9\u306f\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u306b\u3064\u3044\u3066\u306f\u4f55\u3082\u8003\u616e\u3055\u308c\u3066\u3044\u307e\u305b\u3093. Python \u306e\u30d1\u30c3\u30b1\u30fc\u30b8\u3068\u3057\u3066\u4f7f\u7528\u53ef\u80fd\u306a MCMC \u8a08\u7b97\u30e9\u30a4\u30d6\u30e9\u30ea\u3068\u306f\u8a08\u7b97\u901f\u5ea6\u306f\u96f2\u6ce5\u306e\u5dee\u304c\u3042\u308b\u3068\u601d\u308f\u308c\u307e\u3059. \u3053\u3053\u3067\u306f, MCMC \u8a08\u7b97\u306e\u52b9\u7387\u3092\u4f53\u9a13\u3059\u308b\u3068\u3044\u3046\u3088\u308a\u306f MCMC \u8a08\u7b97\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u4e2d\u3067\u4f55\u304c\u8d77\u304d\u3066\u3044\u308b\u306e\u304b\u3092\u610f\u8b58\u3057\u306a\u304c\u3089\u30b3\u30fc\u30c9\u3092\u66f8\u304f\u3053\u3068\u3092\u76ee\u7684\u3068\u3057\u3066\u3044\u307e\u3059. \u21a9 \u5f97\u3089\u308c\u305f\u30c7\u30fc\u30bf\u5217\u306e\u5206\u5e03\u3092\u8b70\u8ad6\u3059\u308b\u5834\u5408\u306b\u306f, \u30b5\u30f3\u30d7\u30eb\u9593\u306e\u76f8\u95a2\u304c\u7d50\u679c\u306b\u5f71\u97ff\u3057\u307e\u3059. \u6642\u9593\u7684\u306b\u5341\u5206\u96e2\u308c\u305f\u5834\u6240\u306e\u30b5\u30f3\u30d7\u30eb\u3060\u3051\u306b\u9593\u5f15\u3044\u3066\u304b\u3089\u6271\u3046\u3053\u3068\u3067\u30b5\u30f3\u30d7\u30eb\u9593\u306e\u76f8\u95a2\u3092\u5207\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u305d\u306e\u305f\u3081\u306b\u306f\u3088\u308a\u591a\u304f\u306e\u30c7\u30fc\u30bf\u3092\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u305f\u3081, \u3053\u3053\u3067\u306f\u3053\u306e\u64cd\u4f5c\u306f\u7701\u7565\u3057\u307e\u3059. \u21a9 \u78ba\u7387\u5909\u6570 \\(x\\) \u306e \\(i\\) \u756a\u76ee\u306e\u8981\u7d20\u3092 \\(x_{[i]}\\) \u3067\u8868\u73fe\u3057\u3066\u3044\u307e\u3059. \u21a9","title":"GaussianStep"},{"location":"mcmc/static_monte_carlo/","text":"\u9759\u7684\u306a\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5 \u3053\u3053\u3067\u306f\u30de\u30eb\u30b3\u30d5\u9023\u9396\u3067\u306f\u306a\u3044\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5\u3092\u7528\u3044\u3066\u8a08\u7b97\u3092\u3059\u308b\u65b9\u6cd5\u3068\u305d\u306e\u9650\u754c\u306b\u3064\u3044\u3066\u89e6\u308c\u307e\u3059. \u30de\u30eb\u30b3\u30d5\u9023\u9396\u306b\u3088\u3063\u3066\u52d5\u7684\u306b\u30b5\u30f3\u30d7\u30eb\u3092\u751f\u6210\u3059\u308b\u65b9\u6cd5\u3068\u5bfe\u6bd4\u3059\u308b\u305f\u3081\u306b, \u3053\u3053\u3067\u306f\u9759\u7684\u306a\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5\u3068\u547c\u3076\u3053\u3068\u306b\u3057\u307e\u3059. 1 \u9759\u7684\u306a\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5\u306b\u3088\u308b\u671f\u5f85\u5024\u8a08\u7b97 \u306f\u3058\u3081\u306b \u3067\u8aac\u660e\u3057\u305f\u3088\u3046\u306b, \u3042\u308b\u78ba\u7387\u5206\u5e03\u95a2\u6570 \\(P(x)\\) \u306b\u5f93\u3046\u78ba\u7387\u5909\u6570 \\(x\\) \u304b\u3089\u8a08\u7b97\u3055\u308c\u308b\u91cf \\(A(x)\\) \u306e\u671f\u5f85\u5024\u3092\u77e5\u308a\u305f\u3051\u308c\u3070, \u78ba\u7387\u5206\u5e03\u95a2\u6570 \\(P(x)\\) \u306b\u5f93\u3046\u4e71\u6570\u5217 \\(\\{x_i\\}_{i=1{\\ldots}n}\\) \u3092\u751f\u6210\u3057\u3066\u5e73\u5747\u5024\u3092\u8a08\u7b97\u3059\u308b\u3068\u3044\u3046\u624b\u6cd5\u304c\u4f7f\u3048\u307e\u3059. \u3053\u3053\u3067, \u4ee5\u4e0b\u306e\u3088\u3046\u306a\u554f\u984c\u8a2d\u5b9a\u3092\u8003\u3048\u307e\u3059. \u9006\u95a2\u6570\u6cd5\u306e\u3088\u3046\u306b\u5909\u6570\u5909\u63db\u306b\u3088\u3063\u3066 \\(P(x)\\) \u306b\u5f93\u3046\u4e71\u6570\u3092\u751f\u6210\u3059\u308b\u3053\u3068\u306f\u3067\u304d\u306a\u3044. \\(P(x)\\) \u306f\u898f\u683c\u5316\u5b9a\u6570\u3092\u9664\u3044\u3066\u5bb9\u6613\u306b\u8a08\u7b97\u3067\u304d\u308b. \u5225\u306e\u8a00\u3044\u65b9\u3092\u3059\u308b\u3068, \\(P(x)\\) \u3068 \\(P(x')\\) \u306e\u6bd4\u306f\u5bb9\u6613\u306b\u8a08\u7b97\u3067\u304d\u308b\u304c, \\(P(x)\\) \u306e\u7d76\u5bfe\u7684\u306a\u5024\u306f\u308f\u304b\u3089\u306a\u3044. \u524d\u8005\u306b\u3064\u3044\u3066\u306f, \u89e3\u6790\u7684\u306a\u89e3\u304c\u3042\u308c\u3070\u305d\u308c\u3092\u4f7f\u3048\u3070\u3044\u3044\u3068\u3044\u3046\u8a71\u306a\u306e\u3067\u7279\u306b\u89e3\u8aac\u306e\u5fc5\u8981\u306f\u306a\u3044\u3068\u601d\u3044\u307e\u3059. \u307e\u305f, Bayes \u306e\u5b9a\u7406\u306b\u57fa\u3065\u3044\u3066\u7acb\u5f0f\u3059\u308b\u3068\u5f8c\u8005\u306e\u3088\u3046\u306a\u30b1\u30fc\u30b9\u306b\u5ea6\u3005\u906d\u9047\u3057\u307e\u3059. \u5b9f\u9a13\u30fb\u89b3\u6e2c\u306b\u3088\u3063\u3066\u30c7\u30fc\u30bf \\(D\\) \u3092\u5f97\u305f\u3068\u304d\u306b\u30d1\u30e9\u30e1\u30bf\u304c \\(\\alpha\\) \u3067\u3042\u308b\u78ba\u7387\u306f \\[ P(\\alpha | D) = \\frac{1}{Z}P(D | \\alpha)P(\\alpha), \\] \u3068\u66f8\u3051\u307e\u3059. \u3053\u3053\u3067 \\(Z\\) \u306f\u898f\u683c\u5316\u5b9a\u6570\u3067\u3059. \\(Z\\) \u3092\u6c42\u3081\u308b\u305f\u3081\u306b\u306f\u53f3\u8fba\u3092 \\(\\alpha\\) \u306b\u3064\u3044\u3066\u7a4d\u5206\u3057\u3066 1 \u306b\u306a\u308b\u3088\u3046\u306b\u5b9a\u3081\u308c\u3070\u826f\u3044\u308f\u3051\u3067\u3059\u304c, \\(\\alpha\\) \u304c\u591a\u6b21\u5143\u306e\u5834\u5408\u306b\u306f\u7a4d\u5206\u306e\u8a08\u7b97\u30b3\u30b9\u30c8\u304c\u6975\u3081\u3066\u9ad8\u304f\u306a\u308a\u307e\u3059. \\(Z\\) \u3092\u76f4\u63a5\u8a55\u4fa1\u3059\u308b\u3053\u3068\u306a\u3057\u306b \\(P(\\alpha | D)\\) \u306b\u5f93\u3046\u78ba\u7387\u5909\u6570 \\(\\alpha\\) \u3092\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3067\u304d\u308c\u3070, \u8a08\u7b97\u30b3\u30b9\u30c8\u3092\u5927\u304d\u304f\u6291\u3048\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u4e71\u6570\u3092\u751f\u6210\u3059\u308b \u3067\u7d39\u4ecb\u3057\u305f\u68c4\u5374\u6cd5\u306f\u307e\u3055\u306b\u305d\u306e\u3088\u3046\u306a\u624b\u6cd5\u306e\u3072\u3068\u3064\u3067\u3057\u305f. \u4ee5\u4e0b\u3067\u306f\u68c4\u5374\u6cd5\u3068\u4f3c\u305f\u8003\u3048\u65b9\u306b\u57fa\u3065\u3044\u3066, \u63d0\u6848\u5206\u5e03 \\(Q(x)\\) \u3092\u7d4c\u7531\u3057\u3066 \\(A(x)\\) \u306e\u671f\u5f85\u5024\u3092\u6c42\u3081\u308b\u305f\u3081\u306e\u624b\u7d9a\u304d\u3092\u4f8b\u793a\u3057\u307e\u3059. \u305f\u3060\u3057 \\(\\tilde{P}(x)\\) \u306f \\(P(x)\\) \u304b\u3089\u898f\u683c\u5316\u5b9a\u6570 \\(Z\\) \u3092\u9664\u3044\u305f\u95a2\u6570\u3068\u3057\u307e\u3059. 2 \u63d0\u6848\u5206\u5e03 \\(Q(x)\\) \u304b\u3089\u78ba\u7387\u5909\u6570 \\(\\{x_i\\}_{i=1{\\ldots}n}\\) \u3092\u30b5\u30f3\u30d7\u30eb\u3059\u308b. \u78ba\u7387\u5909\u6570 \\(x_i\\) \u306b\u5bfe\u3059\u308b\u91cd\u307f \\(w_i = \\tilde{P}(x_i)/Q(x_i)\\) \u3092\u8a08\u7b97\u3059\u308b. \u4ee5\u4e0b\u306e\u5f0f\u306b\u3088\u3063\u3066 \\(A(x)\\) \u306e\u671f\u5f85\u5024\u3068\u898f\u683c\u5316\u5b9a\u6570\u3092\u5f97\u308b. \\[ \\left\\langle{A(x)}\\right\\rangle_{x{\\sim}P(x)} = \\frac{\\sum_i w_i A(x_i)}{\\sum_i w_i}, \\qquad Z = \\frac{1}{n}\\sum_i w_i. \\] \u68c4\u5374\u6cd5\u3067\u306f \\(w_i\\) \u306b\u6bd4\u4f8b\u3059\u308b\u78ba\u7387\u3067 \\(x_i\\) \u3092\u63a1\u7528\u3057\u3066\u3044\u307e\u3057\u305f\u304c, \u3053\u3053\u3067\u306f\u68c4\u5374\u305b\u305a\u306b \\(w_i\\) \u3092\u30b5\u30f3\u30d7\u30eb\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u91cd\u307f\u3068\u3057\u3066\u6271\u3044\u307e\u3059. 3 4 \u4e0a\u8a18\u306e\u5f0f\u304c\u6b63\u3057\u3044\u3053\u3068\u306e\u78ba\u8a8d \\(w_i\\) \u3082 \\(x_i\\) \u3082\u63d0\u6848\u5206\u5e03 \\(Q(x)\\) \u304b\u3089\u30b5\u30f3\u30d7\u30eb\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306a\u306e\u3067, \u30c7\u30fc\u30bf\u6570\u304c\u5341\u5206\u306b\u591a\u3044\u3068\u304d\u306f, \\(w_i A(x_i)\\) \u306e\u5e73\u5747\u5024\u3092 \\(x \\sim Q(x)\\) \u306b\u5bfe\u3059\u308b\u671f\u5f85\u5024\u3067\u7f6e\u304d\u63db\u3048\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \\[ \\frac{1}{n}\\sum_i w_i A(x_i) \\simeq \\left\\langle w_i A(x_i) \\right\\rangle_{x \\sim Q(x)} = \\int \\mathrm{d}x \\,Z\\frac{P(x)}{Q(x)}\\,A(x)\\,Q(x) = Z \\left\\langle A(x_i) \\right\\rangle_{x \\sim P(x)}. \\] \u540c\u69d8\u306e\u64cd\u4f5c\u3092 \\(w_i\\) \u306e\u5e73\u5747\u5024\u306b\u3082\u5b9f\u884c\u3059\u308b\u3068\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u306a\u308a\u307e\u3059. \\[ \\frac{1}{n}\\sum_i w_i \\simeq \\left\\langle w_i \\right\\rangle_{x \\sim Q(x)} = \\int \\mathrm{d}x \\,Z\\frac{P(x)}{Q(x)}\\,Q(x) = Z. \\] \u3088\u3063\u3066 \\(x \\sim P(x)\\) \u306b\u5bfe\u3059\u308b \\(A(x)\\) \u306e\u671f\u5f85\u5024\u304c\u9069\u5207\u306b\u8a08\u7b97\u3055\u308c\u3066\u3044\u305f\u3053\u3068\u306b\u306a\u308a\u307e\u3059. \u5186\u5468\u7387\u306e\u8a08\u7b97 \u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5\u3092\u3082\u3061\u3044\u305f\u8a08\u7b97\u306e\u4f8b\u3068\u3057\u3066\u3088\u304f\u51fa\u3055\u308c\u308b\u3082\u306e\u306b\u5186\u5468\u7387\u306e\u8a08\u7b97\u304c\u3042\u308a\u307e\u3059. \u4e0a\u8a18\u306e\u8a2d\u5b9a\u306b\u3042\u308f\u305b\u3066\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u554f\u984c\u3092\u5b9a\u7fa9\u3057\u3066\u307f\u307e\u3059. 1 \u8fba\u306e\u9577\u3055\u304c 2 \u3067\u3042\u308b\u6b63\u65b9\u5f62\u5185\u90e8\u306e\u4e00\u69d8\u5206\u5e03\u3092\u63d0\u6848\u5206\u5e03 \\(Q(x)\\) \u3068\u3059\u308b. \u534a\u5f84 1 \u3067\u3042\u308b\u5186\u5185\u90e8\u306e\u4e00\u69d8\u5206\u5e03\u3092 \\(P(x)\\) \u3068\u3059\u308b. \\(\\tilde{P}(x) = 1\\) (\u5186\u5185\u90e8) / \\(0\\) (\u305d\u308c\u4ee5\u5916) \u3068\u3059\u308b. \u3053\u306e\u3068\u304d \\(\\int\\mathrm{d}x\\,P(x) = 1\\) \u3088\u308a\u898f\u683c\u5316\u5b9a\u6570 \\(Z\\) \u304c\u6b63\u65b9\u5f62\u306b\u5bfe\u3059\u308b\u5186\u306e\u9762\u7a4d\u306e\u5272\u5408\u3068\u306a\u308b. \u4ee5\u4e0b\u306b\u3053\u306e\u8a2d\u5b9a\u306b\u5f93\u3063\u3066\u8a08\u7b97\u3059\u308b\u30b3\u30fc\u30c9\u3092\u793a\u3057\u307e\u3059. \\(Q(x)\\) \u304b\u3089 10\u2075 \u500b\u306e\u30c7\u30fc\u30bf\u3092\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u3066\u534a\u5f84 1 \u306e\u5186\u306e\u9762\u7a4d\u3092\u63a8\u5b9a\u3057\u307e\u3057\u305f. \u30b0\u30e9\u30d5\u306f\u7dcf\u30c7\u30fc\u30bf\u6570\u3068\u63a8\u5b9a\u3055\u308c\u305f\u9762\u7a4d\u306e\u63a8\u79fb\u3092\u8868\u3057\u3066\u3044\u307e\u3059. import matplotlib.pyplot as plt from numpy.random import default_rng import numpy as np gen = default_rng ( 2021 ) func = lambda x , y : ( x ** 2 + y ** 2 < 1.0 ) A = 2 * 2 N = 100000 n = np . arange ( N ) + 1.0 x = gen . uniform ( - 1 , 1 , size = ( N )) y = gen . uniform ( - 1 , 1 , size = ( N )) w = A * func ( x , y ) print ( f 'estimated area: { w . sum () / N } ' ) fig = plt . figure () ax = fig . add_subplot () ax . semilogx ( n , w . cumsum () / n ) ax . semilogx ( n , np . pi * np . ones_like ( n )) ax . set_ylabel ( 'estimated area' ) ax . set_xlabel ( 'number of samples' ) plt . tight_layout () plt . show () \u8a08\u7b97\u7d50\u679c estimated area: 3.14508 N \u6b21\u5143\u7403\u306e\u4f53\u7a4d\u306e\u8a08\u7b97 \u4e0a\u8a18\u3067\u306f 2 \u6b21\u5143\u7a7a\u9593\u306b\u5bfe\u3057\u3066\u8a08\u7b97\u3092\u3057\u307e\u3057\u305f\u304c, \u307e\u3063\u305f\u304f\u540c\u3058\u3053\u3068\u3092 N \u6b21\u5143\u7a7a\u9593\u3067\u8a08\u7b97\u3057\u3066\u307f\u307e\u3057\u3087\u3046. N \u6b21\u5143\u7acb\u65b9\u4f53\u306b\u5185\u63a5\u3059\u308b N \u6b21\u5143\u7403\u306e\u4f53\u7a4d\u3092\u8003\u3048\u307e\u3059. \u306a\u304a N \u6b21\u5143\u7403\u306e\u4f53\u7a4d\u306f\u4ee5\u4e0b\u306e\u5f0f\u3067\u8a08\u7b97\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \\[ V_N = \\frac{\\pi^{N/2}}{\\Gamma(N/2 + 1)}. \\] \\(\\Gamma(x)\\) \u306f\u30ac\u30f3\u30de\u95a2\u6570\u3067\u3059. \u3053\u306e\u89e3\u6790\u89e3\u306b\u5bfe\u3057\u3066\u3069\u306e\u3088\u3046\u306b\u53ce\u675f\u3057\u3066\u3044\u304f\u304b\u3092\u8abf\u3079\u307e\u3059. \u4ee5\u4e0b\u306b \\(N=15\\) \u306e\u8a08\u7b97\u4f8b\u3068\u7d50\u679c\u3092\u793a\u3057\u307e\u3057\u305f. \u5148\u7a0b\u3088\u308a\u30b5\u30f3\u30d7\u30eb\u6570\u3092\u5897\u3084\u3057\u3066 10\u2076 \u500b\u306e\u30c7\u30fc\u30bf\u3092 \\(Q(x)\\) \u304b\u3089\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u3066\u3044\u307e\u3059. import matplotlib.pyplot as plt from numpy.random import default_rng from scipy.special import gamma import numpy as np gen = default_rng ( 2021 ) func = lambda x : (( x * x ) . sum ( axis = 1 ) < 1.0 ) N = 15 A = 2 ** N M = 1000000 n = np . arange ( N ) + 1.0 x = gen . uniform ( - 1 , 1 , size = ( M , N )) w = A * func ( x ) V = np . pi ** ( N / 2 ) / gamma ( N / 2 + 1 ) print ( f 'estimated area: { w . sum () / N : .5f } ( { V : .5f } )' ) fig = plt . figure () ax = fig . add_subplot () ax . semilogx ( n , w . cumsum () / n ) ax . semilogx ( n , V * np . ones_like ( n )) ax . set_ylabel ( 'estimated volume' ) ax . set_xlabel ( 'number of samples' ) plt . tight_layout () plt . show () \u8a08\u7b97\u7d50\u679c estimated area: 0.22938 (0.38144) \u7d50\u679c\u306f\u89e3\u6790\u7684\u306b\u8a08\u7b97\u3055\u308c\u308b\u5024\u306b\u6bd4\u3079\u3066\u304b\u306a\u308a\u4f4e\u3044\u5024 (60% \u307b\u3069) \u306b\u306a\u308a\u307e\u3057\u305f. \u4f53\u7a4d\u306e\u63a8\u79fb\u3092\u898b\u3066\u307f\u308b\u3068, \u5148\u7a0b\u306e\u4f8b\u3068\u6bd4\u8f03\u3057\u3066\u5024\u304c\u307e\u3063\u305f\u304f\u53ce\u675f\u3057\u3066\u3044\u306a\u3044\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3059. 10\u2075 \u500b\u3092\u8d85\u3048\u308b\u307e\u3067\u306f 0 \u3092\u793a\u3057\u3066\u304a\u308a, \\(Q(x)\\) \u304b\u3089\u30b5\u30f3\u30d7\u30eb\u3057\u305f\u30c7\u30fc\u30bf\u304c 1 \u3064\u3082 N \u6b21\u5143\u7403\u306b\u5165\u3089\u306a\u304b\u3063\u305f\u3053\u3068\u306b\u306a\u308a\u307e\u3059. 5 \u6b21\u5143\u6570\u3092\u5909\u3048\u3066\u8a08\u7b97\u3092\u3057\u3066\u307f\u308b\u3068 \\(N\\) \u304c\u5c0f\u3055\u3044\u3046\u3061\u306f\u554f\u984c\u306a\u304f\u53ce\u675f\u3057\u3066\u3044\u304d\u307e\u3059\u304c, \\(N = 13\\) \u3042\u305f\u308a\u304b\u3089\u6025\u306b\u53ce\u675f\u3057\u306a\u304f\u306a\u308a\u307e\u3059. \u3053\u308c\u306f N \u6b21\u5143\u7acb\u65b9\u4f53\u306e\u4f53\u7a4d\u306f\u6b21\u5143\u304c\u5927\u304d\u304f\u306a\u308b\u3068\u307b\u3068\u3093\u3069\u3092\u58c1\u969b\u304c\u62c5\u3046\u3088\u3046\u306b\u306a\u308b\u305f\u3081\u3067\u3059. N \u6b21\u5143\u7a7a\u9593\u3067\u306f\u63d0\u6848\u5206\u5e03 \\(Q(x)\\) \u3068\u30bf\u30fc\u30b2\u30c3\u30c8\u3068\u306a\u308b\u5206\u5e03 \\(P(x)\\) \u306e\u9055\u3044\u304c\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5\u306b\u3088\u308b\u8a08\u7b97\u306e\u52b9\u7387\u306b\u5927\u304d\u304f\u95a2\u308f\u3063\u3066\u304d\u307e\u3059. \u30c7\u30fc\u30bf\u306e\u6b21\u5143 N \u304c\u5927\u304d\u3044\u5834\u5408\u306b\u306f, \u9759\u7684\u306a\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5\u306b\u3088\u308b\u671f\u5f85\u5024\u8a08\u7b97\u306f\u53ce\u675f\u6027\u306e\u9762\u3067\u5927\u304d\u306a\u554f\u984c\u3092\u62b1\u3048\u308b\u3053\u3068\u306b\u306a\u308a\u307e\u3059. \u3053\u306e\u547c\u3073\u65b9\u306f\u300e \u7d71\u8a08\u79d1\u5b66\u306e\u30d5\u30ed\u30f3\u30c6\u30a3\u30a2 12 \u8a08\u7b97\u7d71\u8a08II \u30de\u30eb\u30b3\u30d5\u9023\u9396\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5\u3068\u305d\u306e\u5468\u8fba \u300f\u306b\u5023\u3044\u307e\u3057\u305f. \u21a9 \u3064\u307e\u308a \\(P(x) = \\tilde{P}(x)/Z\\) \u3067\u3059. \u21a9 \u671f\u5f85\u5024\u3092\u6c42\u3081\u308b\u3068\u3044\u3046\u89b3\u70b9\u304b\u3089\u306f, \u3042\u308b\u78ba\u7387\u3067\u63a1\u7528\u3059\u308b\u3053\u3068\u306f\u305d\u306e\u78ba\u7387\u306b\u6bd4\u4f8b\u3057\u305f\u91cd\u307f\u3092\u4ed8\u3051\u308b\u3053\u3068\u3068\u540c\u7fa9\u3067\u3059. \u30c7\u30fc\u30bf\u3092\u4e88\u3081\u9593\u5f15\u304f (\u68c4\u5374\u6cd5) \u304b\u671f\u5f85\u5024\u8a08\u7b97\u3067\u5bc4\u4e0e\u3092\u5727\u7e2e\u3059\u308b\u304b, \u3068\u3044\u3046\u30bf\u30a4\u30df\u30f3\u30b0\u306e\u9055\u3044\u3067\u3059. \u21a9 \u68c4\u5374\u3059\u308b\u5834\u5408\u306b\u306f\u6b32\u3057\u3044\u30b5\u30f3\u30d7\u30eb\u6570\u3092\u5f97\u308b\u307e\u3067 loop \u3092\u56de\u3059\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u304c, Python \u306a\u3069\u4e00\u90e8\u306e\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\u8a00\u8a9e\u306f loop \u3092\u56de\u3059\u3068\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u304c\u5927\u304d\u304f\u4f4e\u4e0b\u3059\u308b\u3053\u3068\u304c\u3042\u308b\u305f\u3081, \u305d\u3046\u3044\u3063\u305f\u610f\u5473\u3067\u3082\u3053\u3061\u3089\u306e\u307b\u3046\u304c\u4fbf\u5229\u3060\u3063\u305f\u308a\u3057\u307e\u3059. \u21a9 N \u6b21\u5143\u7acb\u65b9\u4f53\u306e\u4f53\u7a4d\u3068\u306e\u6bd4\u3092\u3068\u3063\u3066\u307f\u308b\u3068 \\(N = 15\\) \u306e\u3068\u304d\u306b\u304a\u3088\u305d 10\u207b\u2075 \u306a\u306e\u3067\u304a\u304a\u3088\u305d\u78ba\u7387\u901a\u308a\u3068\u8a00\u3048\u307e\u3059. \u21a9","title":"\u9759\u7684\u306a\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5"},{"location":"mcmc/static_monte_carlo/#_1","text":"\u3053\u3053\u3067\u306f\u30de\u30eb\u30b3\u30d5\u9023\u9396\u3067\u306f\u306a\u3044\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5\u3092\u7528\u3044\u3066\u8a08\u7b97\u3092\u3059\u308b\u65b9\u6cd5\u3068\u305d\u306e\u9650\u754c\u306b\u3064\u3044\u3066\u89e6\u308c\u307e\u3059. \u30de\u30eb\u30b3\u30d5\u9023\u9396\u306b\u3088\u3063\u3066\u52d5\u7684\u306b\u30b5\u30f3\u30d7\u30eb\u3092\u751f\u6210\u3059\u308b\u65b9\u6cd5\u3068\u5bfe\u6bd4\u3059\u308b\u305f\u3081\u306b, \u3053\u3053\u3067\u306f\u9759\u7684\u306a\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5\u3068\u547c\u3076\u3053\u3068\u306b\u3057\u307e\u3059. 1","title":"\u9759\u7684\u306a\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5"},{"location":"mcmc/static_monte_carlo/#_2","text":"\u306f\u3058\u3081\u306b \u3067\u8aac\u660e\u3057\u305f\u3088\u3046\u306b, \u3042\u308b\u78ba\u7387\u5206\u5e03\u95a2\u6570 \\(P(x)\\) \u306b\u5f93\u3046\u78ba\u7387\u5909\u6570 \\(x\\) \u304b\u3089\u8a08\u7b97\u3055\u308c\u308b\u91cf \\(A(x)\\) \u306e\u671f\u5f85\u5024\u3092\u77e5\u308a\u305f\u3051\u308c\u3070, \u78ba\u7387\u5206\u5e03\u95a2\u6570 \\(P(x)\\) \u306b\u5f93\u3046\u4e71\u6570\u5217 \\(\\{x_i\\}_{i=1{\\ldots}n}\\) \u3092\u751f\u6210\u3057\u3066\u5e73\u5747\u5024\u3092\u8a08\u7b97\u3059\u308b\u3068\u3044\u3046\u624b\u6cd5\u304c\u4f7f\u3048\u307e\u3059. \u3053\u3053\u3067, \u4ee5\u4e0b\u306e\u3088\u3046\u306a\u554f\u984c\u8a2d\u5b9a\u3092\u8003\u3048\u307e\u3059. \u9006\u95a2\u6570\u6cd5\u306e\u3088\u3046\u306b\u5909\u6570\u5909\u63db\u306b\u3088\u3063\u3066 \\(P(x)\\) \u306b\u5f93\u3046\u4e71\u6570\u3092\u751f\u6210\u3059\u308b\u3053\u3068\u306f\u3067\u304d\u306a\u3044. \\(P(x)\\) \u306f\u898f\u683c\u5316\u5b9a\u6570\u3092\u9664\u3044\u3066\u5bb9\u6613\u306b\u8a08\u7b97\u3067\u304d\u308b. \u5225\u306e\u8a00\u3044\u65b9\u3092\u3059\u308b\u3068, \\(P(x)\\) \u3068 \\(P(x')\\) \u306e\u6bd4\u306f\u5bb9\u6613\u306b\u8a08\u7b97\u3067\u304d\u308b\u304c, \\(P(x)\\) \u306e\u7d76\u5bfe\u7684\u306a\u5024\u306f\u308f\u304b\u3089\u306a\u3044. \u524d\u8005\u306b\u3064\u3044\u3066\u306f, \u89e3\u6790\u7684\u306a\u89e3\u304c\u3042\u308c\u3070\u305d\u308c\u3092\u4f7f\u3048\u3070\u3044\u3044\u3068\u3044\u3046\u8a71\u306a\u306e\u3067\u7279\u306b\u89e3\u8aac\u306e\u5fc5\u8981\u306f\u306a\u3044\u3068\u601d\u3044\u307e\u3059. \u307e\u305f, Bayes \u306e\u5b9a\u7406\u306b\u57fa\u3065\u3044\u3066\u7acb\u5f0f\u3059\u308b\u3068\u5f8c\u8005\u306e\u3088\u3046\u306a\u30b1\u30fc\u30b9\u306b\u5ea6\u3005\u906d\u9047\u3057\u307e\u3059. \u5b9f\u9a13\u30fb\u89b3\u6e2c\u306b\u3088\u3063\u3066\u30c7\u30fc\u30bf \\(D\\) \u3092\u5f97\u305f\u3068\u304d\u306b\u30d1\u30e9\u30e1\u30bf\u304c \\(\\alpha\\) \u3067\u3042\u308b\u78ba\u7387\u306f \\[ P(\\alpha | D) = \\frac{1}{Z}P(D | \\alpha)P(\\alpha), \\] \u3068\u66f8\u3051\u307e\u3059. \u3053\u3053\u3067 \\(Z\\) \u306f\u898f\u683c\u5316\u5b9a\u6570\u3067\u3059. \\(Z\\) \u3092\u6c42\u3081\u308b\u305f\u3081\u306b\u306f\u53f3\u8fba\u3092 \\(\\alpha\\) \u306b\u3064\u3044\u3066\u7a4d\u5206\u3057\u3066 1 \u306b\u306a\u308b\u3088\u3046\u306b\u5b9a\u3081\u308c\u3070\u826f\u3044\u308f\u3051\u3067\u3059\u304c, \\(\\alpha\\) \u304c\u591a\u6b21\u5143\u306e\u5834\u5408\u306b\u306f\u7a4d\u5206\u306e\u8a08\u7b97\u30b3\u30b9\u30c8\u304c\u6975\u3081\u3066\u9ad8\u304f\u306a\u308a\u307e\u3059. \\(Z\\) \u3092\u76f4\u63a5\u8a55\u4fa1\u3059\u308b\u3053\u3068\u306a\u3057\u306b \\(P(\\alpha | D)\\) \u306b\u5f93\u3046\u78ba\u7387\u5909\u6570 \\(\\alpha\\) \u3092\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3067\u304d\u308c\u3070, \u8a08\u7b97\u30b3\u30b9\u30c8\u3092\u5927\u304d\u304f\u6291\u3048\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \u4e71\u6570\u3092\u751f\u6210\u3059\u308b \u3067\u7d39\u4ecb\u3057\u305f\u68c4\u5374\u6cd5\u306f\u307e\u3055\u306b\u305d\u306e\u3088\u3046\u306a\u624b\u6cd5\u306e\u3072\u3068\u3064\u3067\u3057\u305f. \u4ee5\u4e0b\u3067\u306f\u68c4\u5374\u6cd5\u3068\u4f3c\u305f\u8003\u3048\u65b9\u306b\u57fa\u3065\u3044\u3066, \u63d0\u6848\u5206\u5e03 \\(Q(x)\\) \u3092\u7d4c\u7531\u3057\u3066 \\(A(x)\\) \u306e\u671f\u5f85\u5024\u3092\u6c42\u3081\u308b\u305f\u3081\u306e\u624b\u7d9a\u304d\u3092\u4f8b\u793a\u3057\u307e\u3059. \u305f\u3060\u3057 \\(\\tilde{P}(x)\\) \u306f \\(P(x)\\) \u304b\u3089\u898f\u683c\u5316\u5b9a\u6570 \\(Z\\) \u3092\u9664\u3044\u305f\u95a2\u6570\u3068\u3057\u307e\u3059. 2 \u63d0\u6848\u5206\u5e03 \\(Q(x)\\) \u304b\u3089\u78ba\u7387\u5909\u6570 \\(\\{x_i\\}_{i=1{\\ldots}n}\\) \u3092\u30b5\u30f3\u30d7\u30eb\u3059\u308b. \u78ba\u7387\u5909\u6570 \\(x_i\\) \u306b\u5bfe\u3059\u308b\u91cd\u307f \\(w_i = \\tilde{P}(x_i)/Q(x_i)\\) \u3092\u8a08\u7b97\u3059\u308b. \u4ee5\u4e0b\u306e\u5f0f\u306b\u3088\u3063\u3066 \\(A(x)\\) \u306e\u671f\u5f85\u5024\u3068\u898f\u683c\u5316\u5b9a\u6570\u3092\u5f97\u308b. \\[ \\left\\langle{A(x)}\\right\\rangle_{x{\\sim}P(x)} = \\frac{\\sum_i w_i A(x_i)}{\\sum_i w_i}, \\qquad Z = \\frac{1}{n}\\sum_i w_i. \\] \u68c4\u5374\u6cd5\u3067\u306f \\(w_i\\) \u306b\u6bd4\u4f8b\u3059\u308b\u78ba\u7387\u3067 \\(x_i\\) \u3092\u63a1\u7528\u3057\u3066\u3044\u307e\u3057\u305f\u304c, \u3053\u3053\u3067\u306f\u68c4\u5374\u305b\u305a\u306b \\(w_i\\) \u3092\u30b5\u30f3\u30d7\u30eb\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u91cd\u307f\u3068\u3057\u3066\u6271\u3044\u307e\u3059. 3 4 \u4e0a\u8a18\u306e\u5f0f\u304c\u6b63\u3057\u3044\u3053\u3068\u306e\u78ba\u8a8d \\(w_i\\) \u3082 \\(x_i\\) \u3082\u63d0\u6848\u5206\u5e03 \\(Q(x)\\) \u304b\u3089\u30b5\u30f3\u30d7\u30eb\u3055\u308c\u305f\u30c7\u30fc\u30bf\u306a\u306e\u3067, \u30c7\u30fc\u30bf\u6570\u304c\u5341\u5206\u306b\u591a\u3044\u3068\u304d\u306f, \\(w_i A(x_i)\\) \u306e\u5e73\u5747\u5024\u3092 \\(x \\sim Q(x)\\) \u306b\u5bfe\u3059\u308b\u671f\u5f85\u5024\u3067\u7f6e\u304d\u63db\u3048\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \\[ \\frac{1}{n}\\sum_i w_i A(x_i) \\simeq \\left\\langle w_i A(x_i) \\right\\rangle_{x \\sim Q(x)} = \\int \\mathrm{d}x \\,Z\\frac{P(x)}{Q(x)}\\,A(x)\\,Q(x) = Z \\left\\langle A(x_i) \\right\\rangle_{x \\sim P(x)}. \\] \u540c\u69d8\u306e\u64cd\u4f5c\u3092 \\(w_i\\) \u306e\u5e73\u5747\u5024\u306b\u3082\u5b9f\u884c\u3059\u308b\u3068\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u306a\u308a\u307e\u3059. \\[ \\frac{1}{n}\\sum_i w_i \\simeq \\left\\langle w_i \\right\\rangle_{x \\sim Q(x)} = \\int \\mathrm{d}x \\,Z\\frac{P(x)}{Q(x)}\\,Q(x) = Z. \\] \u3088\u3063\u3066 \\(x \\sim P(x)\\) \u306b\u5bfe\u3059\u308b \\(A(x)\\) \u306e\u671f\u5f85\u5024\u304c\u9069\u5207\u306b\u8a08\u7b97\u3055\u308c\u3066\u3044\u305f\u3053\u3068\u306b\u306a\u308a\u307e\u3059.","title":"\u9759\u7684\u306a\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5\u306b\u3088\u308b\u671f\u5f85\u5024\u8a08\u7b97"},{"location":"mcmc/static_monte_carlo/#_3","text":"\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5\u3092\u3082\u3061\u3044\u305f\u8a08\u7b97\u306e\u4f8b\u3068\u3057\u3066\u3088\u304f\u51fa\u3055\u308c\u308b\u3082\u306e\u306b\u5186\u5468\u7387\u306e\u8a08\u7b97\u304c\u3042\u308a\u307e\u3059. \u4e0a\u8a18\u306e\u8a2d\u5b9a\u306b\u3042\u308f\u305b\u3066\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u554f\u984c\u3092\u5b9a\u7fa9\u3057\u3066\u307f\u307e\u3059. 1 \u8fba\u306e\u9577\u3055\u304c 2 \u3067\u3042\u308b\u6b63\u65b9\u5f62\u5185\u90e8\u306e\u4e00\u69d8\u5206\u5e03\u3092\u63d0\u6848\u5206\u5e03 \\(Q(x)\\) \u3068\u3059\u308b. \u534a\u5f84 1 \u3067\u3042\u308b\u5186\u5185\u90e8\u306e\u4e00\u69d8\u5206\u5e03\u3092 \\(P(x)\\) \u3068\u3059\u308b. \\(\\tilde{P}(x) = 1\\) (\u5186\u5185\u90e8) / \\(0\\) (\u305d\u308c\u4ee5\u5916) \u3068\u3059\u308b. \u3053\u306e\u3068\u304d \\(\\int\\mathrm{d}x\\,P(x) = 1\\) \u3088\u308a\u898f\u683c\u5316\u5b9a\u6570 \\(Z\\) \u304c\u6b63\u65b9\u5f62\u306b\u5bfe\u3059\u308b\u5186\u306e\u9762\u7a4d\u306e\u5272\u5408\u3068\u306a\u308b. \u4ee5\u4e0b\u306b\u3053\u306e\u8a2d\u5b9a\u306b\u5f93\u3063\u3066\u8a08\u7b97\u3059\u308b\u30b3\u30fc\u30c9\u3092\u793a\u3057\u307e\u3059. \\(Q(x)\\) \u304b\u3089 10\u2075 \u500b\u306e\u30c7\u30fc\u30bf\u3092\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u3066\u534a\u5f84 1 \u306e\u5186\u306e\u9762\u7a4d\u3092\u63a8\u5b9a\u3057\u307e\u3057\u305f. \u30b0\u30e9\u30d5\u306f\u7dcf\u30c7\u30fc\u30bf\u6570\u3068\u63a8\u5b9a\u3055\u308c\u305f\u9762\u7a4d\u306e\u63a8\u79fb\u3092\u8868\u3057\u3066\u3044\u307e\u3059. import matplotlib.pyplot as plt from numpy.random import default_rng import numpy as np gen = default_rng ( 2021 ) func = lambda x , y : ( x ** 2 + y ** 2 < 1.0 ) A = 2 * 2 N = 100000 n = np . arange ( N ) + 1.0 x = gen . uniform ( - 1 , 1 , size = ( N )) y = gen . uniform ( - 1 , 1 , size = ( N )) w = A * func ( x , y ) print ( f 'estimated area: { w . sum () / N } ' ) fig = plt . figure () ax = fig . add_subplot () ax . semilogx ( n , w . cumsum () / n ) ax . semilogx ( n , np . pi * np . ones_like ( n )) ax . set_ylabel ( 'estimated area' ) ax . set_xlabel ( 'number of samples' ) plt . tight_layout () plt . show () \u8a08\u7b97\u7d50\u679c estimated area: 3.14508","title":"\u5186\u5468\u7387\u306e\u8a08\u7b97"},{"location":"mcmc/static_monte_carlo/#n","text":"\u4e0a\u8a18\u3067\u306f 2 \u6b21\u5143\u7a7a\u9593\u306b\u5bfe\u3057\u3066\u8a08\u7b97\u3092\u3057\u307e\u3057\u305f\u304c, \u307e\u3063\u305f\u304f\u540c\u3058\u3053\u3068\u3092 N \u6b21\u5143\u7a7a\u9593\u3067\u8a08\u7b97\u3057\u3066\u307f\u307e\u3057\u3087\u3046. N \u6b21\u5143\u7acb\u65b9\u4f53\u306b\u5185\u63a5\u3059\u308b N \u6b21\u5143\u7403\u306e\u4f53\u7a4d\u3092\u8003\u3048\u307e\u3059. \u306a\u304a N \u6b21\u5143\u7403\u306e\u4f53\u7a4d\u306f\u4ee5\u4e0b\u306e\u5f0f\u3067\u8a08\u7b97\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059. \\[ V_N = \\frac{\\pi^{N/2}}{\\Gamma(N/2 + 1)}. \\] \\(\\Gamma(x)\\) \u306f\u30ac\u30f3\u30de\u95a2\u6570\u3067\u3059. \u3053\u306e\u89e3\u6790\u89e3\u306b\u5bfe\u3057\u3066\u3069\u306e\u3088\u3046\u306b\u53ce\u675f\u3057\u3066\u3044\u304f\u304b\u3092\u8abf\u3079\u307e\u3059. \u4ee5\u4e0b\u306b \\(N=15\\) \u306e\u8a08\u7b97\u4f8b\u3068\u7d50\u679c\u3092\u793a\u3057\u307e\u3057\u305f. \u5148\u7a0b\u3088\u308a\u30b5\u30f3\u30d7\u30eb\u6570\u3092\u5897\u3084\u3057\u3066 10\u2076 \u500b\u306e\u30c7\u30fc\u30bf\u3092 \\(Q(x)\\) \u304b\u3089\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u3066\u3044\u307e\u3059. import matplotlib.pyplot as plt from numpy.random import default_rng from scipy.special import gamma import numpy as np gen = default_rng ( 2021 ) func = lambda x : (( x * x ) . sum ( axis = 1 ) < 1.0 ) N = 15 A = 2 ** N M = 1000000 n = np . arange ( N ) + 1.0 x = gen . uniform ( - 1 , 1 , size = ( M , N )) w = A * func ( x ) V = np . pi ** ( N / 2 ) / gamma ( N / 2 + 1 ) print ( f 'estimated area: { w . sum () / N : .5f } ( { V : .5f } )' ) fig = plt . figure () ax = fig . add_subplot () ax . semilogx ( n , w . cumsum () / n ) ax . semilogx ( n , V * np . ones_like ( n )) ax . set_ylabel ( 'estimated volume' ) ax . set_xlabel ( 'number of samples' ) plt . tight_layout () plt . show () \u8a08\u7b97\u7d50\u679c estimated area: 0.22938 (0.38144) \u7d50\u679c\u306f\u89e3\u6790\u7684\u306b\u8a08\u7b97\u3055\u308c\u308b\u5024\u306b\u6bd4\u3079\u3066\u304b\u306a\u308a\u4f4e\u3044\u5024 (60% \u307b\u3069) \u306b\u306a\u308a\u307e\u3057\u305f. \u4f53\u7a4d\u306e\u63a8\u79fb\u3092\u898b\u3066\u307f\u308b\u3068, \u5148\u7a0b\u306e\u4f8b\u3068\u6bd4\u8f03\u3057\u3066\u5024\u304c\u307e\u3063\u305f\u304f\u53ce\u675f\u3057\u3066\u3044\u306a\u3044\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3059. 10\u2075 \u500b\u3092\u8d85\u3048\u308b\u307e\u3067\u306f 0 \u3092\u793a\u3057\u3066\u304a\u308a, \\(Q(x)\\) \u304b\u3089\u30b5\u30f3\u30d7\u30eb\u3057\u305f\u30c7\u30fc\u30bf\u304c 1 \u3064\u3082 N \u6b21\u5143\u7403\u306b\u5165\u3089\u306a\u304b\u3063\u305f\u3053\u3068\u306b\u306a\u308a\u307e\u3059. 5 \u6b21\u5143\u6570\u3092\u5909\u3048\u3066\u8a08\u7b97\u3092\u3057\u3066\u307f\u308b\u3068 \\(N\\) \u304c\u5c0f\u3055\u3044\u3046\u3061\u306f\u554f\u984c\u306a\u304f\u53ce\u675f\u3057\u3066\u3044\u304d\u307e\u3059\u304c, \\(N = 13\\) \u3042\u305f\u308a\u304b\u3089\u6025\u306b\u53ce\u675f\u3057\u306a\u304f\u306a\u308a\u307e\u3059. \u3053\u308c\u306f N \u6b21\u5143\u7acb\u65b9\u4f53\u306e\u4f53\u7a4d\u306f\u6b21\u5143\u304c\u5927\u304d\u304f\u306a\u308b\u3068\u307b\u3068\u3093\u3069\u3092\u58c1\u969b\u304c\u62c5\u3046\u3088\u3046\u306b\u306a\u308b\u305f\u3081\u3067\u3059. N \u6b21\u5143\u7a7a\u9593\u3067\u306f\u63d0\u6848\u5206\u5e03 \\(Q(x)\\) \u3068\u30bf\u30fc\u30b2\u30c3\u30c8\u3068\u306a\u308b\u5206\u5e03 \\(P(x)\\) \u306e\u9055\u3044\u304c\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5\u306b\u3088\u308b\u8a08\u7b97\u306e\u52b9\u7387\u306b\u5927\u304d\u304f\u95a2\u308f\u3063\u3066\u304d\u307e\u3059. \u30c7\u30fc\u30bf\u306e\u6b21\u5143 N \u304c\u5927\u304d\u3044\u5834\u5408\u306b\u306f, \u9759\u7684\u306a\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5\u306b\u3088\u308b\u671f\u5f85\u5024\u8a08\u7b97\u306f\u53ce\u675f\u6027\u306e\u9762\u3067\u5927\u304d\u306a\u554f\u984c\u3092\u62b1\u3048\u308b\u3053\u3068\u306b\u306a\u308a\u307e\u3059. \u3053\u306e\u547c\u3073\u65b9\u306f\u300e \u7d71\u8a08\u79d1\u5b66\u306e\u30d5\u30ed\u30f3\u30c6\u30a3\u30a2 12 \u8a08\u7b97\u7d71\u8a08II \u30de\u30eb\u30b3\u30d5\u9023\u9396\u30e2\u30f3\u30c6\u30ab\u30eb\u30ed\u6cd5\u3068\u305d\u306e\u5468\u8fba \u300f\u306b\u5023\u3044\u307e\u3057\u305f. \u21a9 \u3064\u307e\u308a \\(P(x) = \\tilde{P}(x)/Z\\) \u3067\u3059. \u21a9 \u671f\u5f85\u5024\u3092\u6c42\u3081\u308b\u3068\u3044\u3046\u89b3\u70b9\u304b\u3089\u306f, \u3042\u308b\u78ba\u7387\u3067\u63a1\u7528\u3059\u308b\u3053\u3068\u306f\u305d\u306e\u78ba\u7387\u306b\u6bd4\u4f8b\u3057\u305f\u91cd\u307f\u3092\u4ed8\u3051\u308b\u3053\u3068\u3068\u540c\u7fa9\u3067\u3059. \u30c7\u30fc\u30bf\u3092\u4e88\u3081\u9593\u5f15\u304f (\u68c4\u5374\u6cd5) \u304b\u671f\u5f85\u5024\u8a08\u7b97\u3067\u5bc4\u4e0e\u3092\u5727\u7e2e\u3059\u308b\u304b, \u3068\u3044\u3046\u30bf\u30a4\u30df\u30f3\u30b0\u306e\u9055\u3044\u3067\u3059. \u21a9 \u68c4\u5374\u3059\u308b\u5834\u5408\u306b\u306f\u6b32\u3057\u3044\u30b5\u30f3\u30d7\u30eb\u6570\u3092\u5f97\u308b\u307e\u3067 loop \u3092\u56de\u3059\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u304c, Python \u306a\u3069\u4e00\u90e8\u306e\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\u8a00\u8a9e\u306f loop \u3092\u56de\u3059\u3068\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u304c\u5927\u304d\u304f\u4f4e\u4e0b\u3059\u308b\u3053\u3068\u304c\u3042\u308b\u305f\u3081, \u305d\u3046\u3044\u3063\u305f\u610f\u5473\u3067\u3082\u3053\u3061\u3089\u306e\u307b\u3046\u304c\u4fbf\u5229\u3060\u3063\u305f\u308a\u3057\u307e\u3059. \u21a9 N \u6b21\u5143\u7acb\u65b9\u4f53\u306e\u4f53\u7a4d\u3068\u306e\u6bd4\u3092\u3068\u3063\u3066\u307f\u308b\u3068 \\(N = 15\\) \u306e\u3068\u304d\u306b\u304a\u3088\u305d 10\u207b\u2075 \u306a\u306e\u3067\u304a\u304a\u3088\u305d\u78ba\u7387\u901a\u308a\u3068\u8a00\u3048\u307e\u3059. \u21a9","title":"N \u6b21\u5143\u7403\u306e\u4f53\u7a4d\u306e\u8a08\u7b97"}]}